{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "dataset_dir = r'datasets\\PhishStorm\\urlset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# !pip install transformers datasets torch evaluate\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu118'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from calflops import calculate_flops\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000])\n",
      "tensor(1.0116)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_nums = torch.randn(5000)\n",
    "print(rand_nums.shape)\n",
    "print(torch.std(rand_nums))\n",
    "plt.hist(rand_nums, bins=500)\n",
    "plt.hist(torch.fmod(rand_nums,2), bins=250)\n",
    "plt.hist(torch.fmod(rand_nums,2.)*(2./3.), bins=250)\n",
    "plt.xlim([-4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_15048\\2436288285.py:1: ParserWarning: Skipping line 18259: expected 14 fields, saw 15\n",
      "Skipping line 18273: expected 14 fields, saw 15\n",
      "\n",
      "  df = pd.read_csv(dataset_dir, on_bad_lines='warn', encoding = 'ISO-8859-1', low_memory=False)[['domain','label']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    43251\n",
      "1    43070\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    4834\n",
      "0    4758\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_dir, on_bad_lines='warn', encoding = 'ISO-8859-1', low_memory=False)[['domain','label']]\n",
    "df.columns=['text', 'Topic']\n",
    "df.dropna(inplace=True)\n",
    "class_list = df.Topic.unique()\n",
    "class_id = {'benign':0, 'phishing': 1}\n",
    "id_class = {0: 'benign', 1:'phishing'}\n",
    "df['label'] = np.array([t for t in df['Topic']], dtype=int)\n",
    "df = df.drop('Topic', axis=1)\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=True)\n",
    "print(df_train.label.value_counts())\n",
    "print(df_test.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520142866c1d4134b740f92f83492eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/86321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2ca24e4b024a1aa1a9ac0781bdf778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=64, padding='max_length')\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the format for PyTorch\n",
    "train_dataset = train_dataset.rename_column('label', 'labels')\n",
    "test_dataset = test_dataset.rename_column('label', 'labels')\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=r'logs/OtherModels/bert_ag_results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "# Load the metrics\n",
    "import evaluate;\n",
    "accuracy_metric = evaluate.load('accuracy', trust_remote_code=True)\n",
    "precision_metric = evaluate.load('precision', trust_remote_code=True)\n",
    "recall_metric = evaluate.load('recall', trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p.predictions, p.label_ids\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall']\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2436ab2cc90a4b8f866730a9465d6840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1934bb00761443c894259b11a3a6db61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05669315904378891, 'eval_accuracy': 0.9875938281901585, 'eval_precision': 0.9875896539240167, 'eval_recall': 0.9875971797080474, 'eval_runtime': 5.8412, 'eval_samples_per_second': 1642.121, 'eval_steps_per_second': 6.505, 'epoch': 1.0}\n",
      "{'loss': 0.0073, 'learning_rate': 1.85207100591716e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaabc63be6384e6181b0305b5aabf090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06313420087099075, 'eval_accuracy': 0.9871768140116765, 'eval_precision': 0.9872070176509484, 'eval_recall': 0.9872263998721401, 'eval_runtime': 5.5328, 'eval_samples_per_second': 1733.646, 'eval_steps_per_second': 6.868, 'epoch': 2.0}\n",
      "{'loss': 0.0041, 'learning_rate': 1.70414201183432e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de09e39b44b49f581df8383e64e316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0646197572350502, 'eval_accuracy': 0.9873853211009175, 'eval_precision': 0.9873944717167789, 'eval_recall': 0.987423354920998, 'eval_runtime': 6.0099, 'eval_samples_per_second': 1596.045, 'eval_steps_per_second': 6.323, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2d8a5148ec4d98bcc8b271cd7649b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06646925210952759, 'eval_accuracy': 0.9857172643869891, 'eval_precision': 0.9857675217615666, 'eval_recall': 0.985775019421594, 'eval_runtime': 5.8946, 'eval_samples_per_second': 1627.256, 'eval_steps_per_second': 6.447, 'epoch': 4.0}\n",
      "{'loss': 0.0044, 'learning_rate': 1.5562130177514792e-05, 'epoch': 4.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d25fe433a674ac2a110c195b2edf454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06862922012805939, 'eval_accuracy': 0.9855087572977481, 'eval_precision': 0.9856180537320742, 'eval_recall': 0.985584673018967, 'eval_runtime': 5.5955, 'eval_samples_per_second': 1714.249, 'eval_steps_per_second': 6.791, 'epoch': 5.0}\n",
      "{'loss': 0.0045, 'learning_rate': 1.4082840236686392e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b951e28d034671a5b6bb1a161c8c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05154266580939293, 'eval_accuracy': 0.9889491242702252, 'eval_precision': 0.9889412399354953, 'eval_recall': 0.9889616477650689, 'eval_runtime': 5.5642, 'eval_samples_per_second': 1723.865, 'eval_steps_per_second': 6.829, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83124d0f8aeb45128079e1752dee1991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06003753840923309, 'eval_accuracy': 0.9888448707256047, 'eval_precision': 0.9888650554813643, 'eval_recall': 0.988889604825564, 'eval_runtime': 5.6857, 'eval_samples_per_second': 1687.036, 'eval_steps_per_second': 6.683, 'epoch': 7.0}\n",
      "{'loss': 0.0024, 'learning_rate': 1.2603550295857989e-05, 'epoch': 7.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54673e93593483198c94a1e49c3f5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05543595552444458, 'eval_accuracy': 0.9898874061718098, 'eval_precision': 0.9898796739475835, 'eval_recall': 0.9898991624932196, 'eval_runtime': 5.5439, 'eval_samples_per_second': 1730.191, 'eval_steps_per_second': 6.854, 'epoch': 8.0}\n",
      "{'loss': 0.002, 'learning_rate': 1.1124260355029586e-05, 'epoch': 8.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59762d2e5788432486a1ce8951891440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06708712875843048, 'eval_accuracy': 0.9892618849040867, 'eval_precision': 0.9892886124295824, 'eval_recall': 0.9893099495082037, 'eval_runtime': 5.5651, 'eval_samples_per_second': 1723.609, 'eval_steps_per_second': 6.828, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ec031d90de4eebb4a9504c9bb94a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07541047036647797, 'eval_accuracy': 0.9870725604670558, 'eval_precision': 0.9871345309939421, 'eval_recall': 0.9871345309939421, 'eval_runtime': 5.619, 'eval_samples_per_second': 1707.065, 'eval_steps_per_second': 6.763, 'epoch': 10.0}\n",
      "{'loss': 0.0012, 'learning_rate': 9.644970414201184e-06, 'epoch': 10.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734ce4e89c23483d8c0e532255c75835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.071197509765625, 'eval_accuracy': 0.9884278565471226, 'eval_precision': 0.9884656404772564, 'eval_recall': 0.9884808252738284, 'eval_runtime': 5.4984, 'eval_samples_per_second': 1744.515, 'eval_steps_per_second': 6.911, 'epoch': 11.0}\n",
      "{'loss': 0.0013, 'learning_rate': 8.165680473372781e-06, 'epoch': 11.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a2df2fa8f44492a3939e9ada501539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06961513310670853, 'eval_accuracy': 0.9886363636363636, 'eval_precision': 0.9886565457723374, 'eval_recall': 0.9886810846458017, 'eval_runtime': 5.5221, 'eval_samples_per_second': 1737.031, 'eval_steps_per_second': 6.881, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936e72c52dce4d9a89b95b742ff6aca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06995712220668793, 'eval_accuracy': 0.9896788990825688, 'eval_precision': 0.9896780943425059, 'eval_recall': 0.9897088160905927, 'eval_runtime': 5.6061, 'eval_samples_per_second': 1710.995, 'eval_steps_per_second': 6.778, 'epoch': 13.0}\n",
      "{'loss': 0.0005, 'learning_rate': 6.686390532544379e-06, 'epoch': 13.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a038e7675a7347b6ab07ea27d9e9a3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07335828989744186, 'eval_accuracy': 0.9902001668056714, 'eval_precision': 0.990201904110025, 'eval_recall': 0.9902325947823347, 'eval_runtime': 5.598, 'eval_samples_per_second': 1713.468, 'eval_steps_per_second': 6.788, 'epoch': 14.0}\n",
      "{'loss': 0.0006, 'learning_rate': 5.207100591715976e-06, 'epoch': 14.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c15ceceb4b4de192c900e9964b0800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07465539127588272, 'eval_accuracy': 0.9898874061718098, 'eval_precision': 0.9898965655987741, 'eval_recall': 0.9899255970781435, 'eval_runtime': 5.6172, 'eval_samples_per_second': 1707.6, 'eval_steps_per_second': 6.765, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748bc12a1f884372b6645a0559f18b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07487743347883224, 'eval_accuracy': 0.9894703919933278, 'eval_precision': 0.9894847267652335, 'eval_recall': 0.9895118610417348, 'eval_runtime': 5.6059, 'eval_samples_per_second': 1711.051, 'eval_steps_per_second': 6.779, 'epoch': 16.0}\n",
      "{'loss': 0.0005, 'learning_rate': 3.7278106508875745e-06, 'epoch': 16.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0d5f2ff5e34954803691fa8e7055b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06946327537298203, 'eval_accuracy': 0.9906171809841534, 'eval_precision': 0.990609223168855, 'eval_recall': 0.9906331135262815, 'eval_runtime': 5.6311, 'eval_samples_per_second': 1703.407, 'eval_steps_per_second': 6.748, 'epoch': 17.0}\n",
      "{'loss': 0.0004, 'learning_rate': 2.2485207100591717e-06, 'epoch': 17.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9f54c56e454989a850ce38ceb287ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06960413604974747, 'eval_accuracy': 0.9904086738949124, 'eval_precision': 0.9904080717309418, 'eval_recall': 0.9904080717309418, 'eval_runtime': 5.7661, 'eval_samples_per_second': 1663.521, 'eval_steps_per_second': 6.59, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fac10a8d9104fdaa3bf73811d2cec3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07140828669071198, 'eval_accuracy': 0.9905129274395329, 'eval_precision': 0.9905057929616341, 'eval_recall': 0.9905329838402948, 'eval_runtime': 5.5788, 'eval_samples_per_second': 1719.371, 'eval_steps_per_second': 6.812, 'epoch': 19.0}\n",
      "{'loss': 0.0002, 'learning_rate': 7.692307692307694e-07, 'epoch': 19.23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91aff1f2bf7d4a01ac6142402aafa6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07277266681194305, 'eval_accuracy': 0.9905129274395329, 'eval_precision': 0.9905072204963712, 'eval_recall': 0.9905362881634103, 'eval_runtime': 5.5657, 'eval_samples_per_second': 1723.403, 'eval_steps_per_second': 6.827, 'epoch': 20.0}\n",
      "{'train_runtime': 2528.4216, 'train_samples_per_second': 682.805, 'train_steps_per_second': 2.674, 'train_loss': 0.0021615763773491395, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b8cf8be0f24ab8a3770ee1b99a1c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.07277266681194305, 'eval_accuracy': 0.9905129274395329, 'eval_precision': 0.9905072204963712, 'eval_recall': 0.9905362881634103, 'eval_runtime': 5.6378, 'eval_samples_per_second': 1701.363, 'eval_steps_per_second': 6.74, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# trainer.train(resume_from_checkpoint=r\"logs/OtherModels/bert_ag_results/last_epoch\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(r\"logs/OtherModels/bert_ag_results/last_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation results: {'eval_loss': 0.07060451805591583, 'eval_accuracy': 0.9905251842751843, 'eval_precision': 0.9877763381021575, 'eval_recall': 0.9839378848819438, 'eval_runtime': 300.514, 'eval_samples_per_second': 216.695, 'eval_steps_per_second': 8.668, 'epoch': 5.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858533752195847"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.9877763381021575\n",
    "r = 0.9839378848819438\n",
    "(2*p*r)/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2654: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  66.96 M \n",
      "fwd MACs:                                                               5.51 GMACs\n",
      "fwd FLOPs:                                                              11.03 GFLOPS\n",
      "fwd+bwd MACs:                                                           16.54 GMACs\n",
      "fwd+bwd FLOPs:                                                          33.1 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "DistilBertForSequenceClassification(\n",
      "  66.96 M = 100% Params, 5.51 GMACs = 100% MACs, 11.03 GFLOPS = 100% FLOPs\n",
      "  (distilbert): DistilBertModel(\n",
      "    66.36 M = 99.11% Params, 5.51 GMACs = 99.98% MACs, 11.03 GFLOPS = 99.98% FLOPs\n",
      "    (embeddings): Embeddings(\n",
      "      23.84 M = 35.6% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs\n",
      "      (word_embeddings): Embedding(23.44 M = 35.01% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(393.22 K = 0.59% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 512, 768)\n",
      "      (LayerNorm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs, (768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      42.53 M = 63.51% Params, 5.51 GMACs = 99.98% MACs, 11.03 GFLOPS = 99.97% FLOPs\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          7.09 M = 10.59% Params, 918.55 MMACs = 16.66% MACs, 1.84 GFLOPS = 16.66% FLOPs\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            2.36 M = 3.53% Params, 314.57 MMACs = 5.71% MACs, 629.24 MFLOPS = 5.7% FLOPs\n",
      "            (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.1, inplace=False)\n",
      "            (q_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs, (768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            4.72 M = 7.05% Params, 603.98 MMACs = 10.96% MACs, 1.21 GFLOPS = 10.95% FLOPs\n",
      "            (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.1, inplace=False)\n",
      "            (lin1): Linear(2.36 M = 3.53% Params, 301.99 MMACs = 5.48% MACs, 603.98 MFLOPS = 5.47% FLOPs, in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(2.36 M = 3.52% Params, 301.99 MMACs = 5.48% MACs, 603.98 MFLOPS = 5.47% FLOPs, in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs, (768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(590.59 K = 0.88% Params, 1.18 MMACs = 0.02% MACs, 2.36 MFLOPS = 0.02% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(3.08 K = 0% Params, 6.14 KMACs = 0% MACs, 12.29 KFLOPS = 0% FLOPs, in_features=768, out_features=4, bias=True)\n",
      "  (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.2, inplace=False)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('11.03 GFLOPS', '5.51 GMACs', '66.96 M')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_flops(model, input_shape=(2, 64), transformer_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                                    FLOP    % Total\n",
      "---------------------------------------------------  ---------  ---------\n",
      "DistilBertForSequenceClassification                  5512.501M    100.00%\n",
      " - aten.addmm                                        5437.004M     98.63%\n",
      " - aten.bmm                                            75.497M      1.37%\n",
      " DistilBertForSequenceClassification.distilbert      5511.315M     99.98%\n",
      "  - aten.addmm                                       5435.818M     98.61%\n",
      "  - aten.bmm                                           75.497M      1.37%\n",
      " DistilBertForSequenceClassification.pre_classifier     1.180M      0.02%\n",
      "  - aten.addmm                                          1.180M      0.02%\n",
      " DistilBertForSequenceClassification.classifier         0.006M      0.00%\n",
      "  - aten.addmm                                          0.006M      0.00%\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, max_length=64, truncation=True, padding='max_length', return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "flopt_counter = FlopCounterMode(model)\n",
    "with flopt_counter:\n",
    "    model(**encoded_input)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 612351,
     "sourceId": 1095715,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
