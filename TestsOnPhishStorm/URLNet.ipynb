{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0hDf2T3HnQy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eWxRbWhWHMaQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from bisect import bisect_left\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from pathlib import Path\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "import itertools\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from bisect import bisect_left\n",
        "import torch\n",
        "import torch\n",
        "import time\n",
        "import sys\n",
        "import pandas as pd\n",
        "from torch.utils.flop_counter import FlopCounterMode\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pt-0PhoTHdic"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "    class VocabFactory():\n",
        "\n",
        "        def __init__(self, tokenizer) -> None:\n",
        "            self.tokens_dict = {}\n",
        "            self.tokenizer = tokenizer\n",
        "            self.vocab_id = {}\n",
        "            self.id_vocab = {}\n",
        "\n",
        "        def create_vocab(self, texts, vocab_count=0):\n",
        "            i = 0\n",
        "            self.tokens_dict['❿'] = sys.maxsize\n",
        "\n",
        "            for text in texts:\n",
        "                if i %100000 == 0:\n",
        "                    print(i)\n",
        "                i+=1\n",
        "\n",
        "                tokens = list(self.tokenizer(text))\n",
        "                for token in tokens:\n",
        "                    # token = self.tokenizer(token)\n",
        "                    if token not in self.tokens_dict:\n",
        "                        self.tokens_dict[token] = 0\n",
        "                    self.tokens_dict[token] += 1\n",
        "            self.finalize(vocab_count)\n",
        "\n",
        "        def finalize(self, vocab_count=0):\n",
        "            all_tokens = pd.DataFrame({'tokens': list(self.tokens_dict.keys()), 'counts': list(self.tokens_dict.values())})\n",
        "            all_tokens = all_tokens.sort_values(by=['counts'], ascending=False)\n",
        "            tokens = all_tokens['tokens'].values\n",
        "            if vocab_count != 0:\n",
        "                tokens = tokens[:vocab_count]\n",
        "            self.vocab_id = {t: i for i, t in enumerate(tokens)}\n",
        "            self.id_vocab = {i: t for i, t in enumerate(tokens)}\n",
        "\n",
        "    def read_data(file_dir):\n",
        "        with open(file_dir) as file:\n",
        "            urls = []\n",
        "            labels = []\n",
        "            for line in file.readlines():\n",
        "                items = line.split('\\t')\n",
        "                label = int(items[0])\n",
        "                if label == 1:\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    labels.append(0)\n",
        "                url = items[1][:-1]\n",
        "                urls.append(url)\n",
        "        return urls, labels\n",
        "\n",
        "    def split_url(line, part):\n",
        "        if line.startswith(\"http://\"):\n",
        "            line=line[7:]\n",
        "        if line.startswith(\"https://\"):\n",
        "            line=line[8:]\n",
        "        if line.startswith(\"ftp://\"):\n",
        "            line=line[6:]\n",
        "        if line.startswith(\"www.\"):\n",
        "            line = line[4:]\n",
        "        slash_pos = line.find('/')\n",
        "        if slash_pos > 0 and slash_pos < len(line)-1: # line = \"fsdfsdf/sdfsdfsd\"\n",
        "            primarydomain = line[:slash_pos]\n",
        "            path_argument = line[slash_pos+1:]\n",
        "            path_argument_tokens = path_argument.split('/')\n",
        "            pathtoken = \"/\".join(path_argument_tokens[:-1])\n",
        "            last_pathtoken = path_argument_tokens[-1]\n",
        "            if len(path_argument_tokens) > 2 and last_pathtoken == '':\n",
        "                pathtoken = \"/\".join(path_argument_tokens[:-2])\n",
        "                last_pathtoken = path_argument_tokens[-2]\n",
        "            question_pos = last_pathtoken.find('?')\n",
        "            if question_pos != -1:\n",
        "                argument = last_pathtoken[question_pos+1:]\n",
        "                pathtoken = pathtoken + \"/\" + last_pathtoken[:question_pos]\n",
        "            else:\n",
        "                argument = \"\"\n",
        "                pathtoken = pathtoken + \"/\" + last_pathtoken\n",
        "            last_slash_pos = pathtoken.rfind('/')\n",
        "            sub_dir = pathtoken[:last_slash_pos]\n",
        "            filename = pathtoken[last_slash_pos+1:]\n",
        "            file_last_dot_pos = filename.rfind('.')\n",
        "            if file_last_dot_pos != -1:\n",
        "                file_extension = filename[file_last_dot_pos+1:]\n",
        "                filename = filename[:file_last_dot_pos]\n",
        "            else:\n",
        "                file_extension = \"\"\n",
        "        elif slash_pos == 0:    # line = \"/fsdfsdfsdfsdfsd\"\n",
        "            primarydomain = line[1:]\n",
        "            pathtoken = \"\"\n",
        "            argument = \"\"\n",
        "            sub_dir = \"\"\n",
        "            filename = \"\"\n",
        "            file_extension = \"\"\n",
        "        elif slash_pos == len(line)-1:   # line = \"fsdfsdfsdfsdfsd/\"\n",
        "            primarydomain = line[:-1]\n",
        "            pathtoken = \"\"\n",
        "            argument = \"\"\n",
        "            sub_dir = \"\"\n",
        "            filename = \"\"\n",
        "            file_extension = \"\"\n",
        "        else:      # line = \"fsdfsdfsdfsdfsd\"\n",
        "            primarydomain = line\n",
        "            pathtoken = \"\"\n",
        "            argument = \"\"\n",
        "            sub_dir = \"\"\n",
        "            filename = \"\"\n",
        "            file_extension = \"\"\n",
        "        if part == 'pd':\n",
        "            return primarydomain\n",
        "        elif part == 'path':\n",
        "            return pathtoken\n",
        "        elif part == 'argument':\n",
        "            return argument\n",
        "        elif part == 'sub_dir':\n",
        "            return sub_dir\n",
        "        elif part == 'filename':\n",
        "            return filename\n",
        "        elif part == 'fe':\n",
        "            return file_extension\n",
        "        elif part == 'others':\n",
        "            if len(argument) > 0:\n",
        "                return pathtoken + '?' +  argument\n",
        "            else:\n",
        "                return pathtoken\n",
        "        else:\n",
        "            return primarydomain, pathtoken, argument, sub_dir, filename, file_extension\n",
        "\n",
        "    def get_word_vocab(urls, max_length_words, tokenizer, min_word_freq=0):\n",
        "        vocab_factory = VocabFactory(tokenizer)\n",
        "        vocab_factory.create_vocab(urls)\n",
        "        vocab_id = vocab_factory.vocab_id\n",
        "        start = time.time()\n",
        "        tokenized_texts = [tokenizer(text) for text in urls]\n",
        "        x = ([torch.tensor([vocab_id[token] for token in t_text]) for t_text in tokenized_texts])\n",
        "        x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=0)[:,:max_length_words]\n",
        "        print(\"Finished build vocabulary and mapping to x in {}\".format(time.time() - start))\n",
        "        vocab_dict = vocab_factory.vocab_id\n",
        "        reverse_dict = vocab_factory.id_vocab\n",
        "        print(\"Size of word vocabulary: {}\".format(len(reverse_dict)))\n",
        "        return x, reverse_dict\n",
        "\n",
        "    def get_words(x, reverse_dict, delimit_mode, urls=None):\n",
        "        processed_x = []\n",
        "        if delimit_mode == 0:\n",
        "            for url in x:\n",
        "                words = []\n",
        "                for word_id in url:\n",
        "                    if word_id.item() != 0:\n",
        "                        words.append(reverse_dict[word_id.item()])\n",
        "                    else:\n",
        "                        break\n",
        "                processed_x.append(words)\n",
        "        elif delimit_mode == 1:\n",
        "            for i in range(x.shape[0]):\n",
        "                word_url = x[i]\n",
        "                raw_url = urls[i]\n",
        "                words = []\n",
        "                for w in range(len(word_url)):\n",
        "                    word_id = word_url[w]\n",
        "                    if word_id.item() == 0:\n",
        "                        words.extend(list(raw_url))\n",
        "                        break\n",
        "                    else:\n",
        "                        word = reverse_dict[word_id.item()]\n",
        "                        idx = raw_url.index(word)\n",
        "                        special_chars = list(raw_url[0:idx])\n",
        "                        words.extend(special_chars)\n",
        "                        words.append(word)\n",
        "                        raw_url = raw_url[idx+len(word):]\n",
        "                        if w == len(word_url) - 1:\n",
        "                            words.extend(list(raw_url))\n",
        "                processed_x.append(words)\n",
        "        return processed_x\n",
        "\n",
        "    def get_char_ngrams(ngram_len, word):\n",
        "        word = f\"<{word}>\"\n",
        "        return [word[i:i + ngram_len] for i in range(len(word) - ngram_len + 1)]\n",
        "\n",
        "    def char_id_x(urls, char_dict, max_len_chars):\n",
        "        chidx = [min(len(url), max_len_chars) for url in urls]\n",
        "        chared_id_x = [torch.from_numpy(np.array([char_dict[url[i]] if url[i] in char_dict else 0 for i in range(chidx[l])])) for l, url in enumerate(urls)]\n",
        "        chared_id_x = torch.nn.utils.rnn.pad_sequence(chared_id_x, batch_first=True, padding_value=char_dict['❿'])\n",
        "        return chared_id_x\n",
        "\n",
        "    def ngram_id_x_dicts(word_x, max_len_subwords, high_freq_words=None):\n",
        "        char_ngram_len = 1\n",
        "        all_ngrams = set()\n",
        "        ngramed_x = []\n",
        "        all_words = set()\n",
        "        worded_x = []\n",
        "        counter = 0\n",
        "        for counter, url in enumerate(word_x):\n",
        "            if counter % 100000 == 0:\n",
        "                print(\"Processing #url {}\".format(counter))\n",
        "            url_in_ngrams = []\n",
        "            url_in_words = []\n",
        "            for word in url:\n",
        "                ngrams = get_char_ngrams(char_ngram_len, word)\n",
        "                if (len(ngrams) > max_len_subwords) or \\\n",
        "                    (high_freq_words is not None and len(word)>1 and not is_in(high_freq_words, word)):\n",
        "                    ngram_slice = ngrams[:max_len_subwords]\n",
        "                    all_ngrams.update(ngram_slice)\n",
        "                    url_in_ngrams.append(ngram_slice)\n",
        "                    all_words.add(\"<UNKNOWN>\")\n",
        "                    url_in_words.append(\"<UNKNOWN>\")\n",
        "                else:\n",
        "                    all_ngrams.update(ngrams)\n",
        "                    url_in_ngrams.append(ngrams)\n",
        "                    all_words.add(word)\n",
        "                    url_in_words.append(word)\n",
        "            ngramed_x.append(url_in_ngrams)\n",
        "            worded_x.append(url_in_words)\n",
        "        print(\"worded_x completed\")\n",
        "        all_ngrams = ['❿'] + list(all_ngrams)\n",
        "        ngrams_dict = {ngram: i + 1 for i, ngram in enumerate(all_ngrams)}\n",
        "\n",
        "        print(\"ngrams_dict completed\")\n",
        "        all_words = list(all_words)\n",
        "        words_dict = {word: i + 1 for i, word in enumerate(all_words)}\n",
        "        \n",
        "        return ngrams_dict, words_dict, ngramed_x, worded_x\n",
        "\n",
        "    def ngram_id_x(ngrams_dict, words_dict, ngramed_x, worded_x, max_len_subwords):\n",
        "        print(\"words_dict completed\")\n",
        "\n",
        "        fill_char = ngrams_dict['❿']\n",
        "        ngramed_id_x = [\n",
        "            [\n",
        "                [\n",
        "                    ngrams_dict[ngram] for ngram in ngramed_word[:max_len_subwords]\n",
        "                ] + [fill_char] * max(0, max_len_subwords - len(ngramed_word))\n",
        "                for ngramed_word in ngramed_url\n",
        "            ]\n",
        "            for ngramed_url in ngramed_x\n",
        "        ]\n",
        "        ngramed_id_x = torch.from_numpy(np.array(ngramed_id_x))\n",
        "        print(\"ngramed_id_x completed\")\n",
        "        worded_id_x = [\n",
        "            [words_dict[word] for word in worded_url]\n",
        "            for worded_url in worded_x\n",
        "        ]\n",
        "        worded_id_x = torch.from_numpy(np.array(worded_id_x))\n",
        "\n",
        "        print(\"worded_id_x completed\")\n",
        "        return ngramed_id_x, worded_id_x\n",
        "\n",
        "    def ngram_id_x_from_dict(word_x, max_len_subwords, ngram_dict, word_dict = None):\n",
        "        char_ngram_len = 1\n",
        "        print(\"Index of <UNKNOWN> word: {}\".format(word_dict[\"<UNKNOWN>\"]))\n",
        "        ngramed_id_x = []\n",
        "        worded_id_x = []\n",
        "        counter = 0\n",
        "        if word_dict:\n",
        "            word_vocab = sorted(list(word_dict.keys()))\n",
        "        for url in word_x:\n",
        "            if counter % 100000 == 0:\n",
        "                print(\"Processing url #{}\".format(counter))\n",
        "            counter += 1\n",
        "            url_in_ngrams = []\n",
        "            url_in_words = []\n",
        "            words = url\n",
        "            for word in words:\n",
        "                ngrams = get_char_ngrams(char_ngram_len, word)\n",
        "                if len(ngrams) > max_len_subwords:\n",
        "                    word = \"<UNKNOWN>\"\n",
        "                ngrams_id = []\n",
        "                for ngram in ngrams:\n",
        "                    if ngram in ngram_dict:\n",
        "                        ngrams_id.append(ngram_dict[ngram])\n",
        "                    else:\n",
        "                        ngrams_id.append(0)\n",
        "                url_in_ngrams.append(ngrams_id)\n",
        "                if is_in(word_vocab, word):\n",
        "                    word_id = word_dict[word]\n",
        "                else:\n",
        "                    word_id = word_dict[\"<UNKNOWN>\"]\n",
        "                url_in_words.append(word_id)\n",
        "            ngramed_id_x.append(url_in_ngrams)\n",
        "            worded_id_x.append(url_in_words)\n",
        "\n",
        "        return ngramed_id_x, worded_id_x\n",
        "\n",
        "    def bisect_search(a,x):\n",
        "        i = bisect_left(a,x)\n",
        "        if i != len(a) and a[i] == x:\n",
        "            return i\n",
        "        raise ValueError\n",
        "\n",
        "    def is_in(a,x):\n",
        "        i = bisect_left(a,x)\n",
        "        if i != len(a) and a[i] == x:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def prep_train_test(pos_x, neg_x, dev_pct):\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices=np.random.permutation(np.arange(len(pos_x)))\n",
        "        pos_x_shuffled = pos_x[shuffle_indices]\n",
        "        dev_idx = -1 * int(dev_pct * float(len(pos_x)))\n",
        "        pos_train = pos_x_shuffled[:dev_idx]\n",
        "        pos_test = pos_x_shuffled[dev_idx:]\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices=np.random.permutation(np.arange(len(neg_x)))\n",
        "        neg_x_shuffled = neg_x[shuffle_indices]\n",
        "        dev_idx = -1 * int(dev_pct * float(len(neg_x)))\n",
        "        neg_train = neg_x_shuffled[:dev_idx]\n",
        "        neg_test = neg_x_shuffled[dev_idx:]\n",
        "\n",
        "        x_train = torch.from_numpy(np.array(list(pos_train) + list(neg_train)))\n",
        "        y_train = len(pos_train)*[1] + len(neg_train)*[0]\n",
        "        x_test = torch.from_numpy(np.array(list(pos_test) + list(neg_test)))\n",
        "        y_test = len(pos_test)*[1] + len(neg_test)*[0]\n",
        "\n",
        "        y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=2).float()\n",
        "        y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=2).float()\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_train)))\n",
        "        x_train = x_train[shuffle_indices]\n",
        "        y_train = y_train[shuffle_indices]\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_test)))\n",
        "        x_test = x_test[shuffle_indices]\n",
        "        y_test = y_test[shuffle_indices]\n",
        "\n",
        "        print(\"Train Mal/Ben split: {}/{}\".format(len(pos_train), len(neg_train)))\n",
        "        print(\"Test Mal/Ben split: {}/{}\".format(len(pos_test), len(neg_test)))\n",
        "        print(\"Train/Test split: {}/{}\".format(len(y_train), len(y_test)))\n",
        "        print(\"Train/Test split: {}/{}\".format(len(x_train), len(x_test)))\n",
        "\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "    def prep_train_test2(grouped_ids, dev_pct):\n",
        "\n",
        "        np.random.seed(10)\n",
        "        train_ids = []\n",
        "        test_ids = []\n",
        "\n",
        "        for ids in grouped_ids:\n",
        "            shuffle_indices=np.random.permutation(np.arange(len(ids)))\n",
        "            ids_shuffled = ids[shuffle_indices]\n",
        "            dev_idx = -1 * int(dev_pct * float(len(ids)))\n",
        "            ids_train = ids_shuffled[:dev_idx]\n",
        "            ids_test = ids_shuffled[dev_idx:]\n",
        "            train_ids.append(ids_train)\n",
        "            test_ids.append(ids_test)\n",
        "        y_train = [len(train_ids[i]) * [i] for i in range(len(train_ids))]\n",
        "        y_test = [len(test_ids[i]) * [i] for i in range(len(test_ids))]\n",
        "        y_train = list(itertools.chain.from_iterable(y_train))\n",
        "        y_test = list(itertools.chain.from_iterable(y_test))\n",
        "        x_train = torch.tensor(list(itertools.chain.from_iterable(train_ids)))\n",
        "        x_test = torch.tensor(list(itertools.chain.from_iterable(test_ids)))\n",
        "\n",
        "        y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=len(grouped_ids)).float()\n",
        "        y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=len(grouped_ids)).float()\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_train)))\n",
        "        x_train = x_train[shuffle_indices]\n",
        "        y_train = y_train[shuffle_indices]\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_test)))\n",
        "        x_test = x_test[shuffle_indices]\n",
        "        y_test = y_test[shuffle_indices]\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "    def get_ngramed_id_x(x_idxs, ngramed_id_x):\n",
        "        output_ngramed_id_x = []\n",
        "        for idx in x_idxs:\n",
        "            output_ngramed_id_x.append(ngramed_id_x[idx])\n",
        "        return torch.stack(output_ngramed_id_x)\n",
        "\n",
        "    def pad_seq(urls, max_d1=0, max_d2=0, embedding_size=128):\n",
        "        if max_d1 == 0 and max_d2 == 0:\n",
        "            for url in urls:\n",
        "                if len(url) > max_d1:\n",
        "                    max_d1 = len(url)\n",
        "                for word in url:\n",
        "                    if len(word) > max_d2:\n",
        "                        max_d2 = len(word)\n",
        "        pad_idx = np.zeros((len(urls), max_d1, max_d2, embedding_size))\n",
        "        pad_urls = np.zeros((len(urls), max_d1, max_d2))\n",
        "        pad_vec = [1 for i in range(embedding_size)]\n",
        "        for d0 in range(len(urls)):\n",
        "            url = urls[d0]\n",
        "            for d1 in range(len(url)):\n",
        "                if d1 < max_d1:\n",
        "                    word = url[d1]\n",
        "                    for d2 in range(len(word)):\n",
        "                        if d2 < max_d2:\n",
        "                            pad_urls[d0,d1,d2] = word[d2]\n",
        "                            pad_idx[d0,d1,d2] = pad_vec\n",
        "        return pad_urls, pad_idx\n",
        "\n",
        "    def pad_seq_in_word(urls, max_d1=0, embedding_size=128):\n",
        "        if max_d1 == 0:\n",
        "            url_lens = [len(url) for url in urls]\n",
        "            max_d1 = max(url_lens)\n",
        "        pad_urls = np.zeros((len(urls), max_d1))\n",
        "        #pad_idx = np.zeros((len(urls), max_d1, embedding_size))\n",
        "        #pad_vec = [1 for i in range(embedding_size)]\n",
        "        for d0 in range(len(urls)):\n",
        "            url = urls[d0]\n",
        "            for d1 in range(len(url)):\n",
        "                if d1 < max_d1:\n",
        "                    pad_urls[d0,d1] = url[d1]\n",
        "                    #pad_idx[d0,d1] = pad_vec\n",
        "        return pad_urls\n",
        "\n",
        "    def softmax(x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / e_x.sum()\n",
        "\n",
        "    def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
        "        data = np.array(data)\n",
        "        data_size = len(data)\n",
        "        num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
        "        for epoch in range(num_epochs):\n",
        "            if shuffle:\n",
        "                shuffle_indices = np.random.permutation(np.arange(data_size))\n",
        "                shuffled_data = data[shuffle_indices]\n",
        "            else:\n",
        "                shuffled_data = data\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_idx = batch_num * batch_size\n",
        "                end_idx = min((batch_num+1) * batch_size, data_size)\n",
        "                yield shuffled_data[start_idx:end_idx]\n",
        "\n",
        "    def save_test_result(labels, all_predictions, all_scores, output_dir):\n",
        "        output_labels = []\n",
        "        for i in labels:\n",
        "            if i == 1:\n",
        "                output_labels.append(i)\n",
        "            else:\n",
        "                output_labels.append(-1)\n",
        "        output_preds = []\n",
        "        for i in all_predictions:\n",
        "            if i == 1:\n",
        "                output_preds.append(i)\n",
        "            else:\n",
        "                output_preds.append(-1)\n",
        "        softmax_scores = [softmax(i) for i in all_scores]\n",
        "        with open(output_dir, \"w\") as file:\n",
        "            output = \"label\\tpredict\\tscore\\n\"\n",
        "            file.write(output)\n",
        "            for i in range(len(output_labels)):\n",
        "                output = str(int(output_labels[i])) + '\\t' + str(int(output_preds[i])) + '\\t' + str(softmax_scores[i][1]) + '\\n'\n",
        "                file.write(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ssW6FE5kHMah"
      },
      "outputs": [],
      "source": [
        "def prep_train_test2(grouped_ids, dev_pct):\n",
        "\n",
        "    np.random.seed(10)\n",
        "    train_ids = []\n",
        "    test_ids = []\n",
        "\n",
        "    for ids in grouped_ids:\n",
        "        shuffle_indices=np.random.permutation(np.arange(len(ids)))\n",
        "        ids_shuffled = ids[shuffle_indices]\n",
        "        dev_idx = -1 * int(dev_pct * float(len(ids)))\n",
        "        ids_train = ids_shuffled[:dev_idx]\n",
        "        ids_test = ids_shuffled[dev_idx:]\n",
        "        train_ids.append(ids_train)\n",
        "        test_ids.append(ids_test)\n",
        "    y_train = [len(train_ids[i]) * [i] for i in range(len(train_ids))]\n",
        "    y_test = [len(test_ids[i]) * [i] for i in range(len(test_ids))]\n",
        "    y_train = list(itertools.chain.from_iterable(y_train))\n",
        "    y_test = list(itertools.chain.from_iterable(y_test))\n",
        "    x_train = torch.tensor(list(itertools.chain.from_iterable(train_ids)))\n",
        "    x_test = torch.tensor(list(itertools.chain.from_iterable(test_ids)))\n",
        "\n",
        "    y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=len(grouped_ids)).float()\n",
        "    y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=len(grouped_ids)).float()\n",
        "\n",
        "    np.random.seed(10)\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(x_train)))\n",
        "    x_train = x_train[shuffle_indices]\n",
        "    y_train = y_train[shuffle_indices]\n",
        "\n",
        "    np.random.seed(10)\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(x_test)))\n",
        "    x_test = x_test[shuffle_indices]\n",
        "    y_test = y_test[shuffle_indices]\n",
        "\n",
        "    # print(\"Train Mal/Ben split: {}/{}\".format(len(pos_train), len(neg_train)))\n",
        "    # print(\"Test Mal/Ben split: {}/{}\".format(len(pos_test), len(neg_test)))\n",
        "    # print(\"Train/Test split: {}/{}\".format(len(y_train), len(y_test)))\n",
        "    # print(\"Train/Test split: {}/{}\".format(len(x_train), len(x_test)))\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIMqO3YzHMaW",
        "outputId": "ac51b1d4-1c62-4b2f-c406-8a81b2db8d28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF1H4B-wHtt4"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kmy_PwTCHMaY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_7440\\1177306604.py:1: ParserWarning: Skipping line 18259: expected 14 fields, saw 15\n",
            "Skipping line 18273: expected 14 fields, saw 15\n",
            "\n",
            "  df = pd.read_csv(r\"datasets\\PhishStorm\\urlset.csv\", on_bad_lines='warn', encoding = 'ISO-8859-1', low_memory=False)[['domain','label']]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(r\"datasets\\PhishStorm\\urlset.csv\", on_bad_lines='warn', encoding = 'ISO-8859-1', low_memory=False)[['domain','label']]\n",
        "df.dropna(inplace=True)\n",
        "df.columns = ['url', 'Topic']\n",
        "class_list = ['benign', 'phishing']\n",
        "class_id = {'benign':0, 'phishing': 1}\n",
        "id_class = {0: 'benign', 1:'phishing'}\n",
        "df['label'] = df.Topic#.apply(lambda t: class_id[t])\n",
        "urls = df[\"url\"].values\n",
        "labels = df[\"label\"].values.astype(np.longlong)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWheAfCuHMaZ",
        "outputId": "88a5e2ad-38f8-400e-af44-19037fe6d41a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IyXEb4IxHMaa"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "    default_max_len_words = 200\n",
        "    max_len_words = default_max_len_words\n",
        "    default_max_len_chars = 200\n",
        "    max_len_chars = default_max_len_chars\n",
        "    default_max_len_subwords = 20\n",
        "    max_len_subwords = default_max_len_subwords\n",
        "    default_min_word_freq = 1\n",
        "    min_word_freq = default_min_word_freq\n",
        "\n",
        "    default_delimit_mode = 1\n",
        "    delimit_mode = default_delimit_mode\n",
        "    default_max_len_words = 200\n",
        "    max_len_words = default_max_len_words\n",
        "    default_max_len_chars = 200\n",
        "    max_len_chars = default_max_len_chars\n",
        "    default_max_len_subwords = 20\n",
        "    max_len_subwords = default_max_len_subwords\n",
        "    default_min_word_freq = 1\n",
        "    min_word_freq = default_min_word_freq\n",
        "    default_dev_pct = 0.001\n",
        "    dev_pct=0.1 # default_dev_pct\n",
        "\n",
        "    # model args\n",
        "    default_emb_dim = 32\n",
        "    emb_dim = default_emb_dim\n",
        "    default_filter_sizes = \"3,4,5,6\"\n",
        "    filter_sizes = default_filter_sizes\n",
        "    default_emb_mode = 5\n",
        "    emb_mode = default_emb_mode\n",
        "\n",
        "    # train args\n",
        "    default_nb_epochs = 5\n",
        "    nb_epochs = default_nb_epochs\n",
        "    default_batch_size = 1024\n",
        "    batch_size = default_batch_size\n",
        "    l2_reg_lambda = 0.0\n",
        "    default_lr = 0.001\n",
        "    lr = default_lr\n",
        "\n",
        "    # log args\n",
        "    output_dir = r\"scripts\\URLNet\\outputs\"\n",
        "    print_every = 50\n",
        "    eval_every = 500\n",
        "    checkpoint_every = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVe58FCiHMab",
        "outputId": "dc79a03f-691d-4770-d820-299ad11d9f7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['uk', 'linkedin', 'com', 'pub', 'steve-rubenstein', '8', '718', '755']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "class SepTokenizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.splitter = re.compile(r'[/?.=-_]+')\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.splitter.split(text)\n",
        "\n",
        "tokenizer = SepTokenizer()\n",
        "tokenizer('uk.linkedin.com/pub/steve-rubenstein/8/718/755')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "high_freq_words = None\n",
        "curpath = os.path.abspath(os.curdir)\n",
        "abs_path = os.path.join(curpath, r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\word_x.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ODfM1_CPS_MY"
      },
      "outputs": [],
      "source": [
        "if Path(r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\word_x.pkl\").is_file():\n",
        "  with open(fr'{abs_path}', 'rb') as f:\n",
        "    word_x2 = pickle.load(f)\n",
        "else:\n",
        "  x, word_reverse_dict = get_word_vocab(urls[:], max_len_words, tokenizer)\n",
        "  word_x2 = get_words(x, word_reverse_dict, delimit_mode, urls)\n",
        "  for i in range(len(word_x2)):\n",
        "    if i%100000==0:\n",
        "      print(i)\n",
        "    if len(word_x2[i])> max_len_words:\n",
        "        word_x2[i] = word_x2[i][:max_len_words]\n",
        "    while len(word_x2[i]) < max_len_words:\n",
        "        word_x2[i].append('❿')\n",
        "  clear_output()\n",
        "  with open(fr'{abs_path}', 'wb') as f:\n",
        "    pickle.dump(word_x2, f)\n",
        "\n",
        "if Path(r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\ngrams_dict.pkl\").is_file():\n",
        "  with open(os.path.join(curpath, r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\ngrams_dict.pkl\"), 'rb') as f:\n",
        "    ngrams_dict = pickle.load(f)\n",
        "  with open(os.path.join(curpath, r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\words_dict.pkl\"), 'rb') as f:\n",
        "    words_dict = pickle.load(f)\n",
        "else:\n",
        "  ngrams_dict, words_dict, ngramed_x, worded_x = ngram_id_x_dicts(word_x2, max_len_subwords, high_freq_words)\n",
        "  with open(os.path.join(curpath, r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\ngrams_dict.pkl\"), 'wb') as f:\n",
        "    pickle.dump(ngrams_dict, f)\n",
        "  with open(os.path.join(curpath, r\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\words_dict.pkl\"), 'wb') as f:\n",
        "    pickle.dump(words_dict, f)\n",
        "    \n",
        "chars_dict = ngrams_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if Path(rf\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\chared_id_x.pt\").is_file():\n",
        "    chared_id_x = torch.load(rf'TestsOnPhishStorm\\tempURLNET\\ProcessedData\\chared_id_x.pt')\n",
        "else:\n",
        "    chared_id_x = char_id_x(urls, chars_dict, max_len_chars)\n",
        "    torch.save(chared_id_x, rf'TestsOnPhishStorm\\tempURLNET\\ProcessedData\\chared_id_x.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_x3 = word_x2[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngramed_id_x = torch.zeros((len(word_x2), len(word_x2[0]), max_len_subwords), dtype=torch.int32)\n",
        "worded_id_x = torch.zeros((len(word_x2), len(word_x2[0])), dtype=torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "0 50000\n",
            "True\n",
            "50000 95913\n"
          ]
        }
      ],
      "source": [
        "intervals = 50000\n",
        "previous = 0\n",
        "for i in range(intervals, len(word_x3)+intervals, intervals):\n",
        "    i = min(i, len(word_x3))\n",
        "    if Path(rf\"TestsOnPhishStorm\\tempURLNET\\ProcessedData\\ngramed_id_x_{previous}_{i}.pt\").is_file():\n",
        "        print(\"True\")\n",
        "        ngramed_id_x[previous:i] = torch.load(rf'TestsOnPhishStorm\\tempURLNET\\ProcessedData\\ngramed_id_x_{previous}_{i}.pt')\n",
        "        worded_id_x[previous:i] = torch.load(rf'TestsOnPhishStorm\\tempURLNET\\ProcessedData\\worded_id_x_{previous}_{i}.pt')\n",
        "    else:\n",
        "        print(\"False\")\n",
        "        word_x = word_x3[previous:i]\n",
        "        _, _, ngramed_x, worded_x = ngram_id_x_dicts(word_x, max_len_subwords, high_freq_words)\n",
        "        ngramed_id_x[previous:i], worded_id_x[previous:i] = ngram_id_x(ngrams_dict, words_dict, ngramed_x, worded_x, max_len_subwords)\n",
        "        torch.save(ngramed_id_x[previous:i], rf'TestsOnPhishStorm\\tempURLNET\\ProcessedData\\ngramed_id_x_{previous}_{i}.pt')\n",
        "        torch.save(worded_id_x[previous:i], rf'TestsOnPhishStorm\\tempURLNET\\ProcessedData\\worded_id_x_{previous}_{i}.pt')\n",
        "    \n",
        "    print(previous, i)\n",
        "    previous = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "524CQoBgHMah",
        "outputId": "ddc5f15f-d3a7-4f36-d81a-90a1e95402db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall benign/phishing split: 48009/47904\n"
          ]
        }
      ],
      "source": [
        "y_splits = [[] for i in range(len(class_list))]\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    y_splits[labels[i]].append(i)\n",
        "\n",
        "y_splits = [np.array(splt) for splt in y_splits]\n",
        "\n",
        "\n",
        "print(f\"Overall {class_list[0]}/{class_list[1]} split: {len(y_splits[0])}/{len(y_splits[1])}\")\n",
        "\n",
        "x_train, y, x_test, y_test = prep_train_test2(y_splits, dev_pct)\n",
        "\n",
        "x_char = get_ngramed_id_x(x_train, ngramed_id_x)\n",
        "x_test_char = get_ngramed_id_x(x_test, ngramed_id_x)\n",
        "\n",
        "x_word = get_ngramed_id_x(x_train, worded_id_x)\n",
        "x_test_word = get_ngramed_id_x(x_test, worded_id_x)\n",
        "\n",
        "x_char_seq = get_ngramed_id_x(x_train, chared_id_x)\n",
        "x_test_char_seq = get_ngramed_id_x(x_test, chared_id_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaCGcTlWHMai",
        "outputId": "cc14ab35-cd55-4c94-d6cb-b35b8aafae8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(np.sum(~(labels[x_test] == np.argmax(y_test.numpy(), axis=1))))\n",
        "print(np.sum(~(labels[x_train] == np.argmax(y.numpy(), axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hdP9xhsUHMai"
      },
      "outputs": [],
      "source": [
        "class URLNetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, emb_mode, x_char_seq, x_word, x_char, y) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if emb_mode == 1:\n",
        "            self.dataset = TensorDataset(x_char_seq, y)\n",
        "        elif emb_mode == 2:\n",
        "            self.dataset = TensorDataset(x_word, y)\n",
        "        elif emb_mode == 3:\n",
        "            self.dataset = TensorDataset(x_char_seq, x_word, y)\n",
        "        elif emb_mode == 4:\n",
        "            self.dataset = TensorDataset(x_word, x_char, y) #, char_pad_idx\n",
        "        elif emb_mode == 5:\n",
        "            self.dataset = TensorDataset(x_char_seq, x_word, x_char, y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VZF6MjQcHMaj"
      },
      "outputs": [],
      "source": [
        "train_dataset = URLNetDataset(emb_mode, x_char_seq, x_word, x_char, y)\n",
        "test_dataset = URLNetDataset(emb_mode, x_test_char_seq, x_test_word, x_test_char, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EvvgsvbsHMaj"
      },
      "outputs": [],
      "source": [
        "_ = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "A22F6ELOHMak"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, char_ngram_vocab_size, word_ngram_vocab_size, char_vocab_size,\n",
        "                 word_seq_len, char_seq_len, embedding_size, l2_reg_lambda=0,\n",
        "                 filter_sizes=[3, 4, 5, 6], mode=0, num_classes=2):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.word_seq_len = word_seq_len\n",
        "        self.char_seq_len = char_seq_len\n",
        "        self.embedding_size = embedding_size\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        if mode in [4, 5]:\n",
        "            self.char_embedding = nn.Embedding(char_ngram_vocab_size+1, embedding_size)\n",
        "            torch.nn.init.uniform_(self.char_embedding.weight)\n",
        "        if mode in [2, 3, 4, 5]:\n",
        "            self.word_embedding = nn.Embedding(word_ngram_vocab_size+1, embedding_size)\n",
        "            torch.nn.init.uniform_(self.word_embedding.weight)\n",
        "        if mode in [1, 3, 5]:\n",
        "            self.char_seq_embedding = nn.Embedding(char_vocab_size+1, embedding_size)\n",
        "            torch.nn.init.uniform_(self.char_seq_embedding.weight)\n",
        "\n",
        "        self.dropout_keep_prob = nn.Dropout(0.5)\n",
        "        self.num_filters_total = 256 * len(filter_sizes)\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        for filter_size in filter_sizes:\n",
        "            conv = nn.Conv1d(embedding_size, 256, filter_size, padding=\"valid\")\n",
        "            nn.init.trunc_normal_(conv.weight, std=0.1)\n",
        "            nn.init.constant_(conv.bias, 0.1)\n",
        "            self.conv_layers.append(conv)\n",
        "\n",
        "        if mode in [3, 5]:\n",
        "            self.fc_word = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "            torch.nn.init.xavier_normal_(self.fc_word.weight)\n",
        "            torch.nn.init.constant_(self.fc_word.bias, 0.1)\n",
        "            self.fc_char = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "            torch.nn.init.xavier_normal_(self.fc_char.weight)\n",
        "            torch.nn.init.constant_(self.fc_char.bias, 0.1)\n",
        "            # self.fc_concat = nn.Linear(1024, 512)\n",
        "        # elif mode in [2, 4]:\n",
        "        #     self.fc = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "        # elif mode == 1:\n",
        "        #     self.fc = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
        "        torch.nn.init.constant_(self.fc1.bias, 0.1)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
        "        torch.nn.init.constant_(self.fc2.bias, 0.1)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        torch.nn.init.xavier_normal_(self.fc3.weight)\n",
        "        torch.nn.init.constant_(self.fc3.bias, 0.1)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
        "        torch.nn.init.constant_(self.fc2.bias, 0.1)\n",
        "\n",
        "    def forward(self, x_word=None, x_char=None, x_char_seq=None, x_char_pad_idx=None):\n",
        "        pooled_x = []\n",
        "\n",
        "        if self.mode in [4, 5]:\n",
        "            x_char = self.char_embedding(x_char)\n",
        "            # x_char = x_char * x_char_pad_idx\n",
        "\n",
        "        if self.mode in [2, 3, 4, 5]:\n",
        "            x_word = self.word_embedding(x_word)\n",
        "\n",
        "        if self.mode in [1, 3, 5]:\n",
        "            x_char_seq = self.char_seq_embedding(x_char_seq)\n",
        "\n",
        "        if self.mode in [4, 5]:\n",
        "            x_char = torch.sum(x_char, dim=2)\n",
        "            x_combined = x_char + x_word\n",
        "            x_combined = torch.permute(x_combined, (0, 2, 1))\n",
        "            # x_combined = x_combined.unsqueeze(1)\n",
        "        if self.mode in [2, 3]:\n",
        "            x_combined = torch.permute(x_word, (0, 2, 1))\n",
        "            # x_combined = x_word.unsqueeze(1)\n",
        "        if self.mode in [1, 3, 5]:\n",
        "            char_x_expanded = torch.permute(x_char_seq, (0, 2, 1))\n",
        "            # char_x_expanded = x_char_seq.unsqueeze(1)\n",
        "\n",
        "        if self.mode == 2 or self.mode == 3 or self.mode == 4 or self.mode == 5:\n",
        "\n",
        "            for i, conv in enumerate(self.conv_layers):\n",
        "                h = F.relu(conv(x_combined))\n",
        "                pooled = F.max_pool2d(h, (1, self.word_seq_len - self.filter_sizes[i] + 1))\n",
        "                pooled_x.append(pooled)\n",
        "\n",
        "            h_pooled = torch.cat(pooled_x, 1) #?\n",
        "            h_pooled = h_pooled.squeeze(2) #?\n",
        "\n",
        "            x_flat = torch.reshape(h_pooled, [h_pooled.shape[0], -1])\n",
        "            h_drop = self.dropout_keep_prob(x_flat)\n",
        "\n",
        "\n",
        "        if self.mode == 1 or self.mode == 3 or self.mode == 5:\n",
        "            pooled_char_x = []\n",
        "            for i, conv in enumerate(self.conv_layers):\n",
        "                h = F.relu(conv(char_x_expanded))\n",
        "                pooled = F.max_pool2d(h, (1, self.char_seq_len - self.filter_sizes[i] + 1))\n",
        "                pooled_char_x.append(pooled)\n",
        "\n",
        "            h_char_pool = torch.cat(pooled_char_x, 1) #?\n",
        "            h_char_pool = h_char_pool.squeeze(2) #?\n",
        "            # h_char_pool = h_char_pool.squeeze(2) #?\n",
        "\n",
        "            char_x_flat = torch.reshape(h_char_pool, [h_char_pool.shape[0], -1])\n",
        "            char_h_drop = self.dropout_keep_prob(char_x_flat)\n",
        "\n",
        "        # if self.mode in [3, 5]:\n",
        "        #     word_output = F.relu(self.fc_word(self.dropout(h_pooled)))\n",
        "        #     char_output = F.relu(self.fc_char(self.dropout(h_pooled)))\n",
        "        #     conv_output = torch.cat([word_output, char_output], 1)\n",
        "        if self.mode in [3, 5]:\n",
        "            word_output = self.fc_word(h_drop)\n",
        "            char_output = self.fc_char(char_h_drop)\n",
        "            conv_output = torch.cat([word_output, char_output], 1)\n",
        "        elif self.mode in [2, 4]:\n",
        "            conv_output = h_drop\n",
        "        elif self.mode == 1:\n",
        "            conv_output = char_h_drop\n",
        "        # else:\n",
        "        #     conv_output = F.relu(self.fc(self.dropout(h_pooled)))\n",
        "\n",
        "        output0 = F.relu(self.fc1(conv_output))\n",
        "        output1 = F.relu(self.fc2(output0))\n",
        "        output2 = F.relu(self.fc3(output1))\n",
        "        scores = self.fc4(output2)\n",
        "\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Hk30WSW-HMal"
      },
      "outputs": [],
      "source": [
        "# cnn = TextCNN(\n",
        "#                 char_ngram_vocab_size = len(ngrams_dict)+1,\n",
        "#                 word_ngram_vocab_size = len(words_dict)+1,\n",
        "#                 char_vocab_size = len(chars_dict)+1,\n",
        "#                 embedding_size=emb_dim,\n",
        "#                 word_seq_len=max_len_words,\n",
        "#                 char_seq_len=max_len_chars,\n",
        "#                 l2_reg_lambda=l2_reg_lambda,\n",
        "#                 mode=emb_mode,\n",
        "#                 filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
        "#                 num_classes=4)\n",
        "\n",
        "# optimizer = torch.optim.Adam(cnn.parameters(), lr=lr, weight_decay=l2_reg_lambda)\n",
        "# loss_func = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfKVgs3SHMal",
        "outputId": "6b1958d9-581b-4945-a953-ecf99267e403"
      },
      "outputs": [],
      "source": [
        "# if emb_mode == 1:\n",
        "#     print(cnn(x_char_seq=_[0]).shape)\n",
        "# elif emb_mode == 2:\n",
        "#     print(cnn(x_word=_[0]).shape)\n",
        "# elif emb_mode == 3:\n",
        "#     print(cnn(x_char_seq=_[0], x_word=_[1]).shape)\n",
        "# elif emb_mode == 4:\n",
        "#     print(cnn(x_word=_[0], x_char=_[1]).shape)\n",
        "# elif emb_mode == 5:\n",
        "#     print(cnn(x_char_seq=_[0], x_word=_[1], x_char=_[2]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1mhbrgqTHMal"
      },
      "outputs": [],
      "source": [
        "# from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
        "import torchmetrics\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "import pytorch_lightning as L\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2N7gt4IyHMan"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassifierLightningModel(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        num_classes,\n",
        "        optimizer=None,\n",
        "        loss_func=None,\n",
        "        learning_rate=0.01,\n",
        "        batch_size=64,\n",
        "        lr_scheduler=None,\n",
        "        user_lr_scheduler=False,\n",
        "        min_lr=0.0,\n",
        "    ):\n",
        "        super(ClassifierLightningModel, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = model\n",
        "        self.min_lr = min_lr\n",
        "        # self.save_hyperparameters(ignore=[\"model\"])\n",
        "        self.save_hyperparameters(\"model\", logger=False)\n",
        "        self.optimizer = self._get_optimizer(optimizer)\n",
        "        self.lr_scheduler = (\n",
        "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
        "        )\n",
        "        self.loss_func = loss_func\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x_word=None, x_char=None, x_char_seq=None, x_char_pad_idx=None, *args, **kwargs):\n",
        "        return self.model(x_word, x_char, x_char_seq, x_char_pad_idx)\n",
        "\n",
        "    # def on_train_epoch_start(self) -> None:\n",
        "    #     param_groups = next(iter(self.optimizer.param_groups))\n",
        "    #     if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
        "    #         current_learning_rate = float(param_groups[\"lr\"])\n",
        "    #         self.log(\n",
        "    #             \"lr\",\n",
        "    #             current_learning_rate,\n",
        "    #             batch_size=self.batch_size,\n",
        "    #             on_epoch=True,\n",
        "    #             on_step=False,\n",
        "    #         )\n",
        "\n",
        "    def run_model(self, batch):\n",
        "        if emb_mode == 1:\n",
        "            return self(x_char_seq=batch[0])\n",
        "        elif emb_mode == 2:\n",
        "            return self(x_word=batch[0])\n",
        "        elif emb_mode == 3:\n",
        "            return self(x_char_seq=batch[0], x_word=batch[1])\n",
        "        elif emb_mode == 4:\n",
        "            return self(x_word=batch[0], x_char=batch[1])\n",
        "        elif emb_mode == 5:\n",
        "            return self(x_char_seq=batch[0], x_word=batch[1], x_char=batch[2])\n",
        "\n",
        "    def training_step(self, batch, *args, **kwargs):\n",
        "        for i in range(len(batch)):\n",
        "            batch[i] = batch[i].to(self.device)\n",
        "\n",
        "        self.model.train()\n",
        "        y_out = self.run_model(batch)\n",
        "\n",
        "        loss = self.loss_func(y_out.view(batch[-1].shape), batch[-1])\n",
        "        self.train_losses.append(loss.detach().item())\n",
        "        self.log(\n",
        "            \"train_loss\",\n",
        "            loss,\n",
        "            prog_bar=True,\n",
        "            batch_size=self.batch_size,\n",
        "            on_epoch=True,\n",
        "            on_step=True,\n",
        "        )\n",
        "\n",
        "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(batch[-1], dim=1))\n",
        "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, *args, **kwargs):\n",
        "        for i in range(len(batch)):\n",
        "            batch[i] = batch[i].to(self.device)\n",
        "\n",
        "        self.model.eval()\n",
        "        y_out = self.run_model(batch)\n",
        "        loss = self.loss_func(y_out.view(batch[-1].shape), batch[-1])\n",
        "        self.val_losses.append(loss.detach().item())\n",
        "\n",
        "        self.log(\n",
        "            \"val_loss\",\n",
        "            loss,\n",
        "            prog_bar=True,\n",
        "            batch_size=self.batch_size,\n",
        "            on_epoch=True\n",
        "        )\n",
        "\n",
        "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(batch[-1], dim=1))\n",
        "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, batch_size=self.batch_size)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.lr_scheduler is None:\n",
        "            return self.optimizer\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": self.optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": self.lr_scheduler,\n",
        "                \"monitor\": \"train_loss\",\n",
        "                \"interval\": \"epoch\",\n",
        "                \"frequency\": 1,\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def update_learning_rate(self, learning_rate: float):\n",
        "        self.learning_rate = learning_rate\n",
        "        for g in self.optimizer.param_groups:\n",
        "            g[\"lr\"] = learning_rate\n",
        "\n",
        "    def _get_optimizer(self, optimizer):\n",
        "        return (\n",
        "            optimizer\n",
        "            if optimizer is not None\n",
        "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        )\n",
        "\n",
        "    def _get_lr_scheduler(self, lr_scheduler):\n",
        "        return (\n",
        "            lr_scheduler\n",
        "            if lr_scheduler is not None\n",
        "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
        "            )\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-OK4zTeHMao",
        "outputId": "5c496b0e-5d58-4a5c-f89a-f6b57b887f83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:269: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
            "  rank_zero_warn(\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "seed = 911\n",
        "# for i in range(5):\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss',mode='min',patience=25),\n",
        "    # CustomModelCheckpoint(dirpath=r'models\\malicious_urls_model', filename=f'malicious_urls_model_', every_n_epochs=3, mode='min', monitor='val_loss_epoch', save_on_train_epoch_end=True),\n",
        "    ModelCheckpoint(save_top_k=5, mode='min', monitor='val_loss', save_last=True)\n",
        "    ]\n",
        "classifier_torch_model = TextCNN(\n",
        "                char_ngram_vocab_size = len(ngrams_dict)+1,\n",
        "                word_ngram_vocab_size = len(words_dict)+1,\n",
        "                char_vocab_size = len(chars_dict)+1,\n",
        "                embedding_size=emb_dim,\n",
        "                word_seq_len=max_len_words,\n",
        "                char_seq_len=max_len_chars,\n",
        "                l2_reg_lambda=l2_reg_lambda,\n",
        "                mode=emb_mode,\n",
        "                filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
        "                num_classes=len(class_id)).to(device)\n",
        "\n",
        "# classifier_torch_model = CNN_for_Text(num_embedding=len(vocab_dict), batch_size=batch_size, hidden_dim=hidden_dim, embedding_dim=embedding_dim, max_char_count=256, dropout=0.15, num_out_features=len(class_id), kernel_size=[5, 5, 5, 3], seed=seed)\n",
        "optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=0.00011)\n",
        "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30, 40, 50, 60, 70],gamma=0.5)\n",
        "loss_func = torch.nn.BCEWithLogitsLoss()\n",
        "classfier_lightning_model = ClassifierLightningModel(classifier_torch_model,\n",
        "                                                    num_classes=len(class_id),\n",
        "                                            learning_rate=lr,\n",
        "                                            batch_size=batch_size,\n",
        "                                            optimizer=optimizer,\n",
        "                                            loss_func=loss_func,\n",
        "                                            lr_scheduler=lr_scheduler,\n",
        "                                            user_lr_scheduler=True\n",
        "                                            ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "trainer = L.Trainer(\n",
        "            callbacks=callbacks,\n",
        "            max_epochs=80,\n",
        "            accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
        "            logger=CSVLogger(save_dir='logs/', name='log2')\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module                   FLOP    % Total\n",
            "-------------------  --------  ---------\n",
            "TextCNN              122.072B    100.00%\n",
            " - aten.convolution  118.514B     97.09%\n",
            " - aten.addmm          3.557B      2.91%\n",
            " TextCNN.fc_word       1.074B      0.88%\n",
            "  - aten.addmm         1.074B      0.88%\n",
            " TextCNN.fc_char       1.074B      0.88%\n",
            "  - aten.addmm         1.074B      0.88%\n",
            " TextCNN.fc1           1.074B      0.88%\n",
            "  - aten.addmm         1.074B      0.88%\n",
            " TextCNN.fc2           0.268B      0.22%\n",
            "  - aten.addmm         0.268B      0.22%\n",
            " TextCNN.fc3           0.067B      0.05%\n",
            "  - aten.addmm         0.067B      0.05%\n",
            " TextCNN.fc4           0.001B      0.00%\n",
            "  - aten.addmm         0.001B      0.00%\n"
          ]
        }
      ],
      "source": [
        "_ = next(iter(test_dataloader))\n",
        "flopt_counter = FlopCounterMode(classfier_lightning_model.model)\n",
        "for i in range(len(_)):\n",
        "    _[i] = _[i].to(device)\n",
        "with flopt_counter:\n",
        "    classfier_lightning_model.model(x_char_seq=_[0], x_word=_[1], x_char=_[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "01034ab9e5314a1e85ef1183c32f5750",
            "e0b7c96dd59549fb9cd2ef8f285c9f58",
            "9939119df4d347cdb867d49ac5f6aa8d",
            "6c0db405b45c4c599015ceb5e2270c07",
            "d99b67f41ad64f7c8ba8e8969253809d",
            "39381680356d46d3a02e5aa728424d8e",
            "37f37e6ce5304003a724eb6930e79cb8",
            "5261e91e698e4855b58165dc7ba171cd",
            "304738c44b3a463693916f685acbd8d1",
            "fc6455a9aed34ad7ae30b6b69af8029f",
            "a846982fc12b4152b7ec9080d543cfd3",
            "661b880ef2f24f2db905f76221bb0ce0",
            "bf291d062eb84f188ce18d55dbaf1775",
            "7757a408fd6842f4a72218128305e267",
            "1bc534be68d444c1910416cc4e479c5f",
            "2cbc94f9c3e64677a6439872c8adad6f",
            "060b7dc64f884d62bdc3f37c78e8d5c8",
            "7af71962ac4a49e4a2eb7869687e5a4d",
            "baa32d9dd2c24dd589059ffc5cbc020f",
            "c7c542b10d8f43aba5fe85449af9590b",
            "34e5a744936c4ea9b72efce0fd957253",
            "5e15db0627a0462a9645b41d805c693a",
            "8f2a12038fda473a8c66203314174795",
            "3adba4e9e2c740e5af4986affb98e8b4",
            "2fdba9d903b7446392c18c1533a5b760",
            "43d047c5404e437abb763be00cd6b84c",
            "4a715c3beb424270989dece71ef6cad4",
            "33b9ff0234d040d8bf8de7d9d92b6ebc",
            "514cf467377c434789c8e9d31f766872",
            "7126c8d4733c4b539da66c868395d2ec",
            "c7466d893776499ab6cba653a237c99e",
            "377223d3186047138fe539c1cfa7ba0a",
            "3c1dc5d88a6040b7a002e57f68667f94"
          ]
        },
        "id": "0ARojS7SHMaq",
        "outputId": "0e916d1f-dcb1-47f3-aab0-c18930353af1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params\n",
            "-------------------------------------------------\n",
            "0 | model     | TextCNN            | 6.1 M \n",
            "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
            "2 | train_acc | MulticlassAccuracy | 0     \n",
            "3 | val_acc   | MulticlassAccuracy | 0     \n",
            "4 | test_acc  | MulticlassAccuracy | 0     \n",
            "-------------------------------------------------\n",
            "6.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.1 M     Total params\n",
            "24.347    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b803bb8c4a4a439394c572554577c594",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37d8fbba13b8410a8f97fa1aadbd9cf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "800a06c4b6da4d5d8811449529e924e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "447ac4e72cf04f989615c39d6179e329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e2381ecd6604028ae104de27b7143c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4135b2bf60b42e2870b6db6cfd4496b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d11d94ddd7fc45688ecd6b154525c41a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "995cf348bd744e36af529cc5d9788c7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d427f8b4a3c94a01b683b0fa769470ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34eafb4b6fe44446a5e3d981b7fc4c00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd6d5598e5f2410d9f29e4463926d9d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0d71f8ad7b54958a7bef730f7df1f6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "561aa2cb7b164b07b52fe4113c6c621b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7c92f3f8c8d42c792ea3be64e831a10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a49f1a0a10334a6aa20de6cab6d5d798",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eeff68eee3f4fbda8b600f938b513a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d7beb324b7e41f5a978321351c7d95d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfed9944c4ba4a528304993af35d9e25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a7a9bd8549a48eabbc0ff7bd05feb2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "094466f8c67e4341a795c6ff0c093055",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7202ecb8aa94a2497fc06e0911cadbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0520e5993dba4d669d80a74115a6d863",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c9e3208d7bd4e56bed25e9e99b77e8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e2f13964d3143d3901911259f48a148",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21f90932e16c44a3af635d70f97a9ed5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0401d8c9fc054d68835b02ae2ff07698",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80306a8fa87348218973f0a3a7711c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8da4e3c58cc43ecb98cac41b6f87655",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ae802024fd140d5b38e494f60a7b248",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf0c2f69841c48f0af36c32808d57446",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "710ed28dfcd743599d06fc1459013996",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a60abe4ec4ac4ee98567e2c40dc42590",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cbe1ca4a7df43edb84e40ece6d9dd28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "232645d999774ccdb45044b392a05322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c24dc60d4e48448db7faef5df3499ff8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5ad61010a0c46189bc643bf56b358f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39d173decba74e49a862d189f790e342",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b7c774c452a412da7dc17798f4425af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cfa02c6155d4a15b71a649842ec53aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f70c6fa9f1e74b9c83585c24b5f3c544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a25ef22ed41452f973792bb2a100ffb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d40aa8c8c1843ea964d3a0db71bb9f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4756deb0240249038667f7b2b5f043b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "226443a411b6464eb34dfa2220224c16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7add44819ab411087d37a10fb0d100c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e58b1444568e449395f6e806945a67f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e42de17023264018baa4dd35adc7af8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c9ed6f3f6a40d38943b92cd402a662",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf1b33ff36754c71bf7464c03d077749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e555e4f5bc414aa9b7c8b108ab29cd5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9f72f6af4994205ab2916ed152ee3fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "921f2ee4ddb84e5880d35804541de40e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "658aa58b622940af8b592f91c0009a99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e64181368d1a4f41b94e44e4e0f89541",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3575f6b070842d8b0c2bd6f88ea68d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4f8eaede0e04f86bac5151760e06a93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f063ec56982470d881d274e406946fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6598813e07374606a752d4515e5118ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcb1213263c24bcfb0e14e22a5d91eca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54c704281c52452fb437141e196c584c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9f918eb335540ac8ed19ec54e7da976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d96a016bec8f477d97276c0ffc03ec82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8402a2473a0a45ee90ea80fe498e1106",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a248f555864c11b94967b2506f04c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "477bf3a826ac421ea63c1fbb0fdf75fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f797cd9068347fabf39ba64d666c796",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fec459efff3b459da35c2e8c71da24b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "839d322169f648d390a5b24fa8f1e732",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d635de09cbb499fbe6891d3c3f12b9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c643e6d3dda24f30860777214c9820b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e562494bd2b4cae8ec347c667ea16bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aadad426a20245bd9f86c8e4320ace0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de5734aaf86140729f58f2295f362ddd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a1cf494ad104759aa647a378e0fed71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32c7e219369f4c3f935ce524dd901389",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aec831f7dcec4327a9e210aa2866bb8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2b25399e9184cca9c3d943df03f68f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39782b72323741368f819939f038ae63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f8bddfb9ff4436596a52c89933baa82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6869e8369d8d4108bc326816e0d61a50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13a056e9bfae496abe32a4c0a18475cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WhLaNnjiHMaq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from torchmetrics.classification import ConfusionMatrix\n",
        "def calculate_metrics(cl_model):\n",
        "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
        "\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    cl_model = cl_model.eval()\n",
        "    cl_model.to(device)\n",
        "    for _ in tqdm(test_dataloader):\n",
        "        for i in range(len(_)):\n",
        "            _[i] = _[i].to(device)\n",
        "        with torch.no_grad():\n",
        "            y_p = cl_model.run_model(_)\n",
        "            y_p = y_p.cpu()\n",
        "        y_pred.append(y_p)\n",
        "        y_true.append(_[-1].cpu())\n",
        "    y_pred = torch.cat(y_pred, dim=0)\n",
        "    y_true = torch.cat(y_true, dim=0)\n",
        "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
        "    y_true2 = torch.argmax(y_true, dim=1)\n",
        "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
        "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
        "    print('================================')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "G6hpkHJtHMaq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  7.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9836    0.9850    0.9843      4800\n",
            "           1     0.9849    0.9835    0.9842      4790\n",
            "\n",
            "    accuracy                         0.9843      9590\n",
            "   macro avg     0.9843    0.9843    0.9843      9590\n",
            "weighted avg     0.9843    0.9843    0.9843      9590\n",
            "\n",
            "confusion matrix:\n",
            " tensor([[4728,   72],\n",
            "        [  79, 4711]])\n",
            "================================\n"
          ]
        }
      ],
      "source": [
        "classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
        "classfier_lightning_model = classfier_lightning_model.eval()\n",
        "calculate_metrics(classfier_lightning_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9821755548768072"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = 0.9871\n",
        "r = 0.9773\n",
        "(2*p*r)/(p+r)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01034ab9e5314a1e85ef1183c32f5750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0b7c96dd59549fb9cd2ef8f285c9f58",
              "IPY_MODEL_9939119df4d347cdb867d49ac5f6aa8d",
              "IPY_MODEL_6c0db405b45c4c599015ceb5e2270c07"
            ],
            "layout": "IPY_MODEL_d99b67f41ad64f7c8ba8e8969253809d"
          }
        },
        "060b7dc64f884d62bdc3f37c78e8d5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc534be68d444c1910416cc4e479c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e5a744936c4ea9b72efce0fd957253",
            "placeholder": "​",
            "style": "IPY_MODEL_5e15db0627a0462a9645b41d805c693a",
            "value": " 1/8 [00:19&lt;02:15,  0.05it/s, v_num=0, train_loss_step=0.471, train_acc_step=0.754, val_loss=0.492, val_acc=0.733, train_loss_epoch=1.460, train_acc_epoch=0.602]"
          }
        },
        "2cbc94f9c3e64677a6439872c8adad6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2fdba9d903b7446392c18c1533a5b760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7126c8d4733c4b539da66c868395d2ec",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7466d893776499ab6cba653a237c99e",
            "value": 2
          }
        },
        "304738c44b3a463693916f685acbd8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33b9ff0234d040d8bf8de7d9d92b6ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e5a744936c4ea9b72efce0fd957253": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377223d3186047138fe539c1cfa7ba0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f37e6ce5304003a724eb6930e79cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39381680356d46d3a02e5aa728424d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3adba4e9e2c740e5af4986affb98e8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b9ff0234d040d8bf8de7d9d92b6ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_514cf467377c434789c8e9d31f766872",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "3c1dc5d88a6040b7a002e57f68667f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43d047c5404e437abb763be00cd6b84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377223d3186047138fe539c1cfa7ba0a",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1dc5d88a6040b7a002e57f68667f94",
            "value": " 2/2 [00:14&lt;00:00,  0.14it/s]"
          }
        },
        "4a715c3beb424270989dece71ef6cad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "514cf467377c434789c8e9d31f766872": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5261e91e698e4855b58165dc7ba171cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e15db0627a0462a9645b41d805c693a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "661b880ef2f24f2db905f76221bb0ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf291d062eb84f188ce18d55dbaf1775",
              "IPY_MODEL_7757a408fd6842f4a72218128305e267",
              "IPY_MODEL_1bc534be68d444c1910416cc4e479c5f"
            ],
            "layout": "IPY_MODEL_2cbc94f9c3e64677a6439872c8adad6f"
          }
        },
        "6c0db405b45c4c599015ceb5e2270c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6455a9aed34ad7ae30b6b69af8029f",
            "placeholder": "​",
            "style": "IPY_MODEL_a846982fc12b4152b7ec9080d543cfd3",
            "value": " 2/2 [00:14&lt;00:00,  0.14it/s]"
          }
        },
        "7126c8d4733c4b539da66c868395d2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7757a408fd6842f4a72218128305e267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa32d9dd2c24dd589059ffc5cbc020f",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c542b10d8f43aba5fe85449af9590b",
            "value": 1
          }
        },
        "7af71962ac4a49e4a2eb7869687e5a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f2a12038fda473a8c66203314174795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3adba4e9e2c740e5af4986affb98e8b4",
              "IPY_MODEL_2fdba9d903b7446392c18c1533a5b760",
              "IPY_MODEL_43d047c5404e437abb763be00cd6b84c"
            ],
            "layout": "IPY_MODEL_4a715c3beb424270989dece71ef6cad4"
          }
        },
        "9939119df4d347cdb867d49ac5f6aa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5261e91e698e4855b58165dc7ba171cd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_304738c44b3a463693916f685acbd8d1",
            "value": 2
          }
        },
        "a846982fc12b4152b7ec9080d543cfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa32d9dd2c24dd589059ffc5cbc020f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf291d062eb84f188ce18d55dbaf1775": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060b7dc64f884d62bdc3f37c78e8d5c8",
            "placeholder": "​",
            "style": "IPY_MODEL_7af71962ac4a49e4a2eb7869687e5a4d",
            "value": "Epoch 1:  12%"
          }
        },
        "c7466d893776499ab6cba653a237c99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7c542b10d8f43aba5fe85449af9590b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d99b67f41ad64f7c8ba8e8969253809d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "e0b7c96dd59549fb9cd2ef8f285c9f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39381680356d46d3a02e5aa728424d8e",
            "placeholder": "​",
            "style": "IPY_MODEL_37f37e6ce5304003a724eb6930e79cb8",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "fc6455a9aed34ad7ae30b6b69af8029f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
