{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "dataset_dir = r'datasets\\SpamURL1\\URL.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# !pip install transformers datasets torch evaluate\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu118'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from calflops import calculate_flops\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000])\n",
      "tensor(0.9929)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_nums = torch.randn(5000)\n",
    "print(rand_nums.shape)\n",
    "print(torch.std(rand_nums))\n",
    "plt.hist(rand_nums, bins=500)\n",
    "plt.hist(torch.fmod(rand_nums,2), bins=250)\n",
    "plt.hist(torch.fmod(rand_nums,2.)*(2./3.), bins=250)\n",
    "plt.xlim([-4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    20423\n",
      "1    20412\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    2275\n",
      "0    2263\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'datasets\\SpamURL1\\URL.xlsx')\n",
    "df.columns=['labels', 'text']\n",
    "df.dropna(inplace=True)\n",
    "class_list = df.labels.unique()\n",
    "class_id = {t:i for i, t in enumerate(class_list)}\n",
    "id_class = {i:t for i, t in enumerate(class_list)}\n",
    "df['label'] = np.array([class_id[t] for t in df['labels']], dtype=int)\n",
    "df = df.drop('labels', axis=1)\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=True)\n",
    "print(df_train.label.value_counts())\n",
    "print(df_test.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cfe0ec7f9e466b9ce672aaac5a041c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb31877736a94310809f8735d4b599d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=64, padding='max_length')\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the format for PyTorch\n",
    "train_dataset = train_dataset.rename_column('label', 'labels')\n",
    "test_dataset = test_dataset.rename_column('label', 'labels')\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=r'logs/OtherModels/bert_ag_results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "# Load the metrics\n",
    "import evaluate;\n",
    "accuracy_metric = evaluate.load('accuracy', trust_remote_code=True)\n",
    "precision_metric = evaluate.load('precision', trust_remote_code=True)\n",
    "recall_metric = evaluate.load('recall', trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p.predictions, p.label_ids\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall']\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744bf8866bb94aecbaa65b146b0e9139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef9c885d3e7435aba6d663571385306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06750977784395218, 'eval_accuracy': 0.9748788012340238, 'eval_precision': 0.9749773900271319, 'eval_recall': 0.9748611441585371, 'eval_runtime': 2.7191, 'eval_samples_per_second': 1668.929, 'eval_steps_per_second': 6.62, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b190551a09494ce0adbf0f2d622c52aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05295746773481369, 'eval_accuracy': 0.9803878360511239, 'eval_precision': 0.9803872552218813, 'eval_recall': 0.9803882816255772, 'eval_runtime': 2.7085, 'eval_samples_per_second': 1675.436, 'eval_steps_per_second': 6.646, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff6792ad546456491b30e239bb0eb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04430915415287018, 'eval_accuracy': 0.9850154252974879, 'eval_precision': 0.9850153205168671, 'eval_recall': 0.9850153205168671, 'eval_runtime': 2.697, 'eval_samples_per_second': 1682.598, 'eval_steps_per_second': 6.674, 'epoch': 3.0}\n",
      "{'loss': 0.0888, 'learning_rate': 1.6875e-05, 'epoch': 3.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d07acbd1d12425f974cefe9ef64c863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05129655823111534, 'eval_accuracy': 0.9856765094755399, 'eval_precision': 0.9856938675294362, 'eval_recall': 0.9856699994658458, 'eval_runtime': 2.7473, 'eval_samples_per_second': 1651.779, 'eval_steps_per_second': 6.552, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8d6570ba804aa399fc0cca98584fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07375992834568024, 'eval_accuracy': 0.9814896430145439, 'eval_precision': 0.9819861023201366, 'eval_recall': 0.9814487236139909, 'eval_runtime': 2.757, 'eval_samples_per_second': 1646.007, 'eval_steps_per_second': 6.529, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaacf01bfee451caef35ef82442dcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0559801384806633, 'eval_accuracy': 0.9865579550462759, 'eval_precision': 0.9865810023310023, 'eval_recall': 0.9865502857725571, 'eval_runtime': 2.6713, 'eval_samples_per_second': 1698.803, 'eval_steps_per_second': 6.738, 'epoch': 6.0}\n",
      "{'loss': 0.0125, 'learning_rate': 1.375e-05, 'epoch': 6.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd65d178ea134b4aa201ff6b6de40ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06006975844502449, 'eval_accuracy': 0.9869986778316439, 'eval_precision': 0.9870070890906943, 'eval_recall': 0.9869945079224796, 'eval_runtime': 2.7083, 'eval_samples_per_second': 1675.564, 'eval_steps_per_second': 6.646, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2077e48d2d0c4ad59098ac017af1920b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06054010987281799, 'eval_accuracy': 0.9869986778316439, 'eval_precision': 0.9869992339236628, 'eval_recall': 0.9869980042052513, 'eval_runtime': 2.755, 'eval_samples_per_second': 1647.195, 'eval_steps_per_second': 6.534, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0725859fdfd0481389c9b26bc26d329c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06708797067403793, 'eval_accuracy': 0.9878801234023799, 'eval_precision': 0.9879032634032634, 'eval_recall': 0.9878724633740099, 'eval_runtime': 2.8173, 'eval_samples_per_second': 1610.734, 'eval_steps_per_second': 6.389, 'epoch': 9.0}\n",
      "{'loss': 0.005, 'learning_rate': 1.0625e-05, 'epoch': 9.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0888f48d7b40c39961f690c4d9e850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06481275707483292, 'eval_accuracy': 0.988100484795064, 'eval_precision': 0.9881494302778822, 'eval_recall': 0.9880887473110187, 'eval_runtime': 2.7248, 'eval_samples_per_second': 1665.468, 'eval_steps_per_second': 6.606, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c60d9f5fa24077af8d17de07c7ea2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06332801282405853, 'eval_accuracy': 0.9874394006170119, 'eval_precision': 0.9874399609036904, 'eval_recall': 0.9874387300724021, 'eval_runtime': 2.7084, 'eval_samples_per_second': 1675.509, 'eval_steps_per_second': 6.646, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb959b3fe0414f569075228e9fa4324f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06822469830513, 'eval_accuracy': 0.988100484795064, 'eval_precision': 0.9881207147501077, 'eval_recall': 0.9880934090213807, 'eval_runtime': 2.6488, 'eval_samples_per_second': 1713.2, 'eval_steps_per_second': 6.795, 'epoch': 12.0}\n",
      "{'loss': 0.0029, 'learning_rate': 7.500000000000001e-06, 'epoch': 12.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5f112537404010ad71cdaf3a07a160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07200969010591507, 'eval_accuracy': 0.9878801234023799, 'eval_precision': 0.9879641099207503, 'eval_recall': 0.9878643053808762, 'eval_runtime': 2.7601, 'eval_samples_per_second': 1644.172, 'eval_steps_per_second': 6.522, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d49206331e4fa7ac6de7472143840f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0701107382774353, 'eval_accuracy': 0.988100484795064, 'eval_precision': 0.9881411131195261, 'eval_recall': 0.9880899127386091, 'eval_runtime': 2.769, 'eval_samples_per_second': 1638.882, 'eval_steps_per_second': 6.501, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec2f32b04ca4d60820a30c56ce569de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07367971539497375, 'eval_accuracy': 0.988320846187748, 'eval_precision': 0.9883742660703019, 'eval_recall': 0.9883085275307988, 'eval_runtime': 2.754, 'eval_samples_per_second': 1647.791, 'eval_steps_per_second': 6.536, 'epoch': 15.0}\n",
      "{'loss': 0.0013, 'learning_rate': 4.3750000000000005e-06, 'epoch': 15.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd498daa23549b0a1544d110d14269f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07080157846212387, 'eval_accuracy': 0.9869986778316439, 'eval_precision': 0.9869981291042387, 'eval_recall': 0.9869991696328417, 'eval_runtime': 2.705, 'eval_samples_per_second': 1677.63, 'eval_steps_per_second': 6.654, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397d1b70894143688220aa8dfdefb043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07245168834924698, 'eval_accuracy': 0.988100484795064, 'eval_precision': 0.988168341634837, 'eval_recall': 0.9880864164558376, 'eval_runtime': 2.729, 'eval_samples_per_second': 1662.864, 'eval_steps_per_second': 6.596, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfa64054624420db7ea6b540c45d6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07033517956733704, 'eval_accuracy': 0.988100484795064, 'eval_precision': 0.9881267554280229, 'eval_recall': 0.9880922435937902, 'eval_runtime': 2.762, 'eval_samples_per_second': 1643.018, 'eval_steps_per_second': 6.517, 'epoch': 18.0}\n",
      "{'loss': 0.001, 'learning_rate': 1.25e-06, 'epoch': 18.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca7f3e1178543bcb568a105ef7b18b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07279624789953232, 'eval_accuracy': 0.988761568973116, 'eval_precision': 0.9888150512701763, 'eval_recall': 0.9887492533979498, 'eval_runtime': 2.722, 'eval_samples_per_second': 1667.155, 'eval_steps_per_second': 6.613, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b2a17d2e38410eb8a99a1fd205cad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07124284654855728, 'eval_accuracy': 0.988320846187748, 'eval_precision': 0.9883504405662871, 'eval_recall': 0.9883120238135704, 'eval_runtime': 2.616, 'eval_samples_per_second': 1734.716, 'eval_steps_per_second': 6.881, 'epoch': 20.0}\n",
      "{'train_runtime': 1214.3094, 'train_samples_per_second': 672.563, 'train_steps_per_second': 2.635, 'train_loss': 0.017448950172401965, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c2ce3197bd4714886843be10fc1598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.07124284654855728, 'eval_accuracy': 0.988320846187748, 'eval_precision': 0.9883504405662871, 'eval_recall': 0.9883120238135704, 'eval_runtime': 2.661, 'eval_samples_per_second': 1705.352, 'eval_steps_per_second': 6.764, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# trainer.train(resume_from_checkpoint=r\"logs/OtherModels/bert_ag_results/last_epoch\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(r\"logs/OtherModels/bert_spam_results/last_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 11295, 19699, 9013, 5104, 25481, 1011, 2026, 1012, 3745, 8400, 1012, 4012, 1013, 3167, 1013, 4717, 1035, 2814, 25481, 1035, 4012, 1013, 1035, 9621, 2015, 1013, 2321, 1013, 24185, 8197, 15643, 1012, 2004, 2361, 2595, 1029, 4113, 6305, 9623, 16033, 7520, 1027, 17371, 28940, 2620, 2480, 3736, 2480, 2475, 2100, 2575, 9148, 2102, 2692, 3501, 2094, 2683, 11890, 12193, 4609, 2595, 2480, 102]\n",
      "[101, 7479, 1012, 21210, 12054, 1012, 26226, 1011, 16545, 1012, 10507, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 20116, 1012, 2149, 25688, 1012, 3968, 2226, 1012, 8740, 1013, 1066, 2848, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2739, 1012, 8224, 1012, 4012, 1013, 1029, 8476, 1027, 1038, 1004, 23713, 1025, 6434, 1027, 12667, 2015, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 6316, 1012, 2489, 3270, 9102, 2015, 1012, 8917, 1013, 1047, 3207, 1013, 4642, 2361, 1011, 6994, 23615, 2015, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 2609, 1012, 1057, 14517, 10830, 1012, 6187, 1013, 1066, 8495, 16564, 1013, 19413, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2909, 4817, 1012, 7367, 1013, 1059, 2361, 1011, 4180, 1013, 13354, 7076, 1013, 8285, 13876, 27605, 4371, 1013, 4297, 5856, 1013, 1017, 9468, 2575, 2683, 2581, 23632, 2683, 5243, 15136, 9468, 2683, 2620, 2094, 25746, 28154, 2683, 2683, 28756, 2629, 27421, 2683, 2549, 2050, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 28678, 2239, 4179, 1011, 13749, 1011, 1022, 27717, 20842, 2487, 1012, 13749, 8303, 1011, 9413, 22123, 6806, 1012, 3733, 2860, 2361, 1012, 4012, 1013, 7561, 1013, 1040, 6290, 27009, 2509, 15378, 2121, 19961, 19481, 2509, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1011, 3095, 1012, 6053, 14604, 1012, 9353, 1012, 2866, 1013, 1066, 5796, 10376, 2232, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 20116, 1012, 5334, 1012, 3968, 2226, 1013, 7060, 1013, 15360, 1013, 2808, 1013, 24582, 2015, 1035, 6486, 1035, 1016, 1012, 11135, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 14172, 1012, 2739, 1012, 4012, 1012, 8740, 1013, 2270, 1013, 12667, 2015, 1013, 1016, 1012, 1014, 1013, 17151, 4183, 1035, 2327, 1035, 3441, 1035, 1022, 1012, 20950, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 10114, 1012, 2260, 1012, 17613, 1012, 23380, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 18804, 9335, 2243, 1012, 6112, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 12849, 18073, 1011, 2177, 1012, 4012, 1013, 25540, 1013, 5950, 1012, 1044, 21246, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 3565, 3995, 7834, 1012, 4012, 1012, 7987, 1013, 8292, 28228, 8586, 10244, 1013, 8740, 10760, 16778, 10803, 1013, 27441, 2015, 1027, 23297, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 3563, 4328, 2595, 1012, 1060, 2100, 2480, 1013, 9733, 5243, 6238, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 11265, 21436, 1012, 4012, 1013, 3972, 21850, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 20950, 1012, 3104, 13704, 2015, 1012, 8917, 1013, 7815, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 1060, 10936, 15671, 21638, 18413, 2595, 3736, 13871, 9351, 2497, 2290, 4160, 20554, 6977, 9189, 1011, 11089, 1011, 22303, 1011, 28516, 1011, 24622, 22203, 2629, 1012, 2866, 1012, 1054, 1012, 18726, 11008, 1012, 4012, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 16634, 2319, 1012, 1042, 2015, 7159, 1012, 2522, 1012, 2866, 1013, 2632, 24141, 2575, 2620, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2566, 24032, 3468, 20110, 1012, 4012, 1013, 2811, 1013, 2294, 1013, 5890, 1013, 2184, 1013, 5236, 1011, 1044, 2696, 9468, 7971, 1011, 12225, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2578, 1012, 29161, 19464, 1012, 4012, 1011, 1058, 2480, 2721, 1012, 21766, 1013, 1049, 1027, 4773, 21197, 2378, 1013, 8833, 2378, 14192, 26187, 2487, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 1042, 9818, 5358, 1011, 1039, 4160, 2487, 4859, 2226, 6279, 2683, 2629, 1012, 9199, 27058, 2213, 1012, 6187, 1013, 7532, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 4315, 13910, 12911, 1011, 6746, 1011, 14477, 14317, 21239, 11960, 9468, 7971, 1012, 4012, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 1056, 1012, 8529, 16558, 2099, 1012, 4012, 1013, 2417, 7442, 6593, 1029, 1062, 1027, 16770, 1003, 23842, 1003, 1016, 2546, 1003, 1016, 22540, 2906, 2290, 1012, 2522, 1003, 1016, 2546, 18413, 2226, 1004, 23713, 1025, 1056, 1027, 3461, 9351, 2480, 24703, 2549, 2480, 3501, 19422, 4140, 4160, 2860, 2480, 4478, 2509, 4859, 2094, 2243, 2480, 24475, 14227, 2213, 2099, 24703, 2094, 2290, 102]\n",
      "[101, 7479, 1012, 2642, 15509, 1012, 4012, 1013, 2613, 4355, 3686, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 23760, 7507, 21784, 1012, 4012, 1013, 11322, 3512, 1012, 1044, 21246, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 23794, 2072, 1012, 9774, 1012, 3968, 2226, 1013, 1066, 5951, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 1040, 15985, 22471, 7277, 1012, 4012, 1013, 1060, 6494, 2015, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 10439, 1012, 5002, 11368, 6806, 5104, 1012, 4012, 1013, 2203, 20330, 1012, 2004, 2361, 2595, 1029, 1040, 4246, 2497, 2683, 2581, 2620, 2620, 3207, 2683, 18139, 2050, 2620, 2497, 14141, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 2396, 9581, 1012, 4012, 1013, 3393, 3900, 3567, 1013, 4790, 1013, 14405, 20974, 1035, 1017, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5125, 2638, 7507, 2100, 1012, 4012, 1013, 4748, 10020, 1013, 11135, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 16576, 17788, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 23205, 9626, 2278, 1012, 2364, 1012, 16545, 1013, 9927, 1013, 1041, 15907, 1011, 2553, 1011, 2330, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 26219, 2243, 2290, 3501, 2094, 2290, 1012, 2199, 8545, 23706, 28696, 9397, 1012, 4012, 1013, 2393, 1011, 2490, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 4717, 21638, 8557, 1012, 4012, 1013, 18558, 1013, 7020, 2072, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 7997, 11108, 1012, 18856, 1013, 2188, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 25212, 6342, 9397, 11589, 2015, 1012, 2522, 1012, 2866, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 6396, 7292, 2015, 1012, 4012, 1013, 3075, 1013, 6627, 1013, 5585, 1013, 5757, 1013, 13782, 1013, 4790, 1013, 2484, 13102, 3286, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 20116, 8202, 15660, 1012, 4012, 1013, 2997, 1013, 6036, 2475, 1013, 23923, 3490, 2102, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 5898, 24229, 2015, 1012, 8917, 1013, 9206, 1012, 2004, 2361, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2372, 1012, 1062, 8004, 3995, 1012, 17953, 1013, 1042, 2290, 2912, 2389, 1013, 4007, 1013, 25430, 1035, 14841, 2683, 2683, 2549, 2860, 1012, 16129, 1001, 14841, 2683, 2683, 2549, 2860, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 12109, 7096, 2229, 1012, 2543, 15058, 29098, 1012, 4012, 1013, 2924, 1013, 25022, 9818, 1013, 25022, 9818, 1013, 25640, 1012, 25718, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 2688, 1012, 2694, 1013, 8264, 1013, 3802, 2615, 1013, 1050, 1013, 16129, 2078, 1013, 2739, 24586, 6525, 2102, 1013, 2739, 24586, 6525, 2102, 1012, 1044, 21246, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 8549, 2378, 1012, 1040, 2243, 1013, 25388, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 9733, 5737, 2361, 1012, 9932, 23099, 27114, 1012, 27166, 1013, 3696, 2378, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2771, 14876, 3406, 4355, 21041, 2080, 1012, 4012, 1013, 1042, 24434, 2094, 2620, 20958, 2581, 2497, 16932, 2487, 2094, 23632, 2620, 14526, 2575, 2581, 2683, 19961, 27421, 2063, 16576, 27717, 21926, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 4773, 1012, 23746, 7159, 1012, 4012, 1012, 19817, 1013, 2010, 27292, 8978, 2532, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2053, 3501, 7662, 23238, 2078, 1012, 4012, 1013, 8554, 1013, 1001, 5730, 4215, 1012, 6583, 24703, 22367, 3170, 1030, 22188, 3678, 6292, 1012, 4012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 3389, 8791, 2290, 5283, 1012, 4012, 1013, 10975, 12083, 10441, 4103, 1013, 21416, 2618, 1013, 9530, 8873, 2290, 1013, 18558, 19731, 18413, 1013, 27166, 10288, 3258, 5403, 6844, 2099, 2615, 1013, 22861, 20842, 26337, 24594, 2692, 2497, 2683, 16932, 2546, 11387, 16409, 21486, 2497, 2575, 17134, 22203, 2620, 2509, 4402, 16068, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 3841, 14728, 2078, 1012, 4012, 1013, 5030, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 16021, 2102, 1012, 25212, 6169, 1012, 8256, 1012, 3968, 2226, 1013, 1066, 20116, 16068, 2692, 1013, 6904, 2692, 2629, 1013, 8921, 1013, 5718, 1011, 7367, 4160, 27179, 28954, 2595, 2475, 1012, 11135, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 16596, 8873, 18613, 8193, 3678, 1012, 4440, 7716, 1012, 4012, 1013, 5950, 1012, 1044, 21246, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 4487, 1012, 4895, 11514, 2072, 1012, 2009, 1013, 8292, 2890, 2692, 2575, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5310, 2860, 2860, 2860, 1012, 16420, 6342, 1012, 3968, 2226, 1013, 1066, 1044, 2140, 1013, 25391, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 6638, 2863, 2480, 21890, 10867, 2278, 1012, 4012, 1013, 8241, 1013, 8833, 2378, 1012, 25718, 1029, 10373, 1027, 1004, 23713, 1025, 8909, 1027, 6421, 20958, 2575, 2620, 2683, 2278, 2581, 2278, 2487, 2063, 2620, 2050, 19841, 28756, 29292, 27531, 2094, 19841, 2683, 2094, 18827, 2509, 27421, 2581, 22022, 23833, 2620, 2683, 2278, 2581, 2278, 2487, 2063, 2620, 2050, 19841, 28756, 29292, 27531, 102]\n",
      "[101, 2372, 1012, 4440, 7716, 1012, 4012, 1013, 1066, 12992, 17130, 1013, 9808, 22447, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 16216, 12911, 29548, 9153, 4779, 1012, 2012, 1013, 13276, 2368, 18337, 2102, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 29347, 16150, 20952, 2595, 2094, 2615, 2595, 16872, 2595, 2546, 2595, 2615, 2620, 22932, 2692, 2509, 1012, 1056, 2243, 1013, 8833, 2378, 1035, 2490, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 24594, 20958, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 18133, 21338, 1012, 8917, 1013, 3653, 15088, 4221, 1013, 9281, 1013, 1040, 3619, 2683, 2683, 1013, 1040, 3619, 8663, 2546, 2683, 2683, 1012, 1044, 21246, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 18558, 4580, 1012, 1052, 2475, 7277, 1012, 8917, 1013, 25416, 1013, 5511, 1013, 5718, 15136, 2683, 1012, 11135, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 6896, 19699, 14663, 19961, 2581, 2575, 23833, 2487, 1012, 7987, 10993, 2100, 1012, 2609, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 1060, 3401, 2098, 1012, 4012, 1013, 14101, 5339, 1035, 5658, 1035, 17174, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 8247, 13203, 13767, 5856, 2099, 1012, 23012, 11008, 1012, 4012, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 19627, 1012, 15017, 1012, 12875, 1012, 14078, 1013, 5085, 1013, 9855, 1013, 3733, 8545, 2497, 1012, 14595, 1012, 4012, 1013, 5950, 1012, 25718, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 21486, 22394, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 15136, 24434, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 19195, 1011, 3931, 1011, 11487, 1011, 8980, 1012, 2026, 1012, 8909, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 11937, 11475, 2213, 1012, 5003, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 18827, 2575, 2475, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 8040, 28332, 2692, 1012, 8917, 1013, 4330, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 20868, 10175, 5685, 21397, 1012, 4012, 1013, 11338, 21338, 2229, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 4496, 9289, 13535, 1011, 2026, 1012, 3745, 8400, 1012, 4012, 1013, 1024, 1060, 1024, 1013, 1054, 1013, 3167, 1013, 9353, 12898, 2078, 1035, 4496, 9289, 13535, 1035, 8917, 1013, 1035, 9621, 2015, 1013, 2321, 1013, 24185, 8197, 15643, 1012, 2004, 2361, 2595, 1029, 4113, 6305, 9623, 16033, 7520, 1027, 27885, 13728, 2869, 2078, 3900, 2497, 2692, 24759, 2361, 15992, 6633, 1003, 2322, 102]\n",
      "[101, 7479, 1012, 9130, 1012, 4012, 1012, 16770, 1012, 1055, 2487, 1012, 1043, 24093, 5638, 1012, 4012, 1013, 8833, 2378, 1029, 2279, 1027, 7479, 1012, 9130, 1012, 4012, 1013, 4575, 1012, 2304, 1012, 4261, 19961, 26224, 2575, 2487, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 19961, 2692, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 1042, 9818, 5358, 1011, 1053, 2595, 21926, 15782, 28154, 1012, 2188, 20915, 2620, 2620, 1012, 2033, 1013, 7532, 1012, 16129, 1029, 2051, 17960, 4183, 1027, 1017, 2497, 2683, 2278, 23352, 2050, 23499, 2063, 2487, 2063, 2683, 2094, 19317, 2497, 2475, 2278, 19841, 22932, 2629, 19797, 2094, 23632, 2050, 23352, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 2079, 25608, 13465, 7352, 1012, 4012, 1013, 10424, 1013, 3461, 2953, 26952, 1013, 5025, 7616, 1013, 2739, 1013, 10882, 29111, 1011, 22307, 3089, 4226, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 24471, 23858, 1012, 10424, 1013, 1040, 17168, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 4310, 18155, 25219, 2869, 27268, 6633, 2015, 1012, 4012, 1013, 20996, 7716, 10686, 1013, 5950, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 3536, 8873, 13578, 1012, 4012, 1013, 3259, 1013, 5950, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7632, 3217, 1011, 9092, 1012, 8917, 1013, 1066, 23969, 7828, 5753, 1013, 2003, 5149, 2075, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 28879, 7317, 16526, 6806, 1012, 1056, 2243, 1013, 3477, 1013, 22861, 19436, 11263, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 2455, 10278, 2497, 1012, 4012, 1013, 2381, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 4895, 2072, 1011, 25487, 1012, 2139, 1013, 5950, 1012, 25718, 1029, 8909, 1027, 18540, 2487, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 2026, 18098, 14428, 7292, 1012, 4012, 1013, 2147, 1013, 5950, 1012, 14021, 21246, 2140, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 14021, 21297, 7875, 12722, 3388, 27009, 1012, 1055, 2509, 1012, 7327, 1011, 2139, 1012, 6112, 1011, 4874, 1011, 5527, 1012, 10439, 9527, 8113, 1012, 6112, 1013, 20066, 2989, 9021, 1013, 5950, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 2575, 17134, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 14526, 2581, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 21942, 1012, 8981, 1012, 3968, 2226, 1013, 15589, 22287, 11475, 1013, 2338, 10665, 1013, 14924, 26340, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 3063, 2549, 20908, 1012, 5658, 1013, 2019, 5714, 1012, 16129, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 12731, 2278, 1012, 15384, 2278, 1012, 29464, 1013, 2003, 17299, 2278, 1011, 21770, 10624, 19362, 2692, 2549, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2026, 1012, 12280, 3775, 1012, 4012, 1013, 17917, 2094, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 1059, 19481, 22407, 2620, 2509, 1011, 7479, 1012, 1042, 2078, 8545, 2497, 1012, 2053, 1013, 1042, 2497, 2290, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 5906, 1012, 29464, 24475, 1012, 8917, 1013, 16129, 1013, 14645, 16068, 12376, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 1045, 1011, 1049, 1012, 25630, 1013, 4773, 8706, 2620, 2094, 1013, 10373, 28940, 17287, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 7479, 1012, 9733, 1012, 2522, 1011, 16545, 1011, 8833, 2378, 1012, 1046, 6182, 4160, 15878, 2226, 4160, 2100, 2860, 1012, 2252, 1013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 2190, 1011, 1997, 1011, 4773, 1012, 4012, 1013, 4024, 1013, 11834, 1012, 14021, 21246, 2140, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 17718, 1011, 2004, 1012, 2139, 1013, 8833, 2378, 1012, 2358, 8609, 9232, 2099, 6299, 1012, 5658, 1012, 18133, 7231, 2140, 1013, 18726, 1013, 20116, 2121, 7903, 2063, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 21144, 1012, 1043, 2100, 1013, 1052, 2692, 3501, 2278, 2595, 2475, 1029, 9130, 1035, 10651, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_list = test_dataset.to_list()\n",
    "for _ in dataset_list[:100]:\n",
    "    print(_['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from torchmetrics.classification import ConfusionMatrix\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def calculate_metrics(bert_model):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    bert_model = bert_model.eval()\n",
    "    bert_model.to(device)\n",
    "    dataset_list = test_dataset.to_list()\n",
    "    for _ in tqdm(dataset_list):\n",
    "        X = torch.tensor(_['input_ids']).unsqueeze(0).to(device)\n",
    "        msk = torch.tensor(_['attention_mask']).unsqueeze(0).to(device)\n",
    "        y = torch.tensor(_['labels']).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = bert_model(X, attention_mask=msk).logits\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    # return y_pred, y_true\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    # y_pred = torch.tensor(y_pred)\n",
    "    y_true = torch.tensor(y_true)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    # y_true2 = torch.argmax(y_true, dim=1)\n",
    "    y_true2 = y_true\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4538/4538 [01:19<00:00, 57.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9915    0.9850    0.9883      2263\n",
      "           1     0.9852    0.9916    0.9884      2275\n",
      "\n",
      "    accuracy                         0.9883      4538\n",
      "   macro avg     0.9884    0.9883    0.9883      4538\n",
      "weighted avg     0.9883    0.9883    0.9883      4538\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[2229,   34],\n",
      "        [  19, 2256]])\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.4286, -5.1514]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model(test_dataset[0]['input_ids'].unsqueeze(0).to(device), attention_mask=test_dataset[0]['attention_mask'].unsqueeze(0).to(device)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\EnhanceSEO\\TestsOnSpamURL1\\bert.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cm \u001b[39m=\u001b[39m ConfusionMatrix(task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(class_id))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassification report: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mclassification_report(y_true,\u001b[39m \u001b[39mtorch\u001b[39m.\u001b[39;49margmax(y_pred,\u001b[39m \u001b[39;49mdim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\u001b[39m \u001b[39mdigits\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconfusion matrix:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mcm(y_pred,\u001b[39m \u001b[39my_true)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "print(f'classification report: \\n {classification_report(y_true, torch.argmax(y_pred, dim=1), digits=4)}')\n",
    "print(f'confusion matrix:\\n {cm(y_pred, y_true)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.9901114463777985\n",
    "r = 0.\n",
    "(2*p*r)/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  66.96 M \n",
      "fwd MACs:                                                               5.51 GMACs\n",
      "fwd FLOPs:                                                              11.03 GFLOPS\n",
      "fwd+bwd MACs:                                                           16.54 GMACs\n",
      "fwd+bwd FLOPs:                                                          33.1 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "DistilBertForSequenceClassification(\n",
      "  66.96 M = 100% Params, 5.51 GMACs = 100% MACs, 11.03 GFLOPS = 100% FLOPs\n",
      "  (distilbert): DistilBertModel(\n",
      "    66.36 M = 99.12% Params, 5.51 GMACs = 99.98% MACs, 11.03 GFLOPS = 99.98% FLOPs\n",
      "    (embeddings): Embeddings(\n",
      "      23.84 M = 35.6% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs\n",
      "      (word_embeddings): Embedding(23.44 M = 35.01% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(393.22 K = 0.59% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 512, 768)\n",
      "      (LayerNorm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs, (768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      42.53 M = 63.52% Params, 5.51 GMACs = 99.98% MACs, 11.03 GFLOPS = 99.97% FLOPs\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          7.09 M = 10.59% Params, 918.55 MMACs = 16.66% MACs, 1.84 GFLOPS = 16.66% FLOPs\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            2.36 M = 3.53% Params, 314.57 MMACs = 5.71% MACs, 629.24 MFLOPS = 5.7% FLOPs\n",
      "            (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.1, inplace=False)\n",
      "            (q_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(590.59 K = 0.88% Params, 75.5 MMACs = 1.37% MACs, 150.99 MFLOPS = 1.37% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs, (768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            4.72 M = 7.05% Params, 603.98 MMACs = 10.96% MACs, 1.21 GFLOPS = 10.95% FLOPs\n",
      "            (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.1, inplace=False)\n",
      "            (lin1): Linear(2.36 M = 3.53% Params, 301.99 MMACs = 5.48% MACs, 603.98 MFLOPS = 5.47% FLOPs, in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(2.36 M = 3.52% Params, 301.99 MMACs = 5.48% MACs, 603.98 MFLOPS = 5.47% FLOPs, in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm(1.54 K = 0% Params, 0 MACs = 0% MACs, 491.52 KFLOPS = 0% FLOPs, (768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(590.59 K = 0.88% Params, 1.18 MMACs = 0.02% MACs, 2.36 MFLOPS = 0.02% FLOPs, in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(1.54 K = 0% Params, 3.07 KMACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.2, inplace=False)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2654: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('11.03 GFLOPS', '5.51 GMACs', '66.96 M')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_flops(model, input_shape=(2, 64), transformer_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\EnhanceSEO\\TestsOnSpamURL1\\bert.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mReplace me by any text you\u001b[39m\u001b[39m'\u001b[39m\u001b[39md like.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m encoded_input \u001b[39m=\u001b[39m tokenizer(text, max_length\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoded_input)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m flopt_counter \u001b[39m=\u001b[39m FlopCounterMode(model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/EnhanceSEO/TestsOnSpamURL1/bert.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m flopt_counter:\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:1002\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    996\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    997\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1002\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m   1003\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1004\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1005\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1006\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1007\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1008\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1009\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1010\u001b[0m )\n\u001b[0;32m   1011\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:814\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    812\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 814\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_flash_attention_2:\n\u001b[0;32m    817\u001b[0m     attention_mask \u001b[39m=\u001b[39m attention_mask \u001b[39mif\u001b[39;00m (attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39min\u001b[39;00m attention_mask) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:141\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39membeddings)\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     input_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m seq_length \u001b[39m=\u001b[39m input_embeds\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39m# isues similar to issue #5664\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2260\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2264\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, max_length=64, truncation=True, padding='max_length', return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "flopt_counter = FlopCounterMode(model)\n",
    "with flopt_counter:\n",
    "    model(**encoded_input)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 612351,
     "sourceId": 1095715,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
