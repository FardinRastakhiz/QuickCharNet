{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0hDf2T3HnQy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eWxRbWhWHMaQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from bisect import bisect_left\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from pathlib import Path\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "import itertools\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from bisect import bisect_left\n",
        "import torch\n",
        "import torch\n",
        "import time\n",
        "import sys\n",
        "import pandas as pd\n",
        "from torch.utils.flop_counter import FlopCounterMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pt-0PhoTHdic"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "    class VocabFactory():\n",
        "\n",
        "        def __init__(self, tokenizer) -> None:\n",
        "            self.tokens_dict = {}\n",
        "            self.tokenizer = tokenizer\n",
        "            self.vocab_id = {}\n",
        "            self.id_vocab = {}\n",
        "\n",
        "        def create_vocab(self, texts, vocab_count=0):\n",
        "            i = 0\n",
        "            self.tokens_dict['❿'] = sys.maxsize\n",
        "\n",
        "            for text in texts:\n",
        "                if i %100000 == 0:\n",
        "                    print(i)\n",
        "                i+=1\n",
        "\n",
        "                tokens = list(self.tokenizer(text))\n",
        "                for token in tokens:\n",
        "                    # token = self.tokenizer(token)\n",
        "                    if token not in self.tokens_dict:\n",
        "                        self.tokens_dict[token] = 0\n",
        "                    self.tokens_dict[token] += 1\n",
        "            self.finalize(vocab_count)\n",
        "\n",
        "        def finalize(self, vocab_count=0):\n",
        "            all_tokens = pd.DataFrame({'tokens': list(self.tokens_dict.keys()), 'counts': list(self.tokens_dict.values())})\n",
        "            all_tokens = all_tokens.sort_values(by=['counts'], ascending=False)\n",
        "            tokens = all_tokens['tokens'].values\n",
        "            if vocab_count != 0:\n",
        "                tokens = tokens[:vocab_count]\n",
        "            self.vocab_id = {t: i for i, t in enumerate(tokens)}\n",
        "            self.id_vocab = {i: t for i, t in enumerate(tokens)}\n",
        "\n",
        "    def read_data(file_dir):\n",
        "        with open(file_dir) as file:\n",
        "            urls = []\n",
        "            labels = []\n",
        "            for line in file.readlines():\n",
        "                items = line.split('\\t')\n",
        "                label = int(items[0])\n",
        "                if label == 1:\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    labels.append(0)\n",
        "                url = items[1][:-1]\n",
        "                urls.append(url)\n",
        "        return urls, labels\n",
        "\n",
        "    def split_url(line, part):\n",
        "        if line.startswith(\"http://\"):\n",
        "            line=line[7:]\n",
        "        if line.startswith(\"https://\"):\n",
        "            line=line[8:]\n",
        "        if line.startswith(\"ftp://\"):\n",
        "            line=line[6:]\n",
        "        if line.startswith(\"www.\"):\n",
        "            line = line[4:]\n",
        "        slash_pos = line.find('/')\n",
        "        if slash_pos > 0 and slash_pos < len(line)-1: # line = \"fsdfsdf/sdfsdfsd\"\n",
        "            primarydomain = line[:slash_pos]\n",
        "            path_argument = line[slash_pos+1:]\n",
        "            path_argument_tokens = path_argument.split('/')\n",
        "            pathtoken = \"/\".join(path_argument_tokens[:-1])\n",
        "            last_pathtoken = path_argument_tokens[-1]\n",
        "            if len(path_argument_tokens) > 2 and last_pathtoken == '':\n",
        "                pathtoken = \"/\".join(path_argument_tokens[:-2])\n",
        "                last_pathtoken = path_argument_tokens[-2]\n",
        "            question_pos = last_pathtoken.find('?')\n",
        "            if question_pos != -1:\n",
        "                argument = last_pathtoken[question_pos+1:]\n",
        "                pathtoken = pathtoken + \"/\" + last_pathtoken[:question_pos]\n",
        "            else:\n",
        "                argument = \"\"\n",
        "                pathtoken = pathtoken + \"/\" + last_pathtoken\n",
        "            last_slash_pos = pathtoken.rfind('/')\n",
        "            sub_dir = pathtoken[:last_slash_pos]\n",
        "            filename = pathtoken[last_slash_pos+1:]\n",
        "            file_last_dot_pos = filename.rfind('.')\n",
        "            if file_last_dot_pos != -1:\n",
        "                file_extension = filename[file_last_dot_pos+1:]\n",
        "                filename = filename[:file_last_dot_pos]\n",
        "            else:\n",
        "                file_extension = \"\"\n",
        "        elif slash_pos == 0:    # line = \"/fsdfsdfsdfsdfsd\"\n",
        "            primarydomain = line[1:]\n",
        "            pathtoken = \"\"\n",
        "            argument = \"\"\n",
        "            sub_dir = \"\"\n",
        "            filename = \"\"\n",
        "            file_extension = \"\"\n",
        "        elif slash_pos == len(line)-1:   # line = \"fsdfsdfsdfsdfsd/\"\n",
        "            primarydomain = line[:-1]\n",
        "            pathtoken = \"\"\n",
        "            argument = \"\"\n",
        "            sub_dir = \"\"\n",
        "            filename = \"\"\n",
        "            file_extension = \"\"\n",
        "        else:      # line = \"fsdfsdfsdfsdfsd\"\n",
        "            primarydomain = line\n",
        "            pathtoken = \"\"\n",
        "            argument = \"\"\n",
        "            sub_dir = \"\"\n",
        "            filename = \"\"\n",
        "            file_extension = \"\"\n",
        "        if part == 'pd':\n",
        "            return primarydomain\n",
        "        elif part == 'path':\n",
        "            return pathtoken\n",
        "        elif part == 'argument':\n",
        "            return argument\n",
        "        elif part == 'sub_dir':\n",
        "            return sub_dir\n",
        "        elif part == 'filename':\n",
        "            return filename\n",
        "        elif part == 'fe':\n",
        "            return file_extension\n",
        "        elif part == 'others':\n",
        "            if len(argument) > 0:\n",
        "                return pathtoken + '?' +  argument\n",
        "            else:\n",
        "                return pathtoken\n",
        "        else:\n",
        "            return primarydomain, pathtoken, argument, sub_dir, filename, file_extension\n",
        "\n",
        "    def get_word_vocab(urls, max_length_words, tokenizer, min_word_freq=0):\n",
        "        vocab_factory = VocabFactory(tokenizer)\n",
        "        vocab_factory.create_vocab(urls)\n",
        "        vocab_id = vocab_factory.vocab_id\n",
        "        start = time.time()\n",
        "        tokenized_texts = [tokenizer(text) for text in urls]\n",
        "        x = ([torch.tensor([vocab_id[token] for token in t_text]) for t_text in tokenized_texts])\n",
        "        x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=0)[:,:max_length_words]\n",
        "        print(\"Finished build vocabulary and mapping to x in {}\".format(time.time() - start))\n",
        "        vocab_dict = vocab_factory.vocab_id\n",
        "        reverse_dict = vocab_factory.id_vocab\n",
        "        print(\"Size of word vocabulary: {}\".format(len(reverse_dict)))\n",
        "        return x, reverse_dict\n",
        "\n",
        "    def get_words(x, reverse_dict, delimit_mode, urls=None):\n",
        "        processed_x = []\n",
        "        if delimit_mode == 0:\n",
        "            for url in x:\n",
        "                words = []\n",
        "                for word_id in url:\n",
        "                    if word_id.item() != 0:\n",
        "                        words.append(reverse_dict[word_id.item()])\n",
        "                    else:\n",
        "                        break\n",
        "                processed_x.append(words)\n",
        "        elif delimit_mode == 1:\n",
        "            for i in range(x.shape[0]):\n",
        "                word_url = x[i]\n",
        "                raw_url = urls[i]\n",
        "                words = []\n",
        "                for w in range(len(word_url)):\n",
        "                    word_id = word_url[w]\n",
        "                    if word_id.item() == 0:\n",
        "                        words.extend(list(raw_url))\n",
        "                        break\n",
        "                    else:\n",
        "                        word = reverse_dict[word_id.item()]\n",
        "                        idx = raw_url.index(word)\n",
        "                        special_chars = list(raw_url[0:idx])\n",
        "                        words.extend(special_chars)\n",
        "                        words.append(word)\n",
        "                        raw_url = raw_url[idx+len(word):]\n",
        "                        if w == len(word_url) - 1:\n",
        "                            words.extend(list(raw_url))\n",
        "                processed_x.append(words)\n",
        "        return processed_x\n",
        "\n",
        "    def get_char_ngrams(ngram_len, word):\n",
        "        word = f\"<{word}>\"\n",
        "        return [word[i:i + ngram_len] for i in range(len(word) - ngram_len + 1)]\n",
        "\n",
        "    def char_id_x(urls, char_dict, max_len_chars):\n",
        "        chidx = [min(len(url), max_len_chars) for url in urls]\n",
        "        chared_id_x = [torch.from_numpy(np.array([char_dict[url[i]] if url[i] in char_dict else 0 for i in range(chidx[l])])) for l, url in enumerate(urls)]\n",
        "        chared_id_x = torch.nn.utils.rnn.pad_sequence(chared_id_x, batch_first=True, padding_value=char_dict['❿'])\n",
        "        return chared_id_x\n",
        "\n",
        "    def ngram_id_x_dicts(word_x, max_len_subwords, high_freq_words=None):\n",
        "        char_ngram_len = 1\n",
        "        all_ngrams = set()\n",
        "        ngramed_x = []\n",
        "        all_words = set()\n",
        "        worded_x = []\n",
        "        counter = 0\n",
        "        for counter, url in enumerate(word_x):\n",
        "            if counter % 100000 == 0:\n",
        "                print(\"Processing #url {}\".format(counter))\n",
        "            url_in_ngrams = []\n",
        "            url_in_words = []\n",
        "            for word in url:\n",
        "                ngrams = get_char_ngrams(char_ngram_len, word)\n",
        "                if (len(ngrams) > max_len_subwords) or \\\n",
        "                    (high_freq_words is not None and len(word)>1 and not is_in(high_freq_words, word)):\n",
        "                    ngram_slice = ngrams[:max_len_subwords]\n",
        "                    all_ngrams.update(ngram_slice)\n",
        "                    url_in_ngrams.append(ngram_slice)\n",
        "                    all_words.add(\"<UNKNOWN>\")\n",
        "                    url_in_words.append(\"<UNKNOWN>\")\n",
        "                else:\n",
        "                    all_ngrams.update(ngrams)\n",
        "                    url_in_ngrams.append(ngrams)\n",
        "                    all_words.add(word)\n",
        "                    url_in_words.append(word)\n",
        "            ngramed_x.append(url_in_ngrams)\n",
        "            worded_x.append(url_in_words)\n",
        "        print(\"worded_x completed\")\n",
        "        all_ngrams = ['❿'] + list(all_ngrams)\n",
        "        ngrams_dict = {ngram: i + 1 for i, ngram in enumerate(all_ngrams)}\n",
        "\n",
        "        print(\"ngrams_dict completed\")\n",
        "        all_words = list(all_words)\n",
        "        words_dict = {word: i + 1 for i, word in enumerate(all_words)}\n",
        "        \n",
        "        return ngrams_dict, words_dict, ngramed_x, worded_x\n",
        "\n",
        "    def ngram_id_x(ngrams_dict, words_dict, ngramed_x, worded_x, max_len_subwords):\n",
        "        print(\"words_dict completed\")\n",
        "\n",
        "        fill_char = ngrams_dict['❿']\n",
        "        ngramed_id_x = [\n",
        "            [\n",
        "                [\n",
        "                    ngrams_dict[ngram] for ngram in ngramed_word[:max_len_subwords]\n",
        "                ] + [fill_char] * max(0, max_len_subwords - len(ngramed_word))\n",
        "                for ngramed_word in ngramed_url\n",
        "            ]\n",
        "            for ngramed_url in ngramed_x\n",
        "        ]\n",
        "        ngramed_id_x = torch.from_numpy(np.array(ngramed_id_x))\n",
        "        print(\"ngramed_id_x completed\")\n",
        "        worded_id_x = [\n",
        "            [words_dict[word] for word in worded_url]\n",
        "            for worded_url in worded_x\n",
        "        ]\n",
        "        worded_id_x = torch.from_numpy(np.array(worded_id_x))\n",
        "\n",
        "        print(\"worded_id_x completed\")\n",
        "        return ngramed_id_x, worded_id_x\n",
        "\n",
        "    def ngram_id_x_from_dict(word_x, max_len_subwords, ngram_dict, word_dict = None):\n",
        "        char_ngram_len = 1\n",
        "        print(\"Index of <UNKNOWN> word: {}\".format(word_dict[\"<UNKNOWN>\"]))\n",
        "        ngramed_id_x = []\n",
        "        worded_id_x = []\n",
        "        counter = 0\n",
        "        if word_dict:\n",
        "            word_vocab = sorted(list(word_dict.keys()))\n",
        "        for url in word_x:\n",
        "            if counter % 100000 == 0:\n",
        "                print(\"Processing url #{}\".format(counter))\n",
        "            counter += 1\n",
        "            url_in_ngrams = []\n",
        "            url_in_words = []\n",
        "            words = url\n",
        "            for word in words:\n",
        "                ngrams = get_char_ngrams(char_ngram_len, word)\n",
        "                if len(ngrams) > max_len_subwords:\n",
        "                    word = \"<UNKNOWN>\"\n",
        "                ngrams_id = []\n",
        "                for ngram in ngrams:\n",
        "                    if ngram in ngram_dict:\n",
        "                        ngrams_id.append(ngram_dict[ngram])\n",
        "                    else:\n",
        "                        ngrams_id.append(0)\n",
        "                url_in_ngrams.append(ngrams_id)\n",
        "                if is_in(word_vocab, word):\n",
        "                    word_id = word_dict[word]\n",
        "                else:\n",
        "                    word_id = word_dict[\"<UNKNOWN>\"]\n",
        "                url_in_words.append(word_id)\n",
        "            ngramed_id_x.append(url_in_ngrams)\n",
        "            worded_id_x.append(url_in_words)\n",
        "\n",
        "        return ngramed_id_x, worded_id_x\n",
        "\n",
        "    def bisect_search(a,x):\n",
        "        i = bisect_left(a,x)\n",
        "        if i != len(a) and a[i] == x:\n",
        "            return i\n",
        "        raise ValueError\n",
        "\n",
        "    def is_in(a,x):\n",
        "        i = bisect_left(a,x)\n",
        "        if i != len(a) and a[i] == x:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def prep_train_test(pos_x, neg_x, dev_pct):\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices=np.random.permutation(np.arange(len(pos_x)))\n",
        "        pos_x_shuffled = pos_x[shuffle_indices]\n",
        "        dev_idx = -1 * int(dev_pct * float(len(pos_x)))\n",
        "        pos_train = pos_x_shuffled[:dev_idx]\n",
        "        pos_test = pos_x_shuffled[dev_idx:]\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices=np.random.permutation(np.arange(len(neg_x)))\n",
        "        neg_x_shuffled = neg_x[shuffle_indices]\n",
        "        dev_idx = -1 * int(dev_pct * float(len(neg_x)))\n",
        "        neg_train = neg_x_shuffled[:dev_idx]\n",
        "        neg_test = neg_x_shuffled[dev_idx:]\n",
        "\n",
        "        x_train = torch.from_numpy(np.array(list(pos_train) + list(neg_train)))\n",
        "        y_train = len(pos_train)*[1] + len(neg_train)*[0]\n",
        "        x_test = torch.from_numpy(np.array(list(pos_test) + list(neg_test)))\n",
        "        y_test = len(pos_test)*[1] + len(neg_test)*[0]\n",
        "\n",
        "        y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=2).float()\n",
        "        y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=2).float()\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_train)))\n",
        "        x_train = x_train[shuffle_indices]\n",
        "        y_train = y_train[shuffle_indices]\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_test)))\n",
        "        x_test = x_test[shuffle_indices]\n",
        "        y_test = y_test[shuffle_indices]\n",
        "\n",
        "        print(\"Train Mal/Ben split: {}/{}\".format(len(pos_train), len(neg_train)))\n",
        "        print(\"Test Mal/Ben split: {}/{}\".format(len(pos_test), len(neg_test)))\n",
        "        print(\"Train/Test split: {}/{}\".format(len(y_train), len(y_test)))\n",
        "        print(\"Train/Test split: {}/{}\".format(len(x_train), len(x_test)))\n",
        "\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "    def prep_train_test2(grouped_ids, dev_pct):\n",
        "\n",
        "        np.random.seed(10)\n",
        "        train_ids = []\n",
        "        test_ids = []\n",
        "\n",
        "        for ids in grouped_ids:\n",
        "            shuffle_indices=np.random.permutation(np.arange(len(ids)))\n",
        "            ids_shuffled = ids[shuffle_indices]\n",
        "            dev_idx = -1 * int(dev_pct * float(len(ids)))\n",
        "            ids_train = ids_shuffled[:dev_idx]\n",
        "            ids_test = ids_shuffled[dev_idx:]\n",
        "            train_ids.append(ids_train)\n",
        "            test_ids.append(ids_test)\n",
        "        y_train = [len(train_ids[i]) * [i] for i in range(len(train_ids))]\n",
        "        y_test = [len(test_ids[i]) * [i] for i in range(len(test_ids))]\n",
        "        y_train = list(itertools.chain.from_iterable(y_train))\n",
        "        y_test = list(itertools.chain.from_iterable(y_test))\n",
        "        x_train = torch.tensor(list(itertools.chain.from_iterable(train_ids)))\n",
        "        x_test = torch.tensor(list(itertools.chain.from_iterable(test_ids)))\n",
        "\n",
        "        y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=len(grouped_ids)).float()\n",
        "        y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=len(grouped_ids)).float()\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_train)))\n",
        "        x_train = x_train[shuffle_indices]\n",
        "        y_train = y_train[shuffle_indices]\n",
        "\n",
        "        np.random.seed(10)\n",
        "        shuffle_indices = np.random.permutation(np.arange(len(x_test)))\n",
        "        x_test = x_test[shuffle_indices]\n",
        "        y_test = y_test[shuffle_indices]\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "    def get_ngramed_id_x(x_idxs, ngramed_id_x):\n",
        "        output_ngramed_id_x = []\n",
        "        for idx in x_idxs:\n",
        "            output_ngramed_id_x.append(ngramed_id_x[idx])\n",
        "        return torch.stack(output_ngramed_id_x)\n",
        "\n",
        "    def pad_seq(urls, max_d1=0, max_d2=0, embedding_size=128):\n",
        "        if max_d1 == 0 and max_d2 == 0:\n",
        "            for url in urls:\n",
        "                if len(url) > max_d1:\n",
        "                    max_d1 = len(url)\n",
        "                for word in url:\n",
        "                    if len(word) > max_d2:\n",
        "                        max_d2 = len(word)\n",
        "        pad_idx = np.zeros((len(urls), max_d1, max_d2, embedding_size))\n",
        "        pad_urls = np.zeros((len(urls), max_d1, max_d2))\n",
        "        pad_vec = [1 for i in range(embedding_size)]\n",
        "        for d0 in range(len(urls)):\n",
        "            url = urls[d0]\n",
        "            for d1 in range(len(url)):\n",
        "                if d1 < max_d1:\n",
        "                    word = url[d1]\n",
        "                    for d2 in range(len(word)):\n",
        "                        if d2 < max_d2:\n",
        "                            pad_urls[d0,d1,d2] = word[d2]\n",
        "                            pad_idx[d0,d1,d2] = pad_vec\n",
        "        return pad_urls, pad_idx\n",
        "\n",
        "    def pad_seq_in_word(urls, max_d1=0, embedding_size=128):\n",
        "        if max_d1 == 0:\n",
        "            url_lens = [len(url) for url in urls]\n",
        "            max_d1 = max(url_lens)\n",
        "        pad_urls = np.zeros((len(urls), max_d1))\n",
        "        #pad_idx = np.zeros((len(urls), max_d1, embedding_size))\n",
        "        #pad_vec = [1 for i in range(embedding_size)]\n",
        "        for d0 in range(len(urls)):\n",
        "            url = urls[d0]\n",
        "            for d1 in range(len(url)):\n",
        "                if d1 < max_d1:\n",
        "                    pad_urls[d0,d1] = url[d1]\n",
        "                    #pad_idx[d0,d1] = pad_vec\n",
        "        return pad_urls\n",
        "\n",
        "    def softmax(x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / e_x.sum()\n",
        "\n",
        "    def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
        "        data = np.array(data)\n",
        "        data_size = len(data)\n",
        "        num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
        "        for epoch in range(num_epochs):\n",
        "            if shuffle:\n",
        "                shuffle_indices = np.random.permutation(np.arange(data_size))\n",
        "                shuffled_data = data[shuffle_indices]\n",
        "            else:\n",
        "                shuffled_data = data\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_idx = batch_num * batch_size\n",
        "                end_idx = min((batch_num+1) * batch_size, data_size)\n",
        "                yield shuffled_data[start_idx:end_idx]\n",
        "\n",
        "    def save_test_result(labels, all_predictions, all_scores, output_dir):\n",
        "        output_labels = []\n",
        "        for i in labels:\n",
        "            if i == 1:\n",
        "                output_labels.append(i)\n",
        "            else:\n",
        "                output_labels.append(-1)\n",
        "        output_preds = []\n",
        "        for i in all_predictions:\n",
        "            if i == 1:\n",
        "                output_preds.append(i)\n",
        "            else:\n",
        "                output_preds.append(-1)\n",
        "        softmax_scores = [softmax(i) for i in all_scores]\n",
        "        with open(output_dir, \"w\") as file:\n",
        "            output = \"label\\tpredict\\tscore\\n\"\n",
        "            file.write(output)\n",
        "            for i in range(len(output_labels)):\n",
        "                output = str(int(output_labels[i])) + '\\t' + str(int(output_preds[i])) + '\\t' + str(softmax_scores[i][1]) + '\\n'\n",
        "                file.write(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ssW6FE5kHMah"
      },
      "outputs": [],
      "source": [
        "def prep_train_test2(grouped_ids, dev_pct):\n",
        "\n",
        "    np.random.seed(10)\n",
        "    train_ids = []\n",
        "    test_ids = []\n",
        "\n",
        "    for ids in grouped_ids:\n",
        "        shuffle_indices=np.random.permutation(np.arange(len(ids)))\n",
        "        ids_shuffled = ids[shuffle_indices]\n",
        "        dev_idx = -1 * int(dev_pct * float(len(ids)))\n",
        "        ids_train = ids_shuffled[:dev_idx]\n",
        "        ids_test = ids_shuffled[dev_idx:]\n",
        "        train_ids.append(ids_train)\n",
        "        test_ids.append(ids_test)\n",
        "    y_train = [len(train_ids[i]) * [i] for i in range(len(train_ids))]\n",
        "    y_test = [len(test_ids[i]) * [i] for i in range(len(test_ids))]\n",
        "    y_train = list(itertools.chain.from_iterable(y_train))\n",
        "    y_test = list(itertools.chain.from_iterable(y_test))\n",
        "    x_train = torch.tensor(list(itertools.chain.from_iterable(train_ids)))\n",
        "    x_test = torch.tensor(list(itertools.chain.from_iterable(test_ids)))\n",
        "\n",
        "    y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=len(grouped_ids)).float()\n",
        "    y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=len(grouped_ids)).float()\n",
        "\n",
        "    np.random.seed(10)\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(x_train)))\n",
        "    x_train = x_train[shuffle_indices]\n",
        "    y_train = y_train[shuffle_indices]\n",
        "\n",
        "    np.random.seed(10)\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(x_test)))\n",
        "    x_test = x_test[shuffle_indices]\n",
        "    y_test = y_test[shuffle_indices]\n",
        "\n",
        "    # print(\"Train Mal/Ben split: {}/{}\".format(len(pos_train), len(neg_train)))\n",
        "    # print(\"Test Mal/Ben split: {}/{}\".format(len(pos_test), len(neg_test)))\n",
        "    # print(\"Train/Test split: {}/{}\".format(len(y_train), len(y_test)))\n",
        "    # print(\"Train/Test split: {}/{}\".format(len(x_train), len(x_test)))\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIMqO3YzHMaW",
        "outputId": "ac51b1d4-1c62-4b2f-c406-8a81b2db8d28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF1H4B-wHtt4"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kmy_PwTCHMaY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r\"datasets\\MaliciousURL1\\malicious_phish.csv\")\n",
        "df.columns = ['url', 'Topic']\n",
        "class_list = df.Topic.unique()\n",
        "class_id = {t:i for i, t in enumerate(class_list)}\n",
        "id_class = {i:t for i, t in enumerate(class_list)}\n",
        "df['label'] = df.Topic.apply(lambda t: class_id[t])\n",
        "urls = df[\"url\"].values\n",
        "labels = df[\"label\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'phishing': 0, 'benign': 1, 'defacement': 2, 'malware': 3}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWheAfCuHMaZ",
        "outputId": "88a5e2ad-38f8-400e-af44-19037fe6d41a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "IyXEb4IxHMaa"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "    default_max_len_words = 200\n",
        "    max_len_words = default_max_len_words\n",
        "    default_max_len_chars = 200\n",
        "    max_len_chars = default_max_len_chars\n",
        "    default_max_len_subwords = 20\n",
        "    max_len_subwords = default_max_len_subwords\n",
        "    default_min_word_freq = 1\n",
        "    min_word_freq = default_min_word_freq\n",
        "\n",
        "    default_delimit_mode = 1\n",
        "    delimit_mode = default_delimit_mode\n",
        "    default_max_len_words = 200\n",
        "    max_len_words = default_max_len_words\n",
        "    default_max_len_chars = 200\n",
        "    max_len_chars = default_max_len_chars\n",
        "    default_max_len_subwords = 20\n",
        "    max_len_subwords = default_max_len_subwords\n",
        "    default_min_word_freq = 1\n",
        "    min_word_freq = default_min_word_freq\n",
        "    default_dev_pct = 0.001\n",
        "    dev_pct=0.1 # default_dev_pct\n",
        "\n",
        "    # model args\n",
        "    default_emb_dim = 32\n",
        "    emb_dim = default_emb_dim\n",
        "    default_filter_sizes = \"3,4,5,6\"\n",
        "    filter_sizes = default_filter_sizes\n",
        "    default_emb_mode = 5\n",
        "    emb_mode = default_emb_mode\n",
        "\n",
        "    # train args\n",
        "    default_nb_epochs = 5\n",
        "    nb_epochs = default_nb_epochs\n",
        "    default_batch_size = 1024\n",
        "    batch_size = default_batch_size\n",
        "    l2_reg_lambda = 0.0\n",
        "    default_lr = 0.001\n",
        "    lr = default_lr\n",
        "\n",
        "    # log args\n",
        "    output_dir = r\"scripts\\URLNet\\outputs\"\n",
        "    print_every = 50\n",
        "    eval_every = 500\n",
        "    checkpoint_every = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVe58FCiHMab",
        "outputId": "dc79a03f-691d-4770-d820-299ad11d9f7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['uk', 'linkedin', 'com', 'pub', 'steve-rubenstein', '8', '718', '755']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "class SepTokenizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.splitter = re.compile(r'[/?.=-_]+')\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.splitter.split(text)\n",
        "\n",
        "tokenizer = SepTokenizer()\n",
        "tokenizer('uk.linkedin.com/pub/steve-rubenstein/8/718/755')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "high_freq_words = None\n",
        "curpath = os.path.abspath(os.curdir)\n",
        "abs_path = os.path.join(curpath, r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\word_x.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ODfM1_CPS_MY"
      },
      "outputs": [],
      "source": [
        "if Path(r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\word_x.pkl\").is_file():\n",
        "  with open(fr'{abs_path}', 'rb') as f:\n",
        "    word_x2 = pickle.load(f)\n",
        "else:\n",
        "  x, word_reverse_dict = get_word_vocab(urls[:], max_len_words, tokenizer)\n",
        "  word_x2 = get_words(x, word_reverse_dict, delimit_mode, urls)\n",
        "  for i in range(len(word_x2)):\n",
        "    if i%100000==0:\n",
        "      print(i)\n",
        "    if len(word_x2[i])> max_len_words:\n",
        "        word_x2[i] = word_x2[i][:max_len_words]\n",
        "    while len(word_x2[i]) < max_len_words:\n",
        "        word_x2[i].append('❿')\n",
        "  clear_output()\n",
        "  with open(fr'{abs_path}', 'wb') as f:\n",
        "    pickle.dump(word_x2, f)\n",
        "\n",
        "if Path(r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\ngrams_dict.pkl\").is_file():\n",
        "  with open(os.path.join(curpath, r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\ngrams_dict.pkl\"), 'rb') as f:\n",
        "    ngrams_dict = pickle.load(f)\n",
        "  with open(os.path.join(curpath, r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\words_dict.pkl\"), 'rb') as f:\n",
        "    words_dict = pickle.load(f)\n",
        "else:\n",
        "  ngrams_dict, words_dict, ngramed_x, worded_x = ngram_id_x_dicts(word_x2, max_len_subwords, high_freq_words)\n",
        "  with open(os.path.join(curpath, r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\ngrams_dict.pkl\"), 'wb') as f:\n",
        "    pickle.dump(ngrams_dict, f)\n",
        "  with open(os.path.join(curpath, r\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\words_dict.pkl\"), 'wb') as f:\n",
        "    pickle.dump(words_dict, f)\n",
        "    \n",
        "chars_dict = ngrams_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if Path(rf\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\chared_id_x.pt\").is_file():\n",
        "    chared_id_x = torch.load(rf'TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\chared_id_x.pt')\n",
        "else:\n",
        "    chared_id_x = char_id_x(urls, chars_dict, max_len_chars)\n",
        "    torch.save(chared_id_x, rf'TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\chared_id_x.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_x3 = word_x2[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngramed_id_x = torch.zeros((len(word_x2), len(word_x2[0]), max_len_subwords), dtype=torch.int32)\n",
        "worded_id_x = torch.zeros((len(word_x2), len(word_x2[0])), dtype=torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "0 50000\n"
          ]
        }
      ],
      "source": [
        "intervals = 50000\n",
        "previous = 0\n",
        "for i in range(intervals, len(word_x3)+intervals, intervals):\n",
        "    i = min(i, len(word_x3))\n",
        "    if Path(rf\"TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\ngramed_id_x_{previous}_{i}.pt\").is_file():\n",
        "        print(\"True\")\n",
        "        ngramed_id_x[previous:i] = torch.load(rf'TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\ngramed_id_x_{previous}_{i}.pt')\n",
        "        worded_id_x[previous:i] = torch.load(rf'TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\worded_id_x_{previous}_{i}.pt')\n",
        "    else:\n",
        "        print(\"False\")\n",
        "        word_x = word_x3[previous:i]\n",
        "        _, _, ngramed_x, worded_x = ngram_id_x_dicts(word_x, max_len_subwords, high_freq_words)\n",
        "        ngramed_id_x[previous:i], worded_id_x[previous:i] = ngram_id_x(ngrams_dict, words_dict, ngramed_x, worded_x, max_len_subwords)\n",
        "        torch.save(ngramed_id_x[previous:i], rf'TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\ngramed_id_x_{previous}_{i}.pt')\n",
        "        torch.save(worded_id_x[previous:i], rf'TestsOnMaliciousURL1\\tempURLNET\\ProcessedData\\worded_id_x_{previous}_{i}.pt')\n",
        "    \n",
        "    print(previous, i)\n",
        "    previous = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "524CQoBgHMah",
        "outputId": "ddc5f15f-d3a7-4f36-d81a-90a1e95402db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall phishing/benign/defacement/malware split: 94111/428103/96457/32520\n"
          ]
        }
      ],
      "source": [
        "y_splits = [[] for i in range(len(class_list))]\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    y_splits[labels[i]].append(i)\n",
        "\n",
        "y_splits = [np.array(splt) for splt in y_splits]\n",
        "\n",
        "\n",
        "print(f\"Overall {class_list[0]}/{class_list[1]}/{class_list[2]}/{class_list[3]} split: {len(y_splits[0])}/{len(y_splits[1])}/{len(y_splits[2])}/{len(y_splits[3])}\")\n",
        "\n",
        "x_train, y, x_test, y_test = prep_train_test2(y_splits, dev_pct)\n",
        "\n",
        "x_char = get_ngramed_id_x(x_train, ngramed_id_x)\n",
        "x_test_char = get_ngramed_id_x(x_test, ngramed_id_x)\n",
        "\n",
        "x_word = get_ngramed_id_x(x_train, worded_id_x)\n",
        "x_test_word = get_ngramed_id_x(x_test, worded_id_x)\n",
        "\n",
        "x_char_seq = get_ngramed_id_x(x_train, chared_id_x)\n",
        "x_test_char_seq = get_ngramed_id_x(x_test, chared_id_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaCGcTlWHMai",
        "outputId": "cc14ab35-cd55-4c94-d6cb-b35b8aafae8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(np.sum(~(labels[x_test] == np.argmax(y_test.numpy(), axis=1))))\n",
        "print(np.sum(~(labels[x_train] == np.argmax(y.numpy(), axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hdP9xhsUHMai"
      },
      "outputs": [],
      "source": [
        "class URLNetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, emb_mode, x_char_seq, x_word, x_char, y) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if emb_mode == 1:\n",
        "            self.dataset = TensorDataset(x_char_seq, y)\n",
        "        elif emb_mode == 2:\n",
        "            self.dataset = TensorDataset(x_word, y)\n",
        "        elif emb_mode == 3:\n",
        "            self.dataset = TensorDataset(x_char_seq, x_word, y)\n",
        "        elif emb_mode == 4:\n",
        "            self.dataset = TensorDataset(x_word, x_char, y) #, char_pad_idx\n",
        "        elif emb_mode == 5:\n",
        "            self.dataset = TensorDataset(x_char_seq, x_word, x_char, y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VZF6MjQcHMaj"
      },
      "outputs": [],
      "source": [
        "train_dataset = URLNetDataset(emb_mode, x_char_seq, x_word, x_char, y)\n",
        "test_dataset = URLNetDataset(emb_mode, x_test_char_seq, x_test_word, x_test_char, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EvvgsvbsHMaj"
      },
      "outputs": [],
      "source": [
        "_ = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "A22F6ELOHMak"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, char_ngram_vocab_size, word_ngram_vocab_size, char_vocab_size,\n",
        "                 word_seq_len, char_seq_len, embedding_size, l2_reg_lambda=0,\n",
        "                 filter_sizes=[3, 4, 5, 6], mode=0, num_classes=2):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.word_seq_len = word_seq_len\n",
        "        self.char_seq_len = char_seq_len\n",
        "        self.embedding_size = embedding_size\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        if mode in [4, 5]:\n",
        "            self.char_embedding = nn.Embedding(char_ngram_vocab_size+1, embedding_size)\n",
        "            torch.nn.init.uniform_(self.char_embedding.weight)\n",
        "        if mode in [2, 3, 4, 5]:\n",
        "            self.word_embedding = nn.Embedding(word_ngram_vocab_size+1, embedding_size)\n",
        "            torch.nn.init.uniform_(self.word_embedding.weight)\n",
        "        if mode in [1, 3, 5]:\n",
        "            self.char_seq_embedding = nn.Embedding(char_vocab_size+1, embedding_size)\n",
        "            torch.nn.init.uniform_(self.char_seq_embedding.weight)\n",
        "\n",
        "        self.dropout_keep_prob = nn.Dropout(0.5)\n",
        "        self.num_filters_total = 256 * len(filter_sizes)\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        for filter_size in filter_sizes:\n",
        "            conv = nn.Conv1d(embedding_size, 256, filter_size, padding=\"valid\")\n",
        "            nn.init.trunc_normal_(conv.weight, std=0.1)\n",
        "            nn.init.constant_(conv.bias, 0.1)\n",
        "            self.conv_layers.append(conv)\n",
        "\n",
        "        if mode in [3, 5]:\n",
        "            self.fc_word = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "            torch.nn.init.xavier_normal_(self.fc_word.weight)\n",
        "            torch.nn.init.constant_(self.fc_word.bias, 0.1)\n",
        "            self.fc_char = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "            torch.nn.init.xavier_normal_(self.fc_char.weight)\n",
        "            torch.nn.init.constant_(self.fc_char.bias, 0.1)\n",
        "            # self.fc_concat = nn.Linear(1024, 512)\n",
        "        # elif mode in [2, 4]:\n",
        "        #     self.fc = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "        # elif mode == 1:\n",
        "        #     self.fc = nn.Linear(len(filter_sizes) * 256, 512)\n",
        "\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
        "        torch.nn.init.constant_(self.fc1.bias, 0.1)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
        "        torch.nn.init.constant_(self.fc2.bias, 0.1)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        torch.nn.init.xavier_normal_(self.fc3.weight)\n",
        "        torch.nn.init.constant_(self.fc3.bias, 0.1)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
        "        torch.nn.init.constant_(self.fc2.bias, 0.1)\n",
        "\n",
        "    def forward(self, x_word=None, x_char=None, x_char_seq=None, x_char_pad_idx=None):\n",
        "        pooled_x = []\n",
        "\n",
        "        if self.mode in [4, 5]:\n",
        "            x_char = self.char_embedding(x_char)\n",
        "            # x_char = x_char * x_char_pad_idx\n",
        "\n",
        "        if self.mode in [2, 3, 4, 5]:\n",
        "            x_word = self.word_embedding(x_word)\n",
        "\n",
        "        if self.mode in [1, 3, 5]:\n",
        "            x_char_seq = self.char_seq_embedding(x_char_seq)\n",
        "\n",
        "        if self.mode in [4, 5]:\n",
        "            x_char = torch.sum(x_char, dim=2)\n",
        "            x_combined = x_char + x_word\n",
        "            x_combined = torch.permute(x_combined, (0, 2, 1))\n",
        "            # x_combined = x_combined.unsqueeze(1)\n",
        "        if self.mode in [2, 3]:\n",
        "            x_combined = torch.permute(x_word, (0, 2, 1))\n",
        "            # x_combined = x_word.unsqueeze(1)\n",
        "        if self.mode in [1, 3, 5]:\n",
        "            char_x_expanded = torch.permute(x_char_seq, (0, 2, 1))\n",
        "            # char_x_expanded = x_char_seq.unsqueeze(1)\n",
        "\n",
        "        if self.mode == 2 or self.mode == 3 or self.mode == 4 or self.mode == 5:\n",
        "\n",
        "            for i, conv in enumerate(self.conv_layers):\n",
        "                h = F.relu(conv(x_combined))\n",
        "                pooled = F.max_pool2d(h, (1, self.word_seq_len - self.filter_sizes[i] + 1))\n",
        "                pooled_x.append(pooled)\n",
        "\n",
        "            h_pooled = torch.cat(pooled_x, 1) #?\n",
        "            h_pooled = h_pooled.squeeze(2) #?\n",
        "\n",
        "            x_flat = torch.reshape(h_pooled, [h_pooled.shape[0], -1])\n",
        "            h_drop = self.dropout_keep_prob(x_flat)\n",
        "\n",
        "\n",
        "        if self.mode == 1 or self.mode == 3 or self.mode == 5:\n",
        "            pooled_char_x = []\n",
        "            for i, conv in enumerate(self.conv_layers):\n",
        "                h = F.relu(conv(char_x_expanded))\n",
        "                pooled = F.max_pool2d(h, (1, self.char_seq_len - self.filter_sizes[i] + 1))\n",
        "                pooled_char_x.append(pooled)\n",
        "\n",
        "            h_char_pool = torch.cat(pooled_char_x, 1) #?\n",
        "            h_char_pool = h_char_pool.squeeze(2) #?\n",
        "            # h_char_pool = h_char_pool.squeeze(2) #?\n",
        "\n",
        "            char_x_flat = torch.reshape(h_char_pool, [h_char_pool.shape[0], -1])\n",
        "            char_h_drop = self.dropout_keep_prob(char_x_flat)\n",
        "\n",
        "        # if self.mode in [3, 5]:\n",
        "        #     word_output = F.relu(self.fc_word(self.dropout(h_pooled)))\n",
        "        #     char_output = F.relu(self.fc_char(self.dropout(h_pooled)))\n",
        "        #     conv_output = torch.cat([word_output, char_output], 1)\n",
        "        if self.mode in [3, 5]:\n",
        "            word_output = self.fc_word(h_drop)\n",
        "            char_output = self.fc_char(char_h_drop)\n",
        "            conv_output = torch.cat([word_output, char_output], 1)\n",
        "        elif self.mode in [2, 4]:\n",
        "            conv_output = h_drop\n",
        "        elif self.mode == 1:\n",
        "            conv_output = char_h_drop\n",
        "        # else:\n",
        "        #     conv_output = F.relu(self.fc(self.dropout(h_pooled)))\n",
        "\n",
        "        output0 = F.relu(self.fc1(conv_output))\n",
        "        output1 = F.relu(self.fc2(output0))\n",
        "        output2 = F.relu(self.fc3(output1))\n",
        "        scores = self.fc4(output2)\n",
        "\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Hk30WSW-HMal"
      },
      "outputs": [],
      "source": [
        "# cnn = TextCNN(\n",
        "#                 char_ngram_vocab_size = len(ngrams_dict)+1,\n",
        "#                 word_ngram_vocab_size = len(words_dict)+1,\n",
        "#                 char_vocab_size = len(chars_dict)+1,\n",
        "#                 embedding_size=emb_dim,\n",
        "#                 word_seq_len=max_len_words,\n",
        "#                 char_seq_len=max_len_chars,\n",
        "#                 l2_reg_lambda=l2_reg_lambda,\n",
        "#                 mode=emb_mode,\n",
        "#                 filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
        "#                 num_classes=4)\n",
        "\n",
        "# optimizer = torch.optim.Adam(cnn.parameters(), lr=lr, weight_decay=l2_reg_lambda)\n",
        "# loss_func = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfKVgs3SHMal",
        "outputId": "6b1958d9-581b-4945-a953-ecf99267e403"
      },
      "outputs": [],
      "source": [
        "# if emb_mode == 1:\n",
        "#     print(cnn(x_char_seq=_[0]).shape)\n",
        "# elif emb_mode == 2:\n",
        "#     print(cnn(x_word=_[0]).shape)\n",
        "# elif emb_mode == 3:\n",
        "#     print(cnn(x_char_seq=_[0], x_word=_[1]).shape)\n",
        "# elif emb_mode == 4:\n",
        "#     print(cnn(x_word=_[0], x_char=_[1]).shape)\n",
        "# elif emb_mode == 5:\n",
        "#     print(cnn(x_char_seq=_[0], x_word=_[1], x_char=_[2]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1mhbrgqTHMal"
      },
      "outputs": [],
      "source": [
        "# from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
        "import torchmetrics\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "import pytorch_lightning as L\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2N7gt4IyHMan"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassifierLightningModel(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        num_classes,\n",
        "        optimizer=None,\n",
        "        loss_func=None,\n",
        "        learning_rate=0.01,\n",
        "        batch_size=64,\n",
        "        lr_scheduler=None,\n",
        "        user_lr_scheduler=False,\n",
        "        min_lr=0.0,\n",
        "    ):\n",
        "        super(ClassifierLightningModel, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = model\n",
        "        self.min_lr = min_lr\n",
        "        # self.save_hyperparameters(ignore=[\"model\"])\n",
        "        self.save_hyperparameters(\"model\", logger=False)\n",
        "        self.optimizer = self._get_optimizer(optimizer)\n",
        "        self.lr_scheduler = (\n",
        "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
        "        )\n",
        "        self.loss_func = loss_func\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x_word=None, x_char=None, x_char_seq=None, x_char_pad_idx=None, *args, **kwargs):\n",
        "        return self.model(x_word, x_char, x_char_seq, x_char_pad_idx)\n",
        "\n",
        "    # def on_train_epoch_start(self) -> None:\n",
        "    #     param_groups = next(iter(self.optimizer.param_groups))\n",
        "    #     if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
        "    #         current_learning_rate = float(param_groups[\"lr\"])\n",
        "    #         self.log(\n",
        "    #             \"lr\",\n",
        "    #             current_learning_rate,\n",
        "    #             batch_size=self.batch_size,\n",
        "    #             on_epoch=True,\n",
        "    #             on_step=False,\n",
        "    #         )\n",
        "\n",
        "    def run_model(self, batch):\n",
        "        if emb_mode == 1:\n",
        "            return self(x_char_seq=batch[0])\n",
        "        elif emb_mode == 2:\n",
        "            return self(x_word=batch[0])\n",
        "        elif emb_mode == 3:\n",
        "            return self(x_char_seq=batch[0], x_word=batch[1])\n",
        "        elif emb_mode == 4:\n",
        "            return self(x_word=batch[0], x_char=batch[1])\n",
        "        elif emb_mode == 5:\n",
        "            return self(x_char_seq=batch[0], x_word=batch[1], x_char=batch[2])\n",
        "\n",
        "    def training_step(self, batch, *args, **kwargs):\n",
        "        for i in range(len(batch)):\n",
        "            batch[i] = batch[i].to(self.device)\n",
        "\n",
        "        self.model.train()\n",
        "        y_out = self.run_model(batch)\n",
        "\n",
        "        loss = self.loss_func(y_out.view(batch[-1].shape), batch[-1])\n",
        "        self.train_losses.append(loss.detach().item())\n",
        "        self.log(\n",
        "            \"train_loss\",\n",
        "            loss,\n",
        "            prog_bar=True,\n",
        "            batch_size=self.batch_size,\n",
        "            on_epoch=True,\n",
        "            on_step=True,\n",
        "        )\n",
        "\n",
        "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(batch[-1], dim=1))\n",
        "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, *args, **kwargs):\n",
        "        for i in range(len(batch)):\n",
        "            batch[i] = batch[i].to(self.device)\n",
        "\n",
        "        self.model.eval()\n",
        "        y_out = self.run_model(batch)\n",
        "        loss = self.loss_func(y_out.view(batch[-1].shape), batch[-1])\n",
        "        self.val_losses.append(loss.detach().item())\n",
        "\n",
        "        self.log(\n",
        "            \"val_loss\",\n",
        "            loss,\n",
        "            prog_bar=True,\n",
        "            batch_size=self.batch_size,\n",
        "            on_epoch=True\n",
        "        )\n",
        "\n",
        "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(batch[-1], dim=1))\n",
        "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, batch_size=self.batch_size)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.lr_scheduler is None:\n",
        "            return self.optimizer\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": self.optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": self.lr_scheduler,\n",
        "                \"monitor\": \"train_loss\",\n",
        "                \"interval\": \"epoch\",\n",
        "                \"frequency\": 1,\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def update_learning_rate(self, learning_rate: float):\n",
        "        self.learning_rate = learning_rate\n",
        "        for g in self.optimizer.param_groups:\n",
        "            g[\"lr\"] = learning_rate\n",
        "\n",
        "    def _get_optimizer(self, optimizer):\n",
        "        return (\n",
        "            optimizer\n",
        "            if optimizer is not None\n",
        "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        )\n",
        "\n",
        "    def _get_lr_scheduler(self, lr_scheduler):\n",
        "        return (\n",
        "            lr_scheduler\n",
        "            if lr_scheduler is not None\n",
        "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
        "            )\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-OK4zTeHMao",
        "outputId": "5c496b0e-5d58-4a5c-f89a-f6b57b887f83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "seed = 911\n",
        "# for i in range(5):\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss',mode='min',patience=25),\n",
        "    # CustomModelCheckpoint(dirpath=r'models\\malicious_urls_model', filename=f'malicious_urls_model_', every_n_epochs=3, mode='min', monitor='val_loss_epoch', save_on_train_epoch_end=True),\n",
        "    ModelCheckpoint(save_top_k=5, mode='min', monitor='val_loss', save_last=True)\n",
        "    ]\n",
        "classifier_torch_model = TextCNN(\n",
        "                char_ngram_vocab_size = len(ngrams_dict)+1,\n",
        "                word_ngram_vocab_size = len(words_dict)+1,\n",
        "                char_vocab_size = len(chars_dict)+1,\n",
        "                embedding_size=emb_dim,\n",
        "                word_seq_len=max_len_words,\n",
        "                char_seq_len=max_len_chars,\n",
        "                l2_reg_lambda=l2_reg_lambda,\n",
        "                mode=emb_mode,\n",
        "                filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
        "                num_classes=len(class_id)).to(device)\n",
        "\n",
        "# classifier_torch_model = CNN_for_Text(num_embedding=len(vocab_dict), batch_size=batch_size, hidden_dim=hidden_dim, embedding_dim=embedding_dim, max_char_count=256, dropout=0.15, num_out_features=len(class_id), kernel_size=[5, 5, 5, 3], seed=seed)\n",
        "optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=0.00011)\n",
        "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30, 40, 50, 60, 70],gamma=0.5)\n",
        "loss_func = torch.nn.BCEWithLogitsLoss()\n",
        "classfier_lightning_model = ClassifierLightningModel(classifier_torch_model,\n",
        "                                                    num_classes=len(class_id),\n",
        "                                            learning_rate=lr,\n",
        "                                            batch_size=batch_size,\n",
        "                                            optimizer=optimizer,\n",
        "                                            loss_func=loss_func,\n",
        "                                            lr_scheduler=lr_scheduler,\n",
        "                                            user_lr_scheduler=True\n",
        "                                            ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "trainer = L.Trainer(\n",
        "            callbacks=callbacks,\n",
        "            max_epochs=80,\n",
        "            accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
        "            logger=CSVLogger(save_dir='logs/', name='log2')\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = next(iter(test_dataloader))\n",
        "flopt_counter = FlopCounterMode(classfier_lightning_model.model)\n",
        "for i in range(len(_)):\n",
        "    _[i] = _[i].to(device)\n",
        "with flopt_counter:\n",
        "    classfier_lightning_model.model(x_char_seq=_[0], x_word=_[1], x_char=_[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "01034ab9e5314a1e85ef1183c32f5750",
            "e0b7c96dd59549fb9cd2ef8f285c9f58",
            "9939119df4d347cdb867d49ac5f6aa8d",
            "6c0db405b45c4c599015ceb5e2270c07",
            "d99b67f41ad64f7c8ba8e8969253809d",
            "39381680356d46d3a02e5aa728424d8e",
            "37f37e6ce5304003a724eb6930e79cb8",
            "5261e91e698e4855b58165dc7ba171cd",
            "304738c44b3a463693916f685acbd8d1",
            "fc6455a9aed34ad7ae30b6b69af8029f",
            "a846982fc12b4152b7ec9080d543cfd3",
            "661b880ef2f24f2db905f76221bb0ce0",
            "bf291d062eb84f188ce18d55dbaf1775",
            "7757a408fd6842f4a72218128305e267",
            "1bc534be68d444c1910416cc4e479c5f",
            "2cbc94f9c3e64677a6439872c8adad6f",
            "060b7dc64f884d62bdc3f37c78e8d5c8",
            "7af71962ac4a49e4a2eb7869687e5a4d",
            "baa32d9dd2c24dd589059ffc5cbc020f",
            "c7c542b10d8f43aba5fe85449af9590b",
            "34e5a744936c4ea9b72efce0fd957253",
            "5e15db0627a0462a9645b41d805c693a",
            "8f2a12038fda473a8c66203314174795",
            "3adba4e9e2c740e5af4986affb98e8b4",
            "2fdba9d903b7446392c18c1533a5b760",
            "43d047c5404e437abb763be00cd6b84c",
            "4a715c3beb424270989dece71ef6cad4",
            "33b9ff0234d040d8bf8de7d9d92b6ebc",
            "514cf467377c434789c8e9d31f766872",
            "7126c8d4733c4b539da66c868395d2ec",
            "c7466d893776499ab6cba653a237c99e",
            "377223d3186047138fe539c1cfa7ba0a",
            "3c1dc5d88a6040b7a002e57f68667f94"
          ]
        },
        "id": "0ARojS7SHMaq",
        "outputId": "0e916d1f-dcb1-47f3-aab0-c18930353af1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params\n",
            "-------------------------------------------------\n",
            "0 | model     | TextCNN            | 19.4 M\n",
            "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
            "2 | train_acc | MulticlassAccuracy | 0     \n",
            "3 | val_acc   | MulticlassAccuracy | 0     \n",
            "4 | test_acc  | MulticlassAccuracy | 0     \n",
            "-------------------------------------------------\n",
            "19.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "19.4 M    Total params\n",
            "77.508    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad49a2797a2d425a926a102a8f130710",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9de3264b842f480b8edd31a0f2a78fbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0099cba8c5fa4446a652133711ce0a28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a8938ee8b1b44349066bcc3358ec5a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2edabbed12754af38baeb94dc7254364",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "259e760a737449d397ca5e7295ddd9ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4247ec961376411da91f4eb1327de664",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7863d9289fd74f7caa2fe3c10996acdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e755242a45e45de97b095bfa6ef35f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fa362ca51104f9eb4cf3907e42ad1c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be28be9302d641d6a1214bbbc9b0ee43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5a6d10e41574b30873b288990dc6285",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf66f0a8d57f42738d196a59eabc9720",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a11616c6abce402f9b09f8b290946145",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04d9ce0a6ec84886979e18a186ff7b04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82aa5d97f35d403084386d1ee3740c35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47c012fb62ef41cd8eae038c70a54e64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0580cf7caad8448cb7232dd55e9f967f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0659922c92834e088d8601fb09b31655",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803db3e04b354249873a68062ae9832f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74e430297d434991802ac1f541d5e4b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f03c880304b24cc991bb470118ec9712",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "862cb9b38dea4cc293dc26401967f25f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e610b2f7bca41e789037968662506d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e304720156b48aaa6064a41f6f7d134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c66e7bf91b974792991b2c948c987394",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7103fe58ee5947d0ab530827d79791b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6944081f491453682af87581a73d7ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a20a2a2c73f4c73a4982f1052996473",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21dd8890870c427a9c0e812109ccdf5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "888b1a45c17e4139993efb0f556528d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f17e3ccc9a84e1b8d47aeb28fada3af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c470baabfdc242649a4735ad7e4dd638",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "647effccc0644653a5c3b93f4bb1b3a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4ccb2f384b046369d94c90a69479abe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70dced0a9e48495a8454976d3649e212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f34a1881b2ee49bd827e6629202a4da4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a53e21f9eb34734be30f0dacaabf252",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4ced68246fc47b8bc8fbe125f9a8eca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5318d8af47234fe789f9c7700d42053e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e8883ac5f1642108e9f8252c7a9fc5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6928d3ddf994550b5a9ace8cf279911",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3b037417f4e452ba9ce4703e8d49ac9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8737bc7598414f2d863be28eb693922b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65bb24a1fbe74022bbfe5c19cb09e9cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60ed1d1000d748c3b86bcaca8f270c00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb49c3811cac44be94d7e972e8416596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63ab00075fee4463968a44572f25ec64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae9a96be9c1a4daba32708f9c393cf6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb44000a582e4d25aa78f6f899221733",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4f6025f0e1b470e9c9373ee17e667fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94221faf293d436b88460c14e0a165d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5772ac49d59b42288a1c7bf38c82fd2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9db54f3b5de44e0f8641003253b7fe05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25cbb5b167db4584aa21ead539d0ffa1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cf8daabd6cd4c53b4637bc3394d5e4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69245458a8004938aa5d1b1988c5dbf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eed57ee5da0445cf872f924da15b8b61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56e75fc7c65146269556e40744476e74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80f3bd460acc420aaa917be3045eff1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8ff3810bf24e2db2586f120b6b6e43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55b42b32d8b14fadbf1e71d099cb7a55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8654d6848be045d8944993bb21913dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31ce4cd9f0924ca2a0446f23d43e9c5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05ed44a39a7c424cb40966ac83c3b5e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "435941d78cfd4a00a5aa31446854253d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f86dee01cb41abb72137bbcee311e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db707ea7dc0547a88d63fd10efc1d140",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1793192978da458380eae1f4671107d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8291ca90ad4a45aba2197d0780f945e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e3cf1942ab740099e906324d8d4d7ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2867a9f1e1f9440b91a645bfdca82f9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c04355dc31349429d629fba51801d88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c56d6bc1fbf4aeeb0333d19ae0da108",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a2e750c577442d916c36f659c8403c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bfb3af4e03b440e87f91c25c6f7c9e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "WhLaNnjiHMaq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from torchmetrics.classification import ConfusionMatrix\n",
        "def calculate_metrics(cl_model):\n",
        "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
        "\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    cl_model = cl_model.eval()\n",
        "    cl_model.to(device)\n",
        "    for _ in tqdm(test_dataloader):\n",
        "        for i in range(len(_)):\n",
        "            _[i] = _[i].to(device)\n",
        "        with torch.no_grad():\n",
        "            y_p = cl_model.run_model(_)\n",
        "            y_p = y_p.cpu()\n",
        "        y_pred.append(y_p)\n",
        "        y_true.append(_[-1].cpu())\n",
        "    y_pred = torch.cat(y_pred, dim=0)\n",
        "    y_true = torch.cat(y_true, dim=0)\n",
        "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
        "    y_true2 = torch.argmax(y_true, dim=1)\n",
        "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
        "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
        "    print('================================')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "G6hpkHJtHMaq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:09<00:00,  6.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9668    0.9508    0.9587      9411\n",
            "           1     0.9901    0.9954    0.9927     42810\n",
            "           2     0.9958    0.9990    0.9974      9645\n",
            "           3     0.9959    0.9640    0.9797      3252\n",
            "\n",
            "    accuracy                         0.9879     65118\n",
            "   macro avg     0.9871    0.9773    0.9821     65118\n",
            "weighted avg     0.9878    0.9879    0.9878     65118\n",
            "\n",
            "confusion matrix:\n",
            " tensor([[ 8948,   416,    39,     8],\n",
            "        [  194, 42612,     1,     3],\n",
            "        [    7,     1,  9635,     2],\n",
            "        [  106,    10,     1,  3135]])\n",
            "================================\n"
          ]
        }
      ],
      "source": [
        "classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
        "classfier_lightning_model = classfier_lightning_model.eval()\n",
        "calculate_metrics(classfier_lightning_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9821755548768072"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = 0.9871\n",
        "r = 0.9773\n",
        "(2*p*r)/(p+r)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01034ab9e5314a1e85ef1183c32f5750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0b7c96dd59549fb9cd2ef8f285c9f58",
              "IPY_MODEL_9939119df4d347cdb867d49ac5f6aa8d",
              "IPY_MODEL_6c0db405b45c4c599015ceb5e2270c07"
            ],
            "layout": "IPY_MODEL_d99b67f41ad64f7c8ba8e8969253809d"
          }
        },
        "060b7dc64f884d62bdc3f37c78e8d5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc534be68d444c1910416cc4e479c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e5a744936c4ea9b72efce0fd957253",
            "placeholder": "​",
            "style": "IPY_MODEL_5e15db0627a0462a9645b41d805c693a",
            "value": " 1/8 [00:19&lt;02:15,  0.05it/s, v_num=0, train_loss_step=0.471, train_acc_step=0.754, val_loss=0.492, val_acc=0.733, train_loss_epoch=1.460, train_acc_epoch=0.602]"
          }
        },
        "2cbc94f9c3e64677a6439872c8adad6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2fdba9d903b7446392c18c1533a5b760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7126c8d4733c4b539da66c868395d2ec",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7466d893776499ab6cba653a237c99e",
            "value": 2
          }
        },
        "304738c44b3a463693916f685acbd8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33b9ff0234d040d8bf8de7d9d92b6ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e5a744936c4ea9b72efce0fd957253": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377223d3186047138fe539c1cfa7ba0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f37e6ce5304003a724eb6930e79cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39381680356d46d3a02e5aa728424d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3adba4e9e2c740e5af4986affb98e8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b9ff0234d040d8bf8de7d9d92b6ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_514cf467377c434789c8e9d31f766872",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "3c1dc5d88a6040b7a002e57f68667f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43d047c5404e437abb763be00cd6b84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377223d3186047138fe539c1cfa7ba0a",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1dc5d88a6040b7a002e57f68667f94",
            "value": " 2/2 [00:14&lt;00:00,  0.14it/s]"
          }
        },
        "4a715c3beb424270989dece71ef6cad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "514cf467377c434789c8e9d31f766872": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5261e91e698e4855b58165dc7ba171cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e15db0627a0462a9645b41d805c693a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "661b880ef2f24f2db905f76221bb0ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf291d062eb84f188ce18d55dbaf1775",
              "IPY_MODEL_7757a408fd6842f4a72218128305e267",
              "IPY_MODEL_1bc534be68d444c1910416cc4e479c5f"
            ],
            "layout": "IPY_MODEL_2cbc94f9c3e64677a6439872c8adad6f"
          }
        },
        "6c0db405b45c4c599015ceb5e2270c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6455a9aed34ad7ae30b6b69af8029f",
            "placeholder": "​",
            "style": "IPY_MODEL_a846982fc12b4152b7ec9080d543cfd3",
            "value": " 2/2 [00:14&lt;00:00,  0.14it/s]"
          }
        },
        "7126c8d4733c4b539da66c868395d2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7757a408fd6842f4a72218128305e267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa32d9dd2c24dd589059ffc5cbc020f",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c542b10d8f43aba5fe85449af9590b",
            "value": 1
          }
        },
        "7af71962ac4a49e4a2eb7869687e5a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f2a12038fda473a8c66203314174795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3adba4e9e2c740e5af4986affb98e8b4",
              "IPY_MODEL_2fdba9d903b7446392c18c1533a5b760",
              "IPY_MODEL_43d047c5404e437abb763be00cd6b84c"
            ],
            "layout": "IPY_MODEL_4a715c3beb424270989dece71ef6cad4"
          }
        },
        "9939119df4d347cdb867d49ac5f6aa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5261e91e698e4855b58165dc7ba171cd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_304738c44b3a463693916f685acbd8d1",
            "value": 2
          }
        },
        "a846982fc12b4152b7ec9080d543cfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa32d9dd2c24dd589059ffc5cbc020f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf291d062eb84f188ce18d55dbaf1775": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060b7dc64f884d62bdc3f37c78e8d5c8",
            "placeholder": "​",
            "style": "IPY_MODEL_7af71962ac4a49e4a2eb7869687e5a4d",
            "value": "Epoch 1:  12%"
          }
        },
        "c7466d893776499ab6cba653a237c99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7c542b10d8f43aba5fe85449af9590b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d99b67f41ad64f7c8ba8e8969253809d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "e0b7c96dd59549fb9cd2ef8f285c9f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39381680356d46d3a02e5aa728424d8e",
            "placeholder": "​",
            "style": "IPY_MODEL_37f37e6ce5304003a724eb6930e79cb8",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "fc6455a9aed34ad7ae30b6b69af8029f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
