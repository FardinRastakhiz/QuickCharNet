{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "dataset_dir = r'C:\\Users\\fardin\\Projects\\EnhanceSEO\\datasets\\extractedURLs\\url_classes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from torchvision import datasets\n",
    "# from torchtext.datasets import AG_NEWS\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import BertTokenizer\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 47.9kB/s]\n",
      "config.json: 100%|██████████| 570/570 [00:00<00:00, 569kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:02<00:00, 109kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:04<00:00, 115kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 440M/440M [08:38<00:00, 850kB/s] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "  \"bert-base-uncased\",\n",
    "  trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_text_and_labels(input_data):\n",
    "#     labels = []\n",
    "#     data = []\n",
    "#     for label, d in input_data:\n",
    "#         labels.append(label)\n",
    "#         data.append(d)\n",
    "#     labels = pd.DataFrame(labels, columns=['labels'], dtype=int)\n",
    "#     data = pd.DataFrame(data, columns=['descriptions'], dtype=str)\n",
    "#     return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data\\CrawledWeb\\TopicClassification\\URLClassification\\url_classes.csv')\n",
    "# df.columns = ['Topic', 'Address']\n",
    "df.dropna(inplace=True)\n",
    "class_list = df.Topic.unique()\n",
    "class_id = {t:i for i, t in enumerate(class_list)}\n",
    "id_class = {i:t for i, t in enumerate(class_list)}\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 1024\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = lambda s: list(urlparse(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = \"this is a sample sentence, do you understand this?\"\n",
    "# tokenizer = TweetTokenizer()\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# for i in range(10000):\n",
    "#     # tokens = word_tokenize(doc)\n",
    "#     tokens = tokenizer.tokenize(doc)\n",
    "#     [lemmatizer.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VocabFactory():\n",
    "    \n",
    "#     def __init__(self) -> None:\n",
    "#         self.tokens_dict = {}\n",
    "#         self.lemmatizer = WordNetLemmatizer()\n",
    "#         self.vocab_id = {}\n",
    "#         self.id_vocab = {}\n",
    "    \n",
    "#     def create_vocab(self, documents, vocab_count=10000):\n",
    "#         i = 0\n",
    "#         for doc in documents:\n",
    "#             if i %10000 == 0:\n",
    "#                 print(i)\n",
    "#             i+=1\n",
    "#             tokens = word_tokenize(doc)\n",
    "#             for token in tokens:\n",
    "#                 token = self.lemmatizer.lemmatize(token)\n",
    "#                 if token not in self.tokens_dict:\n",
    "#                     self.tokens_dict[token] = 0\n",
    "#                 self.tokens_dict[token] += 1\n",
    "#         self.finalize(vocab_count)\n",
    "    \n",
    "#     def finalize(self, vocab_count=10000):\n",
    "#         all_tokens = pd.DataFrame({'tokens': list(self.tokens_dict.keys()), 'counts': list(self.tokens_dict.values())})\n",
    "#         all_tokens = all_tokens.sort_values(by=['counts'], ascending=False)\n",
    "#         tokens = all_tokens['tokens'].values[:vocab_count]\n",
    "#         self.vocab_id = {t: i for i, t in enumerate(tokens)}\n",
    "#         self.id_vocab = {i: t for i, t in enumerate(tokens)}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yield_tokens(docs, tokenizer):\n",
    "#     for doc in docs:\n",
    "#         yield tokenizer(doc[0])\n",
    "\n",
    "# vf = VocabFactory()\n",
    "# vf.create_vocab(train_x, vocab_count=12000)\n",
    "vocab_dict = {t: i for i, t in enumerate(bert_tokenizer.vocab)}#vf.vocab_id\n",
    "vocab_size = len(bert_tokenizer.vocab)\n",
    "# build_vocab_from_iterator(yield_tokens(train_x.values, tokenizer), specials=[\"<unk>\"], max_tokens=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, dictionary, tokenizer, doc_length=256) -> None:\n",
    "        super().__init__()\n",
    "        self.doc_length = doc_length\n",
    "        y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.dictionary = dictionary\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = len(self.dictionary)\n",
    "        \n",
    "        self.X = torch.zeros((len(X), doc_length), dtype=torch.int)\n",
    "        for i, doc in enumerate(X):\n",
    "            # tokens = self.tokenizer(doc)\n",
    "            # print(doc)\n",
    "            indices = torch.from_numpy(np.array(self.tokenizer(doc)['input_ids'], dtype=np.longlong))\n",
    "            pad_size = max(self.doc_length - len(indices), 0)\n",
    "            self.X[i] = torch.nn.functional.pad(indices[:self.doc_length], (0,pad_size))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # doc = self.X[index]\n",
    "        # label = self.y[index]\n",
    "        # tokens = self.tokenizer(doc)\n",
    "        # tokens = [self.lemmatizer(t) for t in tokens]\n",
    "        # indices = torch.from_numpy(np.array([self.dictionary[t] for t in tokens if t in self.dictionary], dtype=np.longlong))\n",
    "        # pad_size = max(self.doc_length - len(indices), 0)\n",
    "        # indices = torch.nn.functional.pad(indices[:self.doc_length], (0,pad_size))\n",
    "        # token_vectors = torch.nn.functional.one_hot(indices, self.vocab_size)\n",
    "        return self.X[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2026, 2171, 2003, 2521, 8718, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(\"My name is Fardin!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n",
      "[37, 47, 66, 104, 85, 59, 90, 83, 90, 93, 65, 88, 51, 75, 118, 125, 86, 120, 53, 45, 20, 36, 23, 30, 23, 25, 22, 24, 25, 30, 31, 50, 36, 38, 25, 60, 74, 50, 68, 41, 24, 20, 22, 21, 20, 28, 20, 27, 33, 21, 50, 55, 39, 218, 43, 62, 35, 62, 42, 66, 61, 44, 46, 45, 62, 68, 71, 98, 77, 66, 24, 38, 51, 29, 30, 24, 26, 32, 40, 30, 90, 101, 24, 89, 45, 82, 38, 46, 69, 55, 37, 38, 45, 50, 44, 52, 56, 37, 39, 57, 46, 51, 24, 34, 42, 66, 68, 75, 62, 73, 47, 52, 55, 59, 110, 62, 56, 21, 59, 88, 24, 50, 32, 84, 44, 82, 42, 58, 40, 38, 22, 49, 52, 61, 113, 33, 74, 110, 27, 61, 46, 50, 42, 52, 41, 41, 118, 58, 74, 59, 43, 137, 43, 66, 43, 69, 170, 73, 59, 103, 41, 71, 50, 129, 55, 40, 102, 54, 28, 55, 40, 61, 34, 74, 95, 110, 95, 67, 89, 116, 61, 72, 66, 73, 79, 82, 70, 60, 86, 77, 66, 93, 78, 50, 45, 52, 94, 36, 25, 87, 45, 30, 118, 51, 67, 33, 28, 66, 56, 90, 42, 56, 49, 64, 63, 77, 77, 48, 69, 63, 38, 52, 40, 37, 32, 46, 66, 53, 81, 84, 52, 26, 30, 58, 77, 58, 97, 83, 99, 72, 43, 70, 46, 43, 27, 51, 96, 100, 85, 33, 31, 29, 26, 46, 78, 59, 61, 48, 34, 71, 43, 40, 43, 51, 54, 90, 60, 75, 79, 92, 44, 43, 57, 63, 78, 59, 47, 49, 37, 91, 33, 37, 105, 88, 55, 41, 48, 37, 53, 18, 92, 47, 90, 75, 81, 81, 66, 71, 84, 41, 45, 45, 45, 64, 43, 44, 48, 84, 46, 44, 47, 33, 39, 37, 47, 43, 57, 54, 30, 26, 33, 37, 37, 40, 45, 24, 46, 102, 48, 81, 36, 53, 43, 39, 43, 45, 43, 34, 117, 53, 43, 66, 30, 23, 32, 55, 72, 60, 57, 32, 33, 40, 23, 100, 61, 82, 49, 76, 48, 72, 56, 59, 44, 89, 83, 95, 94, 75, 125, 97, 46, 53, 86, 55, 46, 93, 73, 118, 62, 71, 82, 73, 60, 71, 60, 77, 78, 68, 96, 114, 50, 55, 47, 74, 29, 50, 60, 51, 114, 20, 52, 51, 24, 22, 53, 67, 57, 80, 25, 54, 43, 67, 43, 81, 43, 69, 43, 103, 68, 68, 43, 48, 43, 65, 43, 31, 49, 70, 102, 55, 42, 22, 48, 30, 26, 49, 50, 46, 38, 37, 61, 82, 64, 81, 62, 88, 57, 85, 51, 59, 23, 42, 31, 52, 50, 70, 59, 80, 31, 74, 24, 52, 50, 81, 27, 44, 30, 38, 56, 110, 103, 88, 45, 189, 108, 66, 73, 103, 73, 106, 110, 89, 26, 93, 79, 33, 90, 106, 78, 120, 44, 88, 33, 55, 55, 58, 96, 57, 39, 37, 43, 90, 43, 50, 82, 94, 49, 41, 57, 82, 31, 47, 34, 27, 75, 95, 32, 95, 57, 104, 40, 32, 49, 46, 38, 68, 73, 79, 64, 53, 78, 43, 70, 53, 39, 96, 95, 84, 40, 33, 65, 75, 64, 66, 40, 58, 42, 67, 116, 33, 52, 51, 74, 61, 72, 76, 99, 72, 60, 66, 31, 51, 57, 50, 35, 40, 32, 63, 63, 42, 52, 41, 21, 55, 32, 52, 71, 95, 88, 48, 78, 59, 68, 99, 86, 94, 131, 95, 73, 93, 57, 52, 107, 54, 99, 91, 117, 56, 58, 116, 41, 73, 41, 76, 110, 32, 111, 96, 57, 78, 25, 35, 60, 46, 28, 42, 43, 79, 59, 53, 54, 60, 92, 89, 236, 58, 55, 48, 81, 74, 92, 66, 67, 33, 57, 96, 108, 104, 62, 103, 43, 95, 43, 99, 43, 74, 43, 82, 43, 154, 21, 62, 45, 46, 48, 22, 60, 70, 28, 58, 26, 143, 30, 85, 124, 89, 53, 86, 93, 41, 54, 26, 64, 45, 40, 65, 82, 84, 103, 55, 30, 71, 91, 29, 40, 21, 17, 38, 37, 59, 45, 56, 24, 22, 31, 45, 48, 28, 107, 44, 38, 41, 70, 34, 33, 40, 40, 24, 32, 20, 25, 100, 53, 107, 37, 43, 47, 46, 49, 87, 57, 41, 59, 72, 46, 123, 77, 50, 122, 63, 23, 48, 98, 99, 81, 59, 44, 48, 75, 70, 43, 82, 43, 64, 43, 103, 43, 103, 43, 48, 48, 73, 71, 88, 72, 47, 66, 61, 52, 65, 96, 89, 105, 68, 72, 65, 118, 97, 57, 107, 57, 67, 99, 51, 78, 54, 79, 82, 103, 48, 28, 68, 43, 101, 91, 86, 75, 41, 82, 78, 82, 51, 44, 63, 58, 55, 59, 53, 87, 98, 52, 79, 75, 54, 75, 106, 58, 64, 95, 91, 29, 43, 71, 45, 50, 100, 50, 39, 75, 67, 45, 84, 84, 79, 72, 56, 61, 74, 52, 80, 26, 33, 32, 21, 50, 43, 51, 77, 28, 41, 118, 139, 68, 58, 72, 154, 136, 111, 148, 75, 58, 68, 115, 57, 78, 89, 113, 62, 52, 49, 87, 31, 49, 41, 47, 33, 27, 97, 41, 27, 122, 60, 141, 41, 145, 104, 56, 48, 91, 57, 53, 85, 86, 37, 109, 97, 123, 110, 70, 83, 46, 117, 49, 52, 99, 98, 59, 74, 91, 57, 42, 78, 24, 46, 50, 99, 40, 108, 98, 99, 39, 93, 60, 50, 57, 47, 25, 30, 63, 80, 38, 60, 25, 47, 80, 43, 70, 43, 76, 48, 71, 67, 40, 35, 83, 52, 61, 63, 59, 49, 21, 67, 70, 50, 41, 128, 67, 64, 47, 35, 52, 95, 88, 98, 67, 84, 88, 79, 94, 56, 82, 51, 44, 55, 120, 72, 46, 56, 98, 53, 43, 70, 43, 71, 43, 132, 43, 81, 82, 74, 112, 61, 83, 37, 85, 57, 74, 53, 71, 102, 57, 77, 53, 39, 67, 60, 53, 91, 56, 63, 28, 34, 64, 66, 21, 60, 123, 30, 93, 174, 52, 53, 62, 58, 76, 44, 75, 41, 116, 83, 95, 68, 64, 90, 74, 117, 33, 70, 68, 118, 43, 96, 79, 86, 95, 52, 84, 52, 110, 55, 36, 122, 72, 54, 92, 26, 89, 69, 41, 30, 41, 155, 53, 101, 133, 45, 66, 80, 61, 59, 30, 45, 64, 21, 35, 25, 46, 46, 99, 27, 69, 71, 48, 74, 64, 62, 89, 59, 71, 120, 40, 72, 77, 68, 79, 51, 68, 50, 61, 70, 92, 86, 44, 96, 85, 43, 122, 100, 98, 107, 57, 53, 87, 55, 93, 136, 94, 70, 76, 100, 59, 95, 45, 96, 31, 49, 43, 43, 57, 74, 70, 45, 84, 37, 158, 60, 41, 55, 36, 52, 43, 111, 43, 63, 76, 76, 56, 66, 75, 69, 48, 63, 88, 102, 74, 110, 79, 97, 62, 84, 41, 29, 54, 30, 59, 71, 55, 93, 66, 102, 29, 63, 71, 35, 71, 30, 24, 38, 29, 43, 21, 52, 54, 40, 73, 57, 41, 49, 55, 55, 110, 139, 108, 116, 95, 83, 45, 130, 80, 137, 108, 29, 99, 158, 109, 60, 62, 172, 74, 35, 53, 70, 22, 96, 121, 124, 71, 81, 72, 76, 38, 50, 88, 131, 132, 24, 37, 40, 58, 68, 50, 85, 74, 66, 86, 102, 96, 71, 67, 92, 110, 87, 110, 71, 189, 90, 92, 72, 70, 46, 97, 72, 72, 57, 92, 90, 57, 88, 90, 95, 30, 66, 60, 100, 142, 63, 68, 92, 107, 78, 43, 84, 95, 51, 77, 85, 193, 62, 95, 75, 43, 84, 43, 100, 43, 97, 43, 94, 37, 87, 82, 25, 102, 30, 99, 90, 95, 83, 93, 30, 52, 86, 57, 61, 54, 37, 70, 64, 88, 105, 26, 39, 22, 44, 92, 100, 78, 100, 48, 55, 55, 79, 51, 53, 79, 105, 167, 57, 94, 53, 96, 116, 50, 52, 106, 40, 105, 26, 27, 73, 43, 46, 43, 61, 43, 58, 43, 72, 76, 68, 57, 23, 98, 42, 86, 30, 99, 39, 46, 30, 77, 32, 48, 75, 38, 87, 67, 122, 91, 112, 69, 55, 76, 68, 79, 80, 97, 88, 77, 51, 39, 38, 34, 63, 33, 42, 25, 36, 33, 48, 55, 41, 53, 69, 122, 40, 90, 94, 86, 85, 70, 157, 107, 103, 103, 86, 93, 81, 87, 87, 41, 97, 41, 48, 112, 66, 57, 63, 53, 56, 95, 140, 33, 67, 73, 102, 54, 77, 117, 130, 58, 66, 56, 66, 101, 56, 93, 70, 56, 56, 43, 69, 50, 40, 84, 66, 64, 78, 49, 92, 75, 41, 110, 84, 96, 41, 36, 69, 53, 66, 43, 70, 43, 74, 43, 98, 70, 135, 74, 49, 43, 89, 43, 58, 43, 71, 83, 72, 50, 67, 43, 100, 43, 97, 43, 43, 43, 61, 105, 107, 47, 61, 79, 52, 55, 78, 79, 72, 77, 78, 72, 57, 73, 79, 47, 91, 77, 82, 25, 57, 32, 67, 50, 53, 34, 33, 84, 98, 70, 75, 74, 139, 81, 99, 89, 89, 125, 123, 78, 69, 61, 73, 95, 74, 93, 89, 91, 116, 62, 148, 82, 61, 81, 57, 59, 72, 116, 51, 100, 78, 53, 99, 75, 104, 91, 119, 138, 43, 98, 95, 43, 52, 85, 74, 87, 32, 80, 41, 48, 105, 25, 71, 40, 61, 46, 18, 57, 19, 22, 42, 53, 100, 53, 32, 41, 141, 41, 50, 66, 125, 140, 37, 108, 129, 80, 41, 86, 107, 176, 88, 42, 95, 34, 59, 49, 104, 94, 100, 90, 83, 69, 67, 81, 95, 69, 148, 105, 68, 93, 39, 57, 47, 52, 52, 52, 38, 69, 106, 140, 64, 44, 168, 95, 104, 116, 157, 88, 65, 164, 78, 58, 93, 100, 60, 46, 110, 93, 52, 70, 33, 63, 80, 63, 72, 80, 69, 89, 39, 56, 70, 85, 49, 32, 92, 99, 38, 83, 133, 84, 27, 103, 91, 80, 115, 138, 50, 74, 83, 84, 71, 58, 82, 76, 89, 85, 63, 47, 53, 50, 132, 43, 68, 43, 73, 95, 54, 53, 92, 41, 40, 95, 106, 120, 116, 74, 118, 90, 119, 127, 146, 72, 172, 91, 72, 60, 134, 89, 88, 108, 73, 101, 65, 52, 51, 60, 60, 96, 129, 57, 70, 49, 62, 72, 54, 61, 38, 92, 91, 123, 62, 51, 62, 43, 110, 73, 110, 86, 111, 57, 103, 54, 106, 51, 58, 74, 102, 78, 90, 119, 121, 53, 54, 69, 41, 107, 103, 93, 83, 87, 94, 105, 58, 94, 42, 126, 117, 90, 103, 86, 32, 51, 37, 78, 60, 90, 87, 84, 77, 86, 77, 106, 83, 75, 106, 88, 96, 113, 61, 82, 94, 69, 54, 119, 69, 27, 46, 64, 83, 94, 79, 64, 54, 75, 59, 98, 72, 102, 50, 94, 102, 76, 48, 60, 45, 143, 41, 64, 32, 130, 32, 112, 53, 126, 64, 75, 101, 109, 49, 93, 105, 43, 71, 43, 71, 43, 40, 43, 44, 79, 33, 43, 79, 43, 101, 43, 53, 43, 95, 43, 58, 82, 125, 124, 72, 87, 41, 109, 52, 78, 73, 68, 65, 96, 73, 26, 93, 73, 104, 74, 86, 43, 75, 43, 83, 86, 86, 76, 81, 95, 108, 54, 58, 78, 108, 62, 98, 50, 43, 76, 107, 26, 79, 77, 31, 67, 64, 55, 109, 71, 102, 130, 75, 64, 104, 53, 84, 96, 122, 91, 120, 127, 85, 130, 53, 66, 79, 133, 109, 78, 64, 86, 67, 104, 66, 48, 109, 125, 105, 104, 43, 77, 33, 65, 46, 27, 70, 48, 96, 104, 23, 65, 63, 49, 109, 64, 90, 65, 42, 46, 85, 61, 78, 127, 80, 108, 90, 104, 76, 86, 68, 91, 71, 67, 70, 65, 60, 65, 92, 71, 68, 134, 77, 132, 157, 48, 106, 41, 60, 82, 43, 95, 65, 59, 76, 54, 96, 80, 47, 90, 97, 66, 153, 46, 82, 92, 101, 78, 49, 67, 48, 45, 88, 74, 72, 67, 118, 178, 157, 154, 137, 35, 102, 53, 58, 73, 86, 74, 25, 68, 21, 89, 92, 91, 176, 115, 66, 116, 75, 101, 105, 58, 67, 69, 74, 68, 50, 97, 95, 59, 75, 52, 50, 41, 61, 102, 34, 51, 59, 50, 64, 83, 56, 59, 71, 60, 86, 60, 67, 64, 101, 61, 66, 73, 79, 77, 61, 61, 103, 59, 79, 43, 91, 43, 94, 43, 106, 74, 47, 93, 89, 43, 88, 43, 66, 43, 82, 62, 62, 87, 66, 57, 63, 76, 53, 76, 50, 89, 55, 97, 68, 110, 61, 100, 32, 103, 54, 88, 58, 144, 63, 120, 94, 53, 90, 41, 73, 72, 73, 60, 75, 41, 49, 47, 50, 54, 57, 49, 50, 103, 52, 54, 45, 45, 46, 36, 43, 23, 56, 92, 64, 56, 25, 56, 49, 29, 40, 68, 23, 145, 52, 76, 53, 67, 56, 60, 49, 29, 27, 49, 93, 65, 62, 63, 51, 62, 84, 78, 50, 67, 43, 88, 86, 41, 100, 57, 72, 102, 114, 70, 87, 92, 86, 99, 95, 154, 34, 87, 36, 98, 29, 56, 52, 72, 56, 78, 112, 148, 67, 60, 86, 43, 118, 43, 118, 43, 118, 43, 42, 43, 106, 106, 116, 109, 122, 81, 77, 65, 124, 115, 80, 46, 26, 58, 29, 60, 51, 72, 43, 53, 56, 26, 48, 49, 53, 140, 74, 56, 74, 60, 35, 124, 94, 52, 85, 50, 53, 65, 152, 57, 54, 76, 65, 66, 61, 76, 63, 73, 118, 67, 106, 103, 70, 82, 104, 100, 56, 81, 41, 118, 86, 54, 51, 29, 88, 57, 76, 33, 112, 49, 31, 141, 75, 31, 51, 41, 78, 41, 71, 46, 60, 139, 62, 132, 88, 21, 114, 65, 71, 140, 85, 42, 55, 81, 43, 68, 68, 51, 52, 81, 68, 123, 75, 91, 91, 73, 101, 75, 117, 124, 111, 43, 106, 43, 92, 43, 85, 43, 86, 91, 113, 43, 82, 43, 65, 43, 94, 56, 99, 62, 58, 43, 71, 43, 56, 43, 95, 73, 53, 41, 70, 89, 85, 81, 32, 31, 128, 87, 118, 89, 92, 81, 71, 53, 98, 66, 99, 47, 79, 93, 67, 79, 65, 53, 74, 102, 79, 41, 99, 83, 103, 64, 55, 95, 72, 85, 66, 74, 73, 43, 76, 95, 117, 53, 86, 78, 57, 81, 53, 68, 97, 62, 56, 59, 64, 74, 123, 73, 65, 95, 78, 88, 40, 106, 36, 51, 95, 104, 88, 73, 76, 79, 88, 99, 58, 68, 36, 47, 79, 77, 65, 73, 98, 67, 59, 41, 126, 37, 24, 36, 25, 34, 51, 53, 102, 71, 54, 32, 43, 110, 67, 62, 57, 92, 78, 61, 53, 64, 46, 82, 50, 68, 105, 41, 64, 111, 72, 63, 53, 59, 56, 71, 149, 123, 124, 76, 95, 108, 97, 100, 177, 67, 63, 73, 83, 77, 54, 55, 55, 49, 67, 75, 75, 63, 86, 97, 89, 55, 42, 99, 68, 62, 80, 57, 61, 69, 78, 98, 62, 66, 64, 63, 94, 88, 59, 84, 92, 87, 92, 84, 64, 86, 88, 71, 119, 75, 58, 92, 138, 73, 34, 50, 36, 93, 21, 68, 17, 109, 72, 62, 88, 65, 92, 65, 64, 72, 71, 118, 71, 90, 61, 48, 116, 105, 99, 104, 123, 132, 41, 114, 77, 51, 83, 62, 83, 55, 44, 49, 68, 43, 71, 119, 95, 51, 84, 92, 102, 153, 96, 61, 124, 58, 77, 88, 65, 110, 78, 91, 49, 73, 57, 66, 35, 74, 77, 103, 59, 66, 89, 132, 55, 122, 109, 117, 108, 90, 89, 67, 93, 64, 212, 53, 99, 93, 69, 49, 91, 47, 99, 46, 67, 38, 58, 76, 56, 99, 76, 105, 83, 142, 113, 43, 79, 43, 59, 43, 85, 43, 51, 43, 65, 84, 70, 87, 99, 74, 89, 108, 74, 133, 105, 112, 55, 97, 54, 134, 61, 97, 110, 154, 54, 97, 79, 91, 88, 53, 133, 72, 97, 101, 62, 47, 99, 75, 54, 69, 46, 105, 96, 108, 97, 59, 69, 51, 69, 61, 51, 61, 22, 90, 60, 44, 68, 53, 58, 53, 44, 101, 68, 105, 129, 43, 91, 43, 104, 43, 54, 107, 125, 144, 101, 54, 56, 118, 57, 71, 54, 49, 55, 65, 51, 99, 162, 87, 57, 154, 82, 88, 109, 102, 92, 41, 71, 95, 72, 82, 132, 117, 56, 127, 60, 69, 44, 42, 57, 51, 109, 78, 62, 107, 149, 81, 41, 86, 41, 91, 100, 72, 49, 80, 53, 76, 58, 89, 49, 53, 48, 117, 64, 71, 73, 135, 50, 70, 89, 92, 75, 82, 100, 115, 97, 88, 116, 107, 44, 100, 71, 85, 95, 95, 63, 99, 72, 80, 70, 56, 53, 63, 53, 153, 47, 68, 66, 73, 61, 73, 101, 53, 42, 97, 95, 61, 139, 79, 62, 46, 59, 59, 197, 77, 116, 87, 51, 53, 111, 100, 59, 138, 115, 40, 114, 70, 86, 87, 63, 64, 74, 77, 66, 94, 133, 83, 73, 65, 72, 53, 82, 105, 115, 74, 141, 41, 90, 53, 70, 120, 31, 64, 86, 44, 68, 94, 53, 84, 61, 148, 130, 67, 125, 77, 117, 86, 91, 63, 76, 87, 130, 79, 105, 71, 104, 63, 141, 70, 64, 93, 44, 35, 43, 53, 62, 81, 78, 76, 67, 48, 59, 68, 180, 127, 92, 42, 89, 141, 50, 44, 130, 55, 24, 26, 62, 63, 94, 60, 54, 55, 88, 68, 99, 39, 63, 43, 48, 43, 48, 43, 91, 43, 69, 69, 46, 105, 83, 82, 97, 76, 62, 73, 57, 95, 83, 58, 76, 79, 76, 114, 132, 93, 76, 51, 65, 53, 83, 53, 41, 85, 54, 66, 67, 134, 69, 83, 137, 74, 59, 27, 72, 37, 28, 28, 110, 86, 84, 22, 95, 51, 73, 172, 19, 47, 90, 70, 73, 61, 51, 65, 81, 67, 73, 54, 21, 83, 54, 96, 50, 72, 82, 65, 45, 114, 98, 50, 109, 60, 52, 95, 89, 82, 55, 48, 53, 98, 58, 107, 67, 68, 101, 121, 50, 106, 97, 87, 68, 47, 106, 53, 94, 53, 74, 33, 79, 99, 158, 44, 49, 58, 111, 146, 70, 89, 126, 24, 76, 140, 73, 61, 109, 85, 135, 104, 49, 90, 50, 100, 95, 199, 75, 25, 53, 72, 53, 73, 27, 48, 86, 32, 106, 54, 115, 79, 91, 130, 78, 74, 147, 42, 24, 50, 114, 105, 84, 110, 84, 63, 79, 57, 108, 86, 85, 91, 93, 53, 73, 114, 75, 125, 37, 85, 116, 59, 54, 39, 35, 35, 83, 65, 62, 46, 99, 76, 47, 38, 60, 26, 64, 51, 40, 71, 86, 50, 62, 26, 28, 21, 66, 89, 62, 53, 43, 50, 56, 39, 44, 42, 75, 38, 55, 42, 97, 103, 70, 43, 72, 37, 52, 52, 28, 73, 45, 64, 45, 70, 38, 41, 25, 27, 35, 32, 35, 52, 61, 24, 40, 90, 66, 71, 53, 81, 48, 85, 78, 41, 72, 81, 60, 49, 35, 72, 79, 43, 75, 29, 29, 40, 31, 43, 23, 30, 37, 26, 24, 29, 39, 31, 42, 39, 23, 52, 35, 50, 57, 28, 31, 24, 37, 21, 30, 27, 63, 24, 32, 44, 48, 35, 32, 49, 58, 40, 97, 51, 73, 33, 44, 38, 33, 59, 50, 20, 66, 52, 60, 40, 23, 27, 71, 35, 25, 68, 76, 21, 39, 22, 29, 28, 74, 72, 42, 58, 45, 70, 34, 72, 69, 91, 110, 96, 41, 51, 43, 65, 53, 45, 46, 50, 21, 48, 129, 27, 24, 60, 55, 44, 61, 64, 50, 96, 48, 90, 56, 31, 60, 35, 27, 40, 37, 40, 25, 39, 43, 46, 49, 47, 43, 75, 49, 46, 44, 119, 75, 99, 70, 49, 46, 50, 47, 50, 103, 46, 75, 96, 77, 75, 49, 61, 97, 46, 51, 42, 80, 52, 91, 62, 43, 40, 82, 38, 92, 57, 116, 55, 54, 55, 58, 42, 60, 22, 89, 48, 85, 53, 31, 44, 26, 45, 42, 40, 33, 24, 58, 41, 64, 47, 82, 72, 39, 66, 45, 85, 41, 93, 53, 29, 46, 82, 47, 63, 31, 51, 73, 52, 52, 41, 47, 44, 81, 61, 37, 37, 57, 100, 162, 32, 54, 28, 57, 91, 67, 32, 53, 59, 45, 64, 102, 116, 44, 110, 52, 100, 96, 56, 74, 80, 73, 94, 78, 59, 49, 65, 84, 96, 55, 68, 101, 38, 67, 65, 68, 75, 64, 66, 76, 99, 38, 30, 70, 52, 82, 56, 21, 52, 79, 35, 38, 25, 55, 54, 41, 52, 45, 70, 72, 40, 37, 58, 80, 54, 44, 34, 57, 72, 40, 56, 73, 74, 60, 68, 45, 38, 103, 74, 47, 41, 64, 73, 83, 41, 59, 108, 118, 48, 26, 41, 40, 26, 36, 32, 52, 43, 47, 85, 96, 43, 43, 34, 53, 73, 84, 64, 27, 37, 44, 33, 41, 107, 28, 129, 105, 36, 74, 56, 52, 88, 81, 41, 58, 40, 74, 75, 76, 84, 53, 42, 66, 60, 48, 56, 77, 47, 39, 97, 103, 53, 75, 23, 45, 73, 65, 82, 41, 81, 28, 49, 89, 30, 59, 47, 96, 62, 99, 45, 40, 34, 45, 111, 44, 53, 25, 93, 35, 81, 50, 34, 47, 31, 40, 30, 53, 61, 53, 45, 70, 79, 87, 64, 64, 63, 77, 60, 32, 71, 48, 37, 41, 73, 27, 65, 26, 63, 78, 42, 14, 45, 60, 56, 76, 83, 27, 58, 32, 20, 45, 45, 70, 74, 42, 80, 115, 117, 58, 72, 32, 46, 87, 86, 134, 38, 56, 105, 72, 27, 61, 68, 90, 57, 56, 101, 59, 99, 97, 73, 25, 41, 42, 45, 35, 44, 100, 29, 93, 89, 27, 41, 32, 28, 30, 43, 70, 72, 49, 42, 67, 56, 48, 42, 61, 60, 36, 90, 65, 65, 51, 48, 72, 87, 69, 52, 81, 74, 49, 69, 59, 63, 90, 52, 62, 47, 39, 49, 41, 41, 43, 28, 43, 35, 43, 22, 72, 38, 50, 44, 25, 70, 46, 68, 42, 75, 105, 94, 92, 75, 40, 35, 66, 50, 53, 36, 40, 65, 56, 67, 53, 77, 48, 57, 75, 47, 68, 26, 50, 57, 37, 76, 47, 31, 94, 57, 37, 76, 72, 95, 126, 40, 120, 105, 38, 124, 71, 68, 90, 74, 59, 38, 52, 72, 46, 97, 83, 46, 31, 51, 38, 80, 27, 81, 53, 44, 54, 29, 42, 74, 35, 69, 67, 110, 92, 53, 45, 81, 69, 47, 51, 63, 63, 45, 54, 89, 99, 70, 41, 39, 44, 115, 85, 61, 64, 86, 78, 81, 28, 104, 73, 29, 64, 69, 31, 32, 105, 36, 39, 69, 67, 71, 71, 61, 117, 113, 59, 74, 131, 37, 44, 56, 40, 108, 58, 56, 56, 50, 38, 45, 32, 61, 46, 106, 39, 43, 137, 60, 56, 129, 63, 50, 48, 45, 114, 30, 49, 42, 73, 53, 55, 42, 36, 70, 122, 50, 76, 94, 61, 41, 71, 25, 95, 54, 50, 48, 42, 59, 75, 46, 27, 128, 23, 21, 54, 48, 45, 25, 33, 55, 61, 117, 54, 31, 60, 17, 63, 138, 65, 46, 56, 31, 96, 31, 54, 36, 63, 98, 22, 42, 68, 80, 52, 45, 90, 104, 34, 98, 110, 32, 58, 34, 47, 43, 50, 48, 54, 46, 74, 63, 56, 43, 51, 73, 48, 71, 44, 45, 63, 103, 40, 29, 75, 28, 125, 30, 22, 36, 26, 63, 75, 33, 25, 42, 43, 79, 26, 71, 33, 29, 47, 41, 41, 66, 83, 108, 59, 59, 99, 85, 80, 48, 59, 56, 58, 179, 65, 40, 92, 78, 57, 22, 50, 87, 84, 99, 39, 95, 35, 27, 51, 64, 29, 31, 35, 70, 95, 46, 130, 39, 57, 73, 70, 53, 72, 31, 73, 45, 61, 45, 64, 75, 42, 71, 71, 51, 49, 68, 89, 123, 48, 71, 63, 78, 74, 99, 61, 57, 69, 81, 82, 57, 57, 90, 78, 52, 64, 123, 27, 63, 39, 64, 27, 39, 48, 89, 22, 126, 93, 57, 98, 116, 48, 77, 60, 47, 59, 41, 62, 95, 61, 67, 45, 21, 58, 52, 66, 99, 92, 69, 29, 49, 69, 77, 56, 67, 69, 43, 87, 74, 82, 94, 69, 64, 53, 59, 37, 64, 43, 72, 49, 46, 87, 91, 97, 51, 46, 67, 63, 52, 66, 41, 47, 41, 47, 83, 65, 42, 56, 68, 83, 52, 56, 52, 62, 99, 52, 105, 40, 81, 86, 84, 58, 105, 27, 67, 81, 28, 57, 40, 116, 64, 50, 56, 59, 107, 84, 54, 45, 72, 68, 48, 55, 41, 72, 49, 123, 50, 98, 29, 138, 74, 99, 64, 60, 106, 45, 46, 43, 108, 45, 68, 93, 25, 34, 35, 40, 27, 57, 26, 48, 75, 79, 73, 117, 59, 76, 53, 95, 59, 52, 44, 43, 34, 53, 22, 68, 85, 56, 49, 35, 42, 41, 50, 48, 60, 53, 74, 53, 100, 65, 84, 76, 55, 55, 91, 58, 75, 73, 148, 80, 66, 66, 26, 65, 62, 30, 35, 51, 28, 41, 71, 70, 56, 74, 84, 40, 46, 48, 66, 69, 68, 48, 37, 38, 74, 53, 87, 40, 89, 67, 60, 86, 96, 84, 95, 51, 118, 74, 78, 35, 31, 48, 112, 37, 62, 44, 44, 37, 54, 97, 102, 60, 70, 96, 103, 60, 82, 77, 97, 96, 43, 73, 34, 83, 76, 28, 51, 63, 27, 63, 80, 31, 53, 67, 48, 91, 129, 126, 42, 79, 51, 72, 65, 77, 109, 64, 102, 73, 80, 47, 38, 127, 80, 63, 96, 52, 46, 86, 87, 82, 39, 76, 60, 55, 86, 45, 86, 50, 59, 78, 49, 74, 84, 54, 47, 65, 51, 64, 21, 17, 72, 97, 116, 58, 52, 77, 67, 38, 33, 49, 57, 94, 96, 51, 67, 46, 76, 95, 78, 56, 56, 65, 129, 50, 25, 24, 83, 32, 30, 52, 51, 113, 56, 50, 56, 88, 52, 39, 63, 74, 104, 44, 65, 117, 132, 115, 76, 115, 73, 43, 66, 65, 70, 59, 58, 88, 88, 97, 56, 37, 46, 43, 62, 84, 89, 123, 32, 60, 46, 53, 76, 36, 25, 54, 101, 60, 58, 66, 71, 43, 92, 83, 74, 95, 58, 56, 46, 34, 65, 99, 58, 63, 56, 66, 99, 58, 98, 54, 82, 87, 58, 47, 84, 52, 56, 69, 68, 87, 45, 53, 70, 101, 100, 64, 55, 74, 71, 50, 95, 52, 93, 60, 42, 106, 97, 41, 49, 46, 151, 57, 66, 41, 70, 84, 73, 140, 33, 127, 80, 40, 42, 52, 49, 100, 62, 46, 58, 85, 45, 84, 94, 112, 125, 50, 33, 73, 87, 78, 73, 48, 65, 19, 76, 35, 41, 76, 42, 112, 28, 75, 91, 77, 62, 40, 57, 42, 59, 51, 84, 50, 55, 82, 45, 42, 101, 44, 76, 50, 45, 55, 77, 65, 65, 54, 83, 94, 90, 143, 55, 46, 43, 34, 131, 64, 122, 31, 54, 71, 140, 68, 59, 99, 86, 62, 64, 95, 67, 79, 83, 84, 54, 99, 102, 53, 74, 70, 50, 79, 56, 120, 41, 34, 86, 80, 72, 45, 76, 60, 69, 72, 86, 98, 44, 97, 52, 55, 87, 100, 83, 46, 68, 45, 54, 44, 55, 35, 41, 91, 96, 95, 27, 104, 29, 63, 41, 49, 28, 50, 54, 70, 38, 50, 33, 44, 90, 72, 35, 89, 27, 81, 90, 92, 24, 147, 73, 85, 81, 93, 32, 101, 61, 53, 69, 29, 52, 25, 78, 44, 80, 59, 100, 46, 22, 102, 25, 56, 75, 47, 53, 58, 52, 47, 50, 49, 61, 80, 78, 62, 97, 25, 56, 47, 37, 88, 96, 101, 141, 90, 39, 56, 74, 91, 56, 78, 41, 51, 48, 50, 115, 64, 99, 103, 100, 99, 55, 132, 80, 58, 118, 42, 72, 55, 81, 28, 49, 63, 85, 108, 28, 90, 48, 69, 24, 79, 59, 27, 103, 79, 88, 58, 94, 44, 95, 48, 53, 61, 82, 78, 59, 48, 65, 61, 68, 85, 97, 74, 83, 55, 72, 92, 60, 67, 92, 72, 93, 75, 54, 56, 54, 82, 66, 86, 62, 41, 61, 81, 62, 75, 78, 46, 101, 55, 57, 53, 59, 31, 92, 89, 59, 96, 114, 62, 68, 80, 108, 72, 74, 32, 68, 85, 86, 110, 42, 48, 123, 75, 42, 118, 60, 96, 95, 74, 98, 98, 43, 233, 48, 58, 46, 85, 70, 100, 134, 65, 58, 37, 57, 70, 84, 71, 42, 112, 44, 76, 68, 74, 84, 78, 97, 29, 61, 79, 23, 96, 47, 44, 53, 45, 40, 74, 71, 77, 75, 52, 59, 70, 47, 49, 75, 76, 123, 43, 43, 71, 77, 86, 90, 35, 36, 70, 44, 46, 98, 84, 40, 56, 93, 90, 66, 41, 30, 57, 31, 38, 61, 69, 65, 148, 47, 38, 62, 81, 86, 49, 43, 64, 45, 68, 53, 47, 77, 60, 55, 86, 66, 81, 75, 64, 44, 51, 121, 116, 38, 37, 107, 95, 66, 89, 37, 82, 49, 66, 103, 64, 49, 138, 116, 65, 90, 68, 110, 100, 46, 98, 84, 62, 77, 67, 65, 72, 55, 46, 52, 70, 39, 49, 65, 84, 63, 64, 30, 39, 65, 40, 67, 116, 46, 80, 93, 32, 21, 41, 28, 27, 97, 34, 23, 26, 39, 82, 68, 69, 101, 65, 54, 56, 84, 74, 62, 70, 66, 88, 68, 70, 124, 47, 107, 60, 60, 102, 38, 62, 86, 34, 81, 60, 45, 64, 89, 90, 127, 72, 110, 67, 79, 90, 93, 135, 46, 61, 72, 136, 46, 75, 90, 130, 79, 61, 118, 51, 100, 72, 37, 96, 91, 62, 152, 119, 45, 66, 105, 40, 61, 105, 47, 80, 62, 49, 91, 38, 41, 54, 77, 70, 44, 55, 61, 39, 31, 81, 87, 82, 27, 72, 62, 93, 100, 53, 83, 58, 75, 43, 55, 85, 76, 94, 85, 49, 84, 70, 58, 93, 57, 92, 74, 85, 45, 109, 43, 74, 42, 44, 52, 38, 77, 102, 71, 88, 47, 68, 93, 68, 53, 55, 23, 66, 54, 83, 51, 48, 77, 78, 81, 68, 129, 78, 72, 79, 104, 47, 76, 96, 59, 68, 71, 56, 72, 100, 80, 53, 60, 80, 73, 63, 84, 150, 84, 53, 75, 103, 30, 82, 55, 44, 78, 85, 123, 61, 88, 119, 79, 81, 84, 112, 103, 132, 44, 72, 77, 89, 40, 91, 78, 61, 118, 43, 51, 132, 71, 63, 74, 59, 77, 52, 70, 47, 65, 47, 42, 71, 44, 69, 49, 57, 44, 52, 73, 47, 68, 88, 61, 78, 89, 99, 47, 106, 93, 54, 53, 29, 32, 76, 105, 88, 47, 43, 76, 31, 43, 37, 63, 26, 27, 17, 78, 54, 75, 34, 28, 22, 35, 78, 56, 108, 56, 88, 24, 76, 41, 102, 51, 102, 50, 57, 56, 89, 88, 84, 68, 99, 66, 67, 83, 58, 77, 63, 90, 68, 22, 34, 43, 14, 27, 47, 79, 32, 28, 36, 82, 48, 62, 51, 79, 67, 125, 90, 108, 41, 73, 61, 75, 71, 95, 76, 67, 109, 92, 61, 62, 84, 101, 61, 60, 64, 47, 91, 88, 105, 67, 73, 68, 64, 44, 93, 80, 69, 43, 58, 96, 84, 63, 53, 32, 81, 118, 78, 41, 64, 42, 55, 49, 74, 56, 77, 46, 86, 61, 86, 52, 95, 114, 94, 82, 68, 99, 68, 104, 55, 77, 96, 49, 45, 103, 55, 50, 87, 48, 68, 53, 41, 79, 67, 100, 100, 62, 54, 71, 97, 114, 61, 102, 55, 35, 40, 95, 52, 70, 109, 45, 40, 67, 107, 111, 47, 62, 65, 66, 75, 90, 141, 52, 138, 80, 61, 95, 61, 75, 93, 57, 73, 63, 108, 87, 84, 26, 75, 99, 62, 48, 69, 73, 91, 35, 103, 91, 71, 48, 79, 27, 23, 39, 99, 29, 32, 58, 83, 69, 105, 60, 130, 56, 68, 51, 34, 66, 93, 67, 75, 47, 27, 28, 27, 33, 33, 36, 29, 68, 47, 76, 82, 79, 58, 64, 60, 73, 82, 110, 51, 45, 118, 65, 81, 57, 94, 61, 34, 83, 73, 64, 57, 57, 95, 64, 78, 76, 90, 85, 79, 97, 42, 97, 50, 93, 72, 39, 71, 79, 33, 65, 66, 124, 89, 31, 117, 96, 41, 85, 80, 56, 38, 95, 61, 57, 65, 67, 61, 127, 71, 56, 67, 56, 53, 79, 101, 50, 46, 47, 57, 52, 97, 183, 90, 92, 100, 46, 64, 62, 50, 104, 51, 81, 67, 83, 82, 84, 75, 78, 95, 71, 44, 92, 64, 58, 36, 50, 114, 70, 53, 82, 80, 22, 58, 59, 36, 63, 59, 53, 66, 123, 51, 71, 77, 80, 56, 50, 72, 54, 51, 82, 35, 43, 106, 47, 84, 63, 79, 107, 48, 80, 70, 106, 38, 53, 72, 71, 75, 36, 66, 67, 39, 73, 144, 139, 72, 38, 52, 42, 127, 76, 84, 91, 91, 61, 69, 90, 91, 90, 96, 50, 44, 48, 44, 38, 38, 36, 90, 68, 76, 64, 43, 56, 43, 54, 43, 66, 43, 96, 37, 50, 97, 74, 45, 86, 86, 62, 49, 114, 80, 74, 54, 67, 96, 98, 100, 71, 59, 47, 82, 60, 70, 47, 53, 58, 48, 86, 71, 54, 114, 106, 200, 88, 22, 43, 37, 49, 52, 37, 63, 95, 46, 76, 54, 82, 58, 101, 64, 62, 42, 154, 53, 66, 76, 73, 47, 73, 58, 73, 80, 59, 68, 52, 45, 106, 49, 75, 89, 68, 101, 57, 72, 68, 88, 118, 88, 72, 87, 95, 69, 79, 83, 89, 107, 67, 86, 82, 83, 47, 81, 117, 111, 106, 105, 150, 115, 70, 56, 69, 41, 54, 56, 43, 46, 86, 48, 66, 101, 48, 48, 50, 73, 62, 120, 66, 76, 86, 57, 97, 75, 92, 78, 64, 57, 86, 71, 49, 95, 75, 51, 70, 74, 88, 80, 38, 57, 60, 49, 51, 108, 76, 71, 25, 85, 89, 62, 74, 113, 77, 104, 101, 65, 107, 68, 75, 65, 71, 71, 104, 95, 53, 56, 50, 53, 74, 46, 96, 68, 105, 60, 95, 86, 72, 69, 48, 95, 71, 73, 91, 83, 90, 37, 71, 78, 50, 97, 125, 45, 74, 77, 46, 95, 81, 72, 70, 50, 38, 31, 58, 37, 86, 72, 86, 119, 61, 69, 56, 67, 56, 97, 70, 62, 65, 58, 96, 50, 88, 122, 63, 104, 49, 108, 130, 92, 117, 90, 117, 42, 59, 59, 57, 124, 98, 89, 62, 50, 47, 109, 95, 97, 43, 123, 87, 76, 77, 100, 187, 111, 83, 126, 77, 66, 56, 39, 46, 105, 77, 64, 69, 56, 78, 41, 50, 68, 102, 45, 44, 86, 121, 130, 64, 40, 103, 60, 70, 71, 70, 72, 36, 35, 66, 50, 84, 78, 98, 75, 59, 63, 72, 57, 68, 43, 68, 63, 50, 71, 66, 37, 60, 104, 42, 34, 51, 38, 199, 64, 72, 41, 97, 84, 58, 99, 82, 67, 110, 59, 66, 56, 102, 101, 103, 48, 60, 60, 74, 85, 85, 69, 61, 40, 37, 47, 73, 74, 55, 81, 78, 56, 103, 101, 39, 88, 57, 86, 42, 130, 42, 53, 46, 50, 67, 91, 62, 47, 80, 43, 87, 55, 90, 53, 82, 103, 65, 33, 149, 70, 68, 45, 66, 219, 95, 56, 58, 47, 57, 74, 70, 52, 66, 58, 109, 146, 63, 71, 110, 55, 71, 78, 77, 76, 73, 46, 71, 75, 76, 46, 73, 27, 32, 73, 71, 65, 69, 65, 71, 57, 121, 70, 85, 83, 85, 50, 88, 55, 101, 61, 51, 47, 67, 61, 62, 47, 83, 76, 74, 90, 41, 74, 45, 78, 57, 76, 78, 76, 55, 92, 56, 75, 61, 60, 119, 88, 106, 79, 77, 87, 117, 46, 69, 67, 103, 90, 33, 108, 95, 66, 47, 61, 113, 71, 31, 56, 49, 54, 62, 23, 19, 53, 26, 24, 71, 74, 52, 77, 59, 59, 94, 49, 118, 99, 82, 89, 115, 54, 68, 23, 119, 48, 77, 84, 26, 83, 55, 99, 49, 93, 51, 72, 85, 55, 60, 42, 77, 93, 78, 91, 66, 64, 51, 67, 94, 96, 55, 77, 72, 46, 69, 57, 67, 72, 95, 71, 71, 129, 66, 82, 81, 96, 81, 46, 73, 55, 82, 67, 46, 63, 35, 55, 80, 80, 55, 86, 76, 78, 71, 83, 79, 85, 58, 112, 60, 43, 18, 28, 60, 21, 74, 49, 29, 28, 71, 72, 69, 71, 108, 100, 105, 117, 45, 117, 107, 101, 99, 86, 67, 109, 59, 44, 109, 107, 98, 71, 111, 37, 87, 62, 75, 113, 62, 111, 123, 60, 111, 88, 101, 64, 84, 94, 55, 48, 92, 64, 95, 63, 66, 85, 64, 93, 41, 96, 71, 65, 94, 45, 77, 54, 44, 59, 96, 51, 64, 73, 73, 104, 57, 50, 26, 68, 56, 39, 118, 79, 168, 79, 144, 88, 66, 53, 29, 67, 127, 96, 126, 112, 61, 114, 92, 87, 68, 16, 59, 100, 64, 47, 81, 93, 85, 55, 80, 78, 97, 86, 82, 66, 77, 71, 87, 110, 99, 65, 37, 106, 54, 99, 55, 99, 85, 87, 92, 55, 72, 82, 75, 47, 97, 53, 46, 52, 72, 98, 125, 63, 51, 50, 59, 95, 57, 97, 73, 141, 76, 53, 41, 53, 55, 78, 83, 66, 162, 101, 57, 53, 50, 62, 39, 37, 80, 68, 69, 36, 33, 52, 36, 43, 26, 33, 43, 37, 36, 33, 31, 48, 35, 38, 44, 35, 55, 83, 36, 35, 26, 43, 71, 22, 39, 47, 25, 45, 40, 47, 54, 45, 69, 38, 123, 55, 49, 96, 42, 28, 38, 24, 51, 30, 29, 30, 61, 26, 24, 62, 23, 20, 20, 20, 27, 33, 30, 25, 19, 26, 21, 21, 39, 47, 27, 38, 27, 27, 27, 125, 24, 39, 36, 28, 52, 37, 22, 33, 26, 41, 21, 51, 21, 25, 38, 72, 54, 52, 57, 90, 21, 28, 38, 48, 28, 56, 35, 52, 64, 28, 35, 22, 48, 36, 37, 40, 111, 31, 34, 89, 87, 53, 75, 41, 83, 53, 33, 53, 76, 50, 24, 50, 42, 47, 24, 58, 26, 30, 38, 57, 67, 88, 52, 53, 60, 98, 40, 82, 57, 26, 38, 26, 60, 29, 27, 25, 31, 43, 34, 30, 41, 40, 54, 62, 54, 91, 107, 43, 37, 49, 41, 55, 62, 58, 94, 64, 72, 36, 52, 48, 31, 50, 38, 48, 49, 46, 41, 81, 103, 59, 166, 74, 75, 69, 55, 78, 41, 80, 68, 53, 148, 25, 58, 20, 72, 76, 81, 41, 81, 76, 37, 89, 55, 70, 138, 66, 71, 107, 84, 64, 38, 57, 38, 44, 97, 30, 39, 63, 40, 84, 69, 38, 85, 63, 124, 63, 59, 54, 52, 41, 67, 32, 75, 73, 105, 65, 166, 88, 89, 89, 83, 43, 108, 68, 80, 79, 26, 56, 75, 40, 36, 22, 35, 34, 37, 44, 31, 31, 28, 20, 57, 42, 84, 61, 98, 66, 66, 61, 25, 50, 26, 31, 52, 42, 30, 42, 48, 36, 62, 38, 74, 70, 62, 75, 71, 53, 53, 67, 93, 82, 42, 54, 69, 80, 70, 68, 95, 58, 66, 64, 32, 62, 44, 34, 64, 48, 77, 49, 57, 33, 74, 74, 101, 80, 83, 65, 81, 70, 48, 85, 46, 47, 69, 65, 59, 53, 82, 50, 76, 64, 74, 32, 73, 48, 42, 53, 43, 32, 64, 77, 48, 27, 51, 42, 27, 70, 37, 48, 24, 49, 39, 45, 80, 79, 67, 61, 54, 41, 70, 71, 23, 25, 25, 30, 39, 26, 35, 30, 30, 33, 64, 44, 106, 69, 69, 23, 74, 76, 66, 115, 154, 80, 156, 64, 67, 59, 60, 80, 104, 54, 54, 95, 79, 71, 84, 29, 71, 64, 99, 80, 27, 41, 93, 55, 69, 24, 113, 43, 95, 53, 64, 56, 77, 44, 44, 71, 64, 43, 97, 109, 31, 24, 38, 26, 27, 77, 24, 101, 24, 19, 24, 24, 24, 103, 38, 51, 113, 109, 26, 98, 45, 113, 56, 62, 53, 48, 87, 41, 76, 45, 38, 27, 71, 22, 73, 28, 31, 22, 61, 28, 64, 28, 69, 62, 79, 56, 95, 27, 56, 108, 43, 87, 51, 53, 36, 73, 54, 145, 61, 51, 74, 40, 55, 52, 67, 64, 175, 64, 41, 62, 62, 40, 72, 79, 77, 49, 71, 86, 57, 49, 67, 66, 42, 90, 72, 53, 91, 55, 94, 40, 96, 47, 48, 56, 65, 87, 63, 79, 58, 41, 70, 56, 61, 44, 166, 111, 79, 64, 60, 105, 28, 26, 88, 52, 34, 33, 38, 31, 23, 56, 54, 36, 60, 26, 80, 43, 87, 48, 79, 48, 91, 40, 57, 36, 61, 55, 27, 43, 32, 61, 52, 54, 55, 83, 63, 80, 74, 53, 55, 72, 61, 95, 99, 42, 53, 57, 62, 73, 97, 84, 39, 84, 57, 83, 25, 96, 61, 60, 85, 27, 43, 80, 43, 94, 43, 62, 91, 92, 75, 88, 84, 77, 78, 80, 99, 94, 41, 91, 49, 46, 141, 66, 48, 75, 83, 54, 94, 61, 50, 84, 54, 48, 71, 58, 80, 80, 46, 87, 68, 52, 81, 47, 59, 53, 75, 74, 61, 63, 75, 38, 60, 46, 66, 57, 77, 64, 88, 70, 90, 72, 38, 44, 23, 36, 65, 51, 46, 58, 53, 51, 97, 65, 40, 69, 60, 92, 26, 73, 53, 31, 112, 61, 76, 48, 60, 80, 73, 78, 42, 100, 66, 50, 82, 83, 61, 64, 58, 74, 68, 102, 148, 48, 80, 50, 58, 63, 97, 60, 41, 46, 61, 55, 42, 93, 104, 61, 52, 86, 87, 106, 39, 79, 77, 70, 62, 99, 153, 74, 51, 95, 52, 62, 76, 43, 49, 77, 53, 59, 90, 71, 42, 50, 51, 41, 62, 59, 38, 51, 104, 47, 67, 148, 66, 145, 69, 56, 81, 60, 51, 66, 101, 84, 80, 69, 92, 60, 72, 86, 77, 101, 51, 48, 85, 110, 97, 91, 54, 80, 86, 106, 64, 87, 38, 85, 90, 73, 131, 53, 71, 82, 106, 102, 88, 63, 54, 106, 47, 103, 86, 125, 54, 42, 106, 97, 93, 105, 91, 86, 102, 95, 58, 70, 58, 64, 75, 67, 64, 89, 53, 54, 59, 79, 82, 78, 59, 69, 86, 73, 76, 66, 59, 73, 65, 62, 95, 56, 96, 45, 53, 53, 70, 70, 74, 64, 59, 64, 92, 61, 57, 128, 65, 56, 74, 70, 76, 89, 72, 102, 90, 76, 98, 72, 66, 85, 71, 88, 63, 78, 87, 58, 70, 69, 68, 61, 45, 123, 61, 71, 64, 71, 71, 56, 75, 76, 66, 74, 103, 73, 97, 68, 81, 102, 76, 69, 71, 82, 49, 99, 64, 126, 65, 79, 93, 77, 99, 101, 117, 61, 79, 95, 91, 82, 58, 80, 103, 42, 66, 102, 33, 47, 58, 58, 67, 65, 61, 64, 77, 66, 71, 87, 61, 121, 101, 81, 56, 79, 57, 67, 67, 87, 48, 76, 57, 81, 73, 70, 59, 82, 66, 85, 61, 93, 85, 65, 93, 66, 60, 88, 111, 95, 71, 66, 60, 94, 87, 86, 76, 72, 78, 64, 56, 62, 75, 69, 70, 99, 52, 57, 76, 90, 67, 67, 102, 64, 69, 61, 94, 58, 60, 74, 82, 70, 57, 58, 90, 92, 52, 59, 55, 45, 59, 59, 57, 82, 59, 70, 72, 69, 91, 101, 76, 86, 64, 64, 82, 74, 104, 97, 92, 83, 84, 98, 76, 74, 99, 79, 91, 93, 101, 110, 70, 61, 71, 60, 64, 69, 75, 68, 61, 61, 78, 90, 64, 71, 95, 91, 70, 69, 98, 49, 64, 70, 75, 61, 57, 71, 61, 69, 71, 43, 52, 93, 41, 57, 62, 75, 95, 43, 61, 69, 75, 113, 82, 80, 97, 91, 65, 96, 62, 99, 78, 57, 75, 52, 66, 94, 83, 97, 87, 119, 99, 96, 74, 73, 68, 85, 80, 80, 61, 61, 60, 103, 79, 56, 93, 62, 85, 72, 113, 98, 67, 100, 68, 75, 65, 60, 76, 63, 90, 61, 59, 76, 71, 79, 54, 59, 64, 71, 69, 57, 70, 70, 74, 57, 60, 61, 57, 75, 85, 70, 61, 69, 74, 61, 65, 59, 59, 63, 62, 59, 70, 57, 66, 75, 66, 82, 57, 38, 48, 68, 58, 89, 56, 121, 94, 96, 75, 43, 69, 95, 94, 84, 103, 43, 117, 58, 59, 81, 57, 75, 69, 61, 61, 70, 65, 55, 111, 81, 78, 103, 94, 85, 60, 51, 69, 63, 77, 64, 68, 72, 96, 68, 61, 123, 74, 64, 160, 55, 103, 74, 54, 62, 97, 48, 75, 46, 59, 67, 59, 83, 87, 60, 102, 68, 82, 66, 96, 65, 69, 91, 52, 130, 51, 57, 75, 76, 44, 83, 83, 78, 51, 121, 59, 69, 60, 60, 95, 122, 54, 69, 91, 49, 144, 82, 99, 43, 93, 95, 80, 71, 57, 81, 89, 52, 89, 69, 59, 59, 57, 74, 94, 57, 70, 44, 48, 82, 91, 76, 61, 69, 56, 84, 90, 60, 96, 72, 72, 42, 40, 41, 48, 68, 64, 85, 91, 68, 80, 90, 60, 82, 58, 95, 102, 61, 67, 80, 123, 57, 47, 43, 73, 81, 89, 57, 59, 56, 69, 48, 59, 73, 96, 70, 54, 76, 61, 123, 66, 56, 118, 46, 106, 101, 80, 89, 71, 103, 57, 53, 99, 96, 91, 58, 53, 62, 85, 76, 55, 97, 71, 81, 80, 111, 85, 112, 64, 71, 66, 102, 115, 38, 66, 64, 68, 74, 59, 68, 73, 59, 63, 72, 62, 77, 58, 166, 39, 61, 68, 88, 82, 94, 71, 64, 75, 95, 70, 58, 101, 76, 110, 68, 59, 61, 91, 86, 68, 76, 122, 49, 96, 64, 111, 57, 61, 130, 95, 56, 84, 70, 65, 60, 76, 69, 93, 94, 62, 70, 70, 59, 65, 61, 61, 74, 71, 115, 95, 75, 56, 62, 57, 75, 94, 61, 101, 63, 83, 63, 83, 90, 85, 111, 85, 63, 94, 93, 79, 77, 84, 103, 69, 64, 59, 113, 137, 57, 56, 57, 75, 57, 60, 57, 56, 76, 62, 135, 59, 60, 82, 46, 69, 75, 90, 59, 99, 70, 76, 75, 64, 77, 61, 53, 76, 38, 85, 80, 109, 75, 113, 57, 57, 74, 81, 69, 68, 59, 59, 58, 62, 64, 66, 68, 57, 59, 59, 94, 78, 52, 64, 54, 61, 105, 58, 98, 91, 66, 75, 62, 55, 56, 70, 75, 58, 58, 57, 59, 88, 57, 79, 67, 79, 81, 81, 95, 71, 83, 100, 103, 52, 65, 61, 91, 60, 87, 70, 89, 58, 75, 64, 81, 94, 85, 58, 69, 84, 76, 84, 100, 102, 98, 99, 106, 93, 56, 93, 104, 99, 80, 84, 95, 114, 117, 119, 59, 71, 59, 86, 75, 70, 67, 47, 71, 59, 44, 46, 57, 51, 68, 59, 66, 81, 93, 73, 77, 84, 51, 98, 102, 61, 58, 70, 71, 74, 57, 65, 83, 100, 85, 71, 55, 58, 68, 67, 66, 80, 62, 74, 59, 67, 73, 100, 57, 59, 89, 116, 74, 90, 68, 41, 64, 62, 68, 116, 64, 106, 64, 96, 60, 69, 110, 88, 63, 47, 49, 88, 57, 68, 66, 61, 64, 69, 57, 71, 61, 75, 75, 102, 85, 102, 121, 80, 91, 83, 59, 53, 72, 84, 89, 113, 121, 98, 67, 45, 74, 58, 52, 66, 66, 62, 58, 61, 61, 69, 70, 74, 45, 58, 94, 91, 93, 71, 63, 51, 93, 68, 78, 66, 75, 47, 47, 65, 82, 33, 55, 30, 57, 31, 99, 64, 37, 60, 88, 63, 72, 40, 69, 48, 88, 65, 38, 29, 102, 179, 87, 54, 75, 97, 58, 42, 44, 67, 92, 79, 63, 55, 60, 49, 65, 51, 59, 67, 62, 68, 52, 56, 156, 75, 98, 67, 60, 70, 77, 58, 70, 58, 72, 74, 89, 55, 138, 70, 58, 54, 64, 56, 75, 130, 68, 66, 61, 63, 66, 65, 84, 98, 49, 98, 26, 65, 33, 44, 47, 25, 53, 36, 33, 58, 65, 90, 77, 63, 62, 77, 60, 114, 84, 82, 81, 66, 25, 65, 80, 66, 60, 60, 21, 117, 98, 78, 87, 106, 68, 62, 36, 72, 112, 45, 81, 100, 70, 66, 66, 71, 75, 109, 53, 77, 79, 40, 46, 230, 67, 83, 60, 54, 63, 52, 50, 59, 76, 49, 33, 71, 105, 86, 59, 84, 65, 40, 84, 43, 57, 96, 77, 54, 72, 65, 46, 72, 30, 69, 63, 50, 25, 55, 121, 72, 81, 101, 51, 75, 85, 79, 83, 61, 91, 64, 77, 65, 63, 100, 75, 97, 57, 64, 76, 78, 72, 148, 82, 81, 76, 46, 51, 96, 91, 68, 31, 72, 39, 70, 69, 102, 83, 103, 74, 87, 68, 53, 59, 65, 98, 88, 38, 70, 60, 64, 51, 59, 54, 55, 65, 68, 88, 62, 45, 54, 96, 80, 56, 102, 76, 92, 70, 73, 71, 75, 77, 64, 67, 78, 89, 53, 74, 82, 72, 124, 49, 60, 100, 69, 43, 62, 132, 47, 68, 64, 46, 66, 51, 50, 72, 66, 87, 63, 61, 42, 69, 63, 63, 55, 44, 88, 75, 78, 78, 54, 61, 75, 66, 90, 91, 95, 55, 92, 117, 53, 75, 59, 67, 71, 90, 68, 74, 65, 71, 116, 62, 95, 60, 74, 66, 137, 59, 214, 49, 46, 46, 97, 64, 68, 51, 46, 49, 65, 52, 101, 61, 77, 90, 87, 68, 58, 166, 79, 53, 70, 95, 70, 61, 79, 99, 79, 60, 58, 74, 76, 68, 95, 56, 73, 72, 62, 108, 52, 67, 95, 55, 86, 103, 67, 51, 26, 58, 50, 72, 61, 60, 64, 52, 57, 90, 112, 77, 52, 97, 74, 41, 53, 141, 54, 84, 79, 135, 140, 60, 56, 65, 83, 44, 61, 95, 48, 92, 71, 64, 95, 92, 76, 58, 78, 71, 88, 98, 78, 79, 68, 113, 61, 82, 84, 147, 53, 37, 41, 82, 85, 79, 99, 85, 101, 84, 66, 86, 74, 110, 85, 60, 80, 25, 55, 66, 64, 95, 20, 61, 81, 37, 45, 57, 89, 69, 86, 51, 94, 101, 83, 65, 47, 61, 78, 77, 73, 56, 43, 69, 58, 64, 79, 95, 58, 89, 103, 52, 101, 57, 87, 74, 60, 91, 65, 91, 136, 57, 81, 53, 40, 51, 53, 51, 87, 56, 51, 73, 38, 42, 36, 72, 113, 74, 154, 68, 111, 83, 81, 73, 71, 41, 56, 40, 72, 56, 89, 80, 62, 53, 47, 100, 83, 88, 45, 81, 70, 50, 55, 47, 66, 25, 24, 68, 26, 27, 32, 36, 36, 142, 43, 61, 71, 103, 86, 74, 48, 59, 56, 70, 64, 46, 69, 47, 59, 48, 103, 56, 73, 79, 154, 155, 75, 159, 126, 47, 53, 41, 53, 79, 70, 93, 88, 60, 89, 66, 41, 101, 41, 53, 59, 64, 69, 81, 96, 73, 104, 98, 120, 57, 74, 77, 119, 93, 60, 50, 70, 52, 71, 57, 83, 63, 74, 57, 48, 68, 68, 53, 87, 51, 68, 69, 53, 61, 72, 55, 68, 59, 45, 61, 77, 56, 101, 91, 47, 69, 48, 48, 57, 41, 67, 59, 59, 60, 88, 94, 73, 61, 62, 132, 93, 151, 80, 61, 67, 65, 81, 54, 55, 98, 49, 68, 69, 63, 50, 47, 79, 89, 97, 74, 50, 69, 93, 102, 88, 48, 113, 103, 61, 53, 102, 83, 78, 133, 70, 42, 80, 61, 64, 68, 50, 75, 67, 59, 109, 89, 83, 52, 49, 71, 67, 95, 64, 92, 61, 55, 78, 71, 64, 68, 47, 88, 52, 59, 76, 87, 50, 57, 64, 92, 77, 57, 69, 61, 70, 83, 69, 60, 48, 91, 60, 66, 58, 82, 98, 85, 73, 65, 76, 78, 102, 80, 48, 58, 107, 86, 120, 67, 64, 57, 71, 79, 94, 56, 76, 232, 39, 98, 71, 101, 95, 52, 84, 62, 110, 77, 53, 74, 48, 96, 107, 57, 87, 81, 54, 43, 41, 77, 42, 41, 78, 42, 81, 91, 84, 62, 49, 74, 108, 58, 91, 95, 57, 66, 68, 64, 67, 58, 67, 74, 69, 51, 85, 84, 78, 64, 82, 52, 67, 62, 80, 62, 67, 75, 59, 71, 74, 65, 65, 62, 90, 76, 64, 88, 74, 66, 68, 117, 78, 114, 63, 167, 92, 82, 94, 60, 92, 79, 73, 64, 91, 73, 69, 64, 67, 75, 64, 69, 45, 59, 37, 80, 53, 97, 96, 76, 92, 56, 102, 86, 77, 93, 48, 61, 75, 74, 64, 62, 91, 67, 55, 90, 77, 85, 58, 72, 74, 53, 61, 79, 83, 59, 63, 84, 64, 64, 47, 53, 91, 57, 65, 70, 34, 55, 97, 59, 79, 62, 44, 32, 67, 91, 73, 65, 86, 170, 79, 154, 59, 49, 212, 79, 82, 100, 105, 64, 92, 121, 93, 41, 76, 43, 59, 43, 73, 76, 64, 56, 63, 47, 54, 79, 115, 62, 81, 95, 75, 94, 58, 90, 53, 66, 152, 41, 65, 54, 46, 60, 73, 51, 56, 57, 87, 68, 65, 73, 81, 141, 60, 75, 89, 66, 65, 69, 60, 79, 79, 69, 77, 77, 80, 65, 37, 58, 67, 79, 183, 53, 114, 85, 90, 63, 87, 62, 82, 86, 74, 85, 89, 47, 65, 78, 108, 49, 90, 102, 167, 58, 87, 106, 125, 76, 89, 77, 105, 93, 92, 66, 62, 76, 88, 86, 104, 72, 56, 74, 78, 75, 90, 52, 73, 70, 74, 79, 64, 83, 72, 61, 174, 49, 103, 67, 70, 75, 107, 64, 101, 97, 73, 95, 75, 74, 62, 123, 64, 64, 96, 71, 81, 65, 61, 66, 78, 98, 45, 85, 98, 92, 112, 60, 63, 74, 86, 93, 46, 62, 100, 76, 64, 62, 59, 67, 70, 43, 105, 60, 75, 84, 75, 60, 57, 81, 89, 57, 73, 98, 83, 72, 93, 52, 59, 75, 64, 59, 69, 70, 75, 67, 73, 60, 47, 71, 123, 60, 70, 90, 74, 79, 58, 76, 89, 65, 99, 80, 67, 57, 70, 75, 82, 68, 59, 59, 67, 59, 86, 82, 95, 67, 66, 79, 48, 68, 61, 98, 68, 88, 113, 58, 57, 122, 91, 66, 71, 58, 89, 61, 61, 64, 94, 69, 76, 114, 104, 81, 64, 57, 83, 75, 45, 69, 48, 61, 61, 62, 64, 72, 82, 83, 72, 120, 46, 61, 60, 69, 57, 61, 70, 64, 59, 64, 71, 65, 94, 83, 61, 71, 74, 65, 55, 51, 93, 58, 58, 46, 83, 45, 65, 105, 69, 59, 58, 75, 70, 64, 71, 69, 61, 61, 57, 60, 75, 54, 59, 77, 63, 93, 80, 98, 110, 46, 82, 69, 58, 60, 61, 60, 64, 57, 108, 40, 61, 155, 68, 94, 104, 85, 80, 110, 81, 90, 59, 57, 129, 70, 99, 52, 102, 80, 99, 44, 69, 88, 67, 57, 59, 61, 74, 101, 62, 61, 57, 105, 70, 103, 100, 72, 115, 109, 106, 107, 107, 60, 114, 96, 109, 39, 101, 48, 81, 108, 90, 86, 112, 71, 73, 69, 88, 66, 56, 112, 62, 84, 93, 74, 63, 90, 70, 63, 69, 79, 49, 100, 85, 105, 119, 122, 123, 48, 46, 48, 75, 95, 65, 64, 76, 49, 71, 87, 108, 68, 103, 72, 60, 71, 85, 77, 62, 62, 57, 102, 85, 81, 111, 54, 74, 102, 220, 68, 71, 96, 80, 76, 53, 104, 62, 92, 72, 140, 80, 94, 75, 64, 92, 111, 79, 59, 107, 41, 59, 101, 61, 98, 77, 65, 89, 79, 121, 63, 124, 65, 86, 101, 95, 94, 83, 79, 107, 92, 83, 102, 114, 64, 67, 81, 51, 83, 86, 44, 44, 81, 81, 98, 85, 97, 92, 70, 103, 62, 71, 87, 73, 65, 90, 89, 49, 94, 86, 56, 59, 76, 51, 100, 68, 78, 96, 96, 104, 87, 60, 83, 104, 73, 73, 108, 70, 77, 80, 87, 106, 98, 60, 105, 109, 84, 55, 67, 83, 102, 37, 52, 91, 99, 66, 113, 62, 96, 86, 90, 91, 129, 82, 55, 92, 43, 54, 82, 105, 66, 97, 67, 90, 102, 97, 91, 93, 74, 87, 77, 69, 112, 98, 88, 77, 78, 91, 81, 96, 95, 86, 67, 124, 71, 59, 63, 58, 56, 64, 93, 76, 57, 61, 64, 89, 109, 117, 108, 98, 74, 103, 96, 67, 78, 73, 96, 91, 70, 68, 73, 98, 88, 81, 71, 110, 67, 96, 91, 84, 68, 89, 83, 65, 105, 87, 92, 83, 64, 95, 73, 59, 90, 86, 93, 84, 101, 108, 123, 55, 89, 106, 95, 92, 90, 74, 75, 85, 88, 82, 80, 60, 73, 42, 89, 91, 119, 69, 59, 85, 67, 59, 64, 111, 68, 50, 86, 49, 104, 37, 85, 56, 99, 48, 50, 91, 54, 106, 84, 129, 111, 80, 98, 91, 59, 85, 43, 56, 101, 92, 78, 95, 100, 70, 87, 87, 91, 121, 60, 70, 76, 100, 107, 69, 73, 92, 71, 75, 83, 56, 103, 78, 94, 75, 45, 65, 67, 82, 113, 94, 129, 93, 90, 102, 71, 32, 54, 64, 104, 66, 64, 99, 72, 64, 69, 51, 41, 81, 102, 87, 87, 90, 67, 61, 79, 107, 66, 74, 63, 58, 68, 82, 59, 91, 65, 105, 61, 59, 71, 55, 73, 55, 69, 103, 71, 57, 68, 91, 97, 62, 107, 60, 97, 128, 92, 55, 44, 105, 106, 86, 79, 101, 96, 112, 70, 91, 86, 88, 96, 76, 93, 98, 123, 56, 46, 59, 90, 46, 99, 93, 74, 111, 96, 119, 67, 80, 83, 78, 66, 99, 61, 67, 79, 76, 45, 86, 107, 75, 57, 52, 123, 87, 60, 110, 57, 109, 54, 96, 88, 74, 84, 117, 93, 59, 73, 65, 74, 84, 70, 78, 70, 72, 99, 86, 79, 54, 68, 64, 75, 64, 75, 77, 52, 98, 68, 57, 61, 52, 83, 72, 110, 77, 38, 92, 71, 111, 80, 77, 102, 114, 46, 89, 95, 63, 105, 77, 110, 86, 53, 65, 88, 73, 53, 69, 77, 61, 54, 66, 81, 127, 103, 70, 45, 84, 96, 113, 79, 65, 50, 77, 87, 34, 86, 81, 96, 65, 73, 47, 109, 102, 112, 101, 89, 108, 129, 89, 94, 67, 100, 62, 49, 91, 42, 118, 67, 59, 62, 86, 64, 52, 73, 95, 92, 94, 74, 77, 62, 52, 75, 85, 63, 94, 57, 48, 106, 86, 76, 88, 119, 76, 98, 112, 63, 50, 67, 101, 67, 99, 124, 130, 126, 116, 72, 113, 91, 73, 83, 100, 91, 47, 77, 103, 47, 65, 94, 92, 87, 63, 95, 89, 85, 97, 87, 45, 61, 115, 73, 87, 67, 64, 39, 112, 61, 59, 71, 63, 67, 60, 95, 73, 99, 94, 119, 85, 79, 56, 46, 63, 91, 74, 78, 45, 97, 120, 66, 67, 83, 80, 99, 93, 110, 84, 65, 82, 96, 99, 101, 81, 96, 103, 101, 103, 87, 111, 85, 84, 78, 102, 86, 103, 87, 76, 105, 92, 96, 85, 104, 88, 95, 104, 73, 77, 116, 106, 86, 80, 102, 77, 104, 81, 96, 119, 87, 55, 53, 48, 46, 106, 58, 72, 73, 86, 107, 86, 84, 71, 41, 100, 82, 124, 86, 84, 50, 96, 100, 124, 95, 68, 61, 50, 103, 63, 59, 91, 61, 77, 98, 122, 92, 82, 72, 86, 88, 39, 77, 92, 77, 82, 100, 77, 70, 87, 87, 105, 88, 83, 119, 37, 116, 109, 101, 80, 124, 89, 50, 66, 117, 69, 67, 67, 110, 83, 117, 130, 101, 99, 57, 80, 91, 91, 46, 56, 106, 81, 80, 99, 59, 86, 101, 142, 74, 78, 46, 96, 99, 79, 79, 94, 45, 45, 104, 88, 64, 81, 83, 45, 62, 106, 66, 86, 75, 75, 108, 73, 54, 49, 93, 114, 41, 67, 59, 105, 69, 56, 60, 71, 90, 83, 72, 87, 76, 130, 57, 97, 54, 99, 96, 64, 105, 117, 119, 98, 74, 86, 80, 109, 78, 71, 76, 55, 82, 67, 74, 90, 116, 111, 57, 94, 89, 73, 65, 124, 86, 54, 116, 63, 66, 86, 100, 103, 92, 77, 93, 96, 106, 74, 93, 89, 70, 66, 71, 106, 52, 90, 68, 46, 50, 79, 50, 77, 43, 47, 120, 87, 84, 113, 81, 64, 62, 82, 66, 77, 46, 83, 98, 68, 92, 57, 105, 75, 70, 69, 76, 74, 63, 79, 84, 80, 90, 64, 94, 88, 73, 119, 99, 54, 75, 75, 86, 76, 61, 122, 65, 88, 116, 111, 66, 70, 105, 55, 77, 84, 102, 67, 70, 81, 83, 64, 85, 67, 98, 91, 60, 133, 73, 77, 96, 106, 74, 91, 73, 70, 78, 120, 88, 81, 112, 63, 89, 61, 95, 73, 59, 67, 71, 117, 136, 81, 72, 82, 97, 68, 84, 88, 86, 71, 101, 74, 73, 112, 110, 128, 84, 63, 65, 48, 87, 101, 73, 77, 100, 89, 75, 61, 64, 117, 53, 112, 92, 55, 83, 104, 125, 87, 100, 63, 105, 71, 105, 101, 115, 38, 67, 83, 92, 74, 92, 66, 73, 87, 114, 68, 71, 62, 112, 101, 78, 90, 114, 73, 43, 56, 65, 62, 78, 77, 62, 87, 71, 56, 59, 69, 64, 61, 64, 57, 93, 112, 59, 93, 60, 60, 68, 101, 68, 63, 59, 94, 58, 105, 56, 58, 95, 59, 117, 65, 55, 59, 88, 54, 91, 74, 87, 76, 105, 73, 76, 92, 87, 89, 100, 82, 61, 74, 61, 74, 71, 76, 74, 127, 85, 76, 100, 115, 118, 94, 102, 62, 91, 57, 87, 66, 72, 69, 67, 60, 85, 83, 119, 91, 59, 86, 59, 91, 69, 69, 106, 56, 77, 64, 71, 72, 41, 50, 80, 92, 67, 56, 86, 86, 76, 68, 91, 70, 116, 110, 63, 42, 83, 87, 71, 88, 82, 45, 75, 53, 75, 74, 61, 62, 53, 74, 105, 104, 88, 76, 117, 70, 83, 94, 48, 84, 83, 100, 91, 92, 111, 93, 38, 75, 73, 71, 73, 97, 52, 156, 80, 57, 72, 102, 63, 69, 94, 89, 72, 79, 83, 96, 103, 66, 107, 108, 60, 99, 62, 56, 99, 77, 117, 76, 118, 56, 71, 75, 64, 105, 64, 112, 76, 101, 39, 85, 89, 90, 75, 63, 84, 90, 61, 89, 114, 77, 64, 73, 69, 74, 57, 66, 69, 71, 48, 89, 86, 63, 90, 95, 87, 69, 56, 114, 86, 105, 86, 105, 111, 68, 119, 91, 86, 102, 66, 56, 71, 71, 66, 97, 84, 108, 90, 63, 100, 109, 95, 80, 86, 86, 77, 84, 52, 63, 87, 68, 73, 63, 97, 75, 77, 59, 83, 117, 70, 63, 64, 89, 64, 75, 94, 66, 96, 63, 83, 117, 63, 85, 93, 117, 63, 96, 68, 100, 86, 83, 67, 87, 74, 80, 89, 105, 75, 116, 77, 113, 71, 50, 87, 112, 34, 85, 104, 90, 63, 106, 80, 53, 72, 79, 69, 48, 76, 89, 73, 78, 90, 83, 64, 80, 87, 95, 57, 92, 41, 84, 110, 93, 81, 117, 103, 116, 86, 96, 55, 63, 37, 81, 52, 63, 49, 46, 68, 49, 100, 90, 99, 68, 89, 101, 95, 57, 80, 104, 76, 78, 84, 59, 102, 57, 88, 92, 63, 78, 87, 107, 77, 90, 113, 68, 109, 82, 67, 86, 56, 67, 108, 64, 55, 95, 102, 57, 90, 58, 75, 73, 89, 76, 75, 112, 66, 66, 99, 63, 90, 72, 62, 78, 118, 102, 68, 54, 100, 107, 59, 94, 72, 71, 72, 66, 61, 75, 79, 45, 86, 72, 86, 102, 116, 76, 42, 104, 102, 43, 68, 70, 71, 63, 77, 60, 73, 98, 110, 81, 111, 113, 104, 130, 103, 70, 85, 41, 73, 64, 65, 85, 60, 57, 72, 112, 77, 71, 103, 46, 101, 60, 56, 66, 70, 110, 92, 106, 74, 76, 93, 97, 102, 74, 91, 89, 57, 84, 103, 102, 56, 79, 60, 90, 72, 57, 77, 121, 77, 105, 63, 78, 53, 71, 57, 67, 105, 86, 45, 73, 89, 87, 86, 82, 70, 92, 67, 81, 93, 66, 43, 76, 77, 107, 91, 95, 115, 117, 64, 61, 46, 54, 83, 96, 59, 87, 46, 102, 60, 54, 66, 78, 70, 97, 82, 83, 88, 58, 61, 95, 96, 93, 88, 80, 84, 119, 72, 119, 46, 60, 105, 90, 62, 59, 88, 63, 87, 86, 64, 117, 102, 71, 81, 107, 102, 86, 104, 111, 71, 74, 88, 72, 109, 83, 86, 65, 100, 83, 88, 97, 60, 62, 69, 102, 90, 73, 77, 65, 137, 109, 97, 105, 62, 90, 59, 126, 69, 89, 80, 94, 90, 121, 113, 60, 44, 90, 129, 72, 106, 157, 83, 104, 77, 85, 89, 67, 84, 55, 67, 91, 78, 74, 89, 90, 57, 49, 44, 92, 53, 56, 89, 42, 53, 93, 117, 75, 45, 61, 116, 86, 108, 107, 74, 60, 87, 99, 64, 92, 77, 72, 92, 72, 77, 105, 134, 91, 80, 107, 85, 67, 105, 73, 55, 51, 67, 64, 67, 63, 61, 112, 86, 71, 78, 65, 70, 75, 65, 102, 55, 68, 121, 63, 112, 85, 69, 83, 102, 71, 51, 89, 64, 65, 44, 61, 100, 132, 158, 102, 80, 72, 58, 61, 65, 66, 79, 77, 62, 89, 55, 108, 102, 65, 104, 63, 94, 47, 100, 44, 34, 61, 45, 48, 68, 39, 54, 87, 55, 60, 62, 66, 35, 40, 50, 63, 80, 81, 83, 48, 58, 83, 72, 90, 76, 120, 88, 135, 97, 61, 73, 87, 81, 46, 66, 98, 68, 69, 88, 90, 85, 82, 49, 85, 84, 77, 83, 72, 46, 59, 85, 96, 101, 68, 103, 77, 55, 56, 77, 88, 62, 79, 34, 77, 210, 80, 76, 66, 67, 94, 85, 57, 86, 34, 50, 103, 80, 80, 62, 42, 77, 95, 82, 98, 70, 106, 46, 45, 71, 70, 54, 67, 93, 57, 72, 49, 87, 62, 55, 97, 72, 96, 78, 47, 91, 55, 69, 95, 113, 92, 76, 81, 62, 89, 85, 55, 101, 112, 141, 105, 87, 90, 63, 56, 109, 70, 97, 71, 97, 53, 114, 65, 75, 39, 85, 67, 50, 118, 81, 71, 52, 79, 62, 76, 72, 67, 66, 81, 72, 105, 55, 64, 63, 47, 55, 55, 30, 66, 41, 52, 51, 28, 73, 66, 62, 60, 63, 101, 88, 85, 75, 78, 55, 70, 63, 63, 74, 97, 80, 102, 103, 98, 83, 79, 73, 88, 76, 72, 59, 94, 63, 75, 58, 57, 56, 88, 145, 27, 74, 69, 145, 126, 122, 74, 82, 101, 65, 69, 54, 79, 61, 93, 112, 70, 81, 79, 89, 72, 52, 84, 89, 74, 45, 61, 67, 103, 66, 34, 63, 66, 55, 84, 94, 91, 69, 57, 50, 83, 62, 82, 98, 74, 63, 66, 93, 66, 76, 59, 69, 41, 58, 76, 75, 64, 101, 48, 89, 58, 58, 65, 50, 75, 53, 67, 53, 87, 80, 55, 59, 82, 77, 85, 89, 105, 43, 63, 48, 89, 61, 40, 60, 90, 77, 43, 54, 129, 44, 72, 43, 30, 67, 67, 30, 82, 100, 60, 49, 110, 96, 41, 80, 64, 103, 44, 32, 93, 66, 61, 55, 32, 74, 56, 102, 63, 75, 63, 88, 69, 51, 104, 57, 114, 87, 69, 84, 95, 91, 108, 53, 48, 58, 65, 80, 66, 117, 90, 55, 54, 50, 77, 89, 82, 75, 68, 50, 96, 79, 60, 43, 75, 54, 67, 80, 87, 43, 41, 53, 59, 78, 47, 35, 43, 64, 56, 30, 76, 54, 59, 60, 78, 78, 64, 52, 70, 91, 65, 68, 56, 70, 48, 86, 85, 54, 74, 82, 79, 69, 71, 91, 64, 77, 73, 62, 61, 88, 83, 67, 76, 50, 79, 67, 56, 118, 54, 47, 34, 190, 91, 71, 67, 53, 70, 59, 41, 40, 48, 125, 35, 62, 79, 55, 86, 74, 83, 46, 49, 91, 55, 42, 53, 65, 53, 92, 118, 67, 88, 52, 71, 89, 65, 84, 40, 46, 126, 195, 71, 85, 45, 104, 44, 110, 91, 37, 80, 118, 97, 96, 98, 121, 72, 53, 61, 29, 59, 46, 43, 84, 72, 90, 96, 81, 49, 92, 49, 70, 77, 56, 46, 93, 74, 48, 61, 58, 98, 65, 48, 67, 39, 75, 99, 59, 86, 32, 113, 84, 27, 82, 79, 88, 70, 50, 88, 65, 68, 52, 69, 81, 41, 59, 69, 75, 96, 93, 85, 71, 53, 79, 81, 60, 100, 90, 118, 63, 84, 42, 113, 64, 55, 73, 72, 67, 67, 63, 90, 69, 88, 88, 62, 47, 62, 87, 71, 39, 126, 98, 51, 86, 97, 47, 63, 49, 90, 106, 66, 85, 124, 94, 73, 72, 94, 65, 72, 66, 72, 58, 62, 108, 75, 56, 57, 93, 32, 82, 37, 28, 66, 79, 43, 88, 93, 53, 106, 55, 108, 111, 80, 90, 69, 23, 90, 54, 138, 75, 29, 76, 71, 43, 64, 55, 93, 81, 56, 60, 71, 97, 58, 99, 84, 67, 74, 77, 104, 113, 74, 55, 88, 80, 77, 80, 70, 66, 73, 84, 72, 56, 77, 55, 84, 67, 80, 59, 55, 97, 72, 86, 75, 84, 98, 44, 72, 48, 58, 64, 46, 72, 80, 87, 77, 111, 69, 53, 73, 91, 49, 41, 49, 99, 59, 104, 67, 69, 79, 50, 76, 76, 151, 65, 64, 30, 100, 63, 81, 79, 53, 96, 52, 68, 53, 61, 65, 43, 97, 43, 95, 48, 125, 68, 64, 67, 68, 94, 54, 49, 47, 58, 63, 89, 52, 38, 77, 78, 121, 68, 51, 78, 89, 78, 82, 72, 45, 66, 78, 65, 73, 60, 75, 70, 69, 78, 65, 82, 48, 43, 71, 107, 95, 97, 46, 80, 45, 93, 57, 91, 74, 66, 48, 81, 47, 97, 40, 106, 65, 99, 87, 30, 39, 69, 37, 111, 61, 67, 59, 51, 81, 132, 76, 52, 75, 80, 84, 75, 72, 61, 81, 97, 61, 98, 96, 72, 77, 63, 54, 83, 29, 66, 87, 115, 62, 56, 67, 72, 70, 52, 115, 63, 88, 35, 36, 29, 41, 71, 52, 106, 54, 74, 76, 24, 72, 101, 156, 99, 45, 35, 92, 34, 95, 81, 61, 64, 42, 84, 99, 73, 46, 76, 79, 58, 78, 153, 69, 65, 55, 120, 50, 67, 70, 58, 56, 56, 65, 83, 61, 89, 73, 45, 97, 54, 75, 79, 77, 62, 89, 66, 79, 81, 48, 48, 64, 78, 46, 69, 91, 83, 98, 76, 78, 90, 30, 79, 30, 64, 111, 49, 51, 109, 100, 77, 73, 51, 105, 71, 95, 90, 89, 41, 44, 117, 80, 50, 58, 88, 80, 81, 93, 73, 41, 61, 88, 84, 65, 70, 64, 69, 70, 79, 61, 86, 84, 79, 86, 55, 77, 60, 64, 63, 110, 55, 80, 77, 63, 82, 59, 63, 69, 58, 88, 87, 56, 47, 93, 41, 58, 56, 55, 95, 75, 78, 106, 74, 65, 42, 40, 131, 51, 115, 78, 108, 93, 53, 73, 71, 95, 93, 79, 90, 65, 91, 65, 66, 75, 62, 93, 67, 49, 137, 87, 71, 73, 56, 99, 101, 63, 89, 93, 73, 88, 52, 68, 63, 48, 99, 61, 86, 63, 57, 67, 100, 91, 117, 94, 83, 88, 99, 44, 99, 113, 39, 49, 120, 43, 95, 93, 55, 43, 93, 103, 112, 56, 42, 93, 76, 99, 61, 74, 84, 36, 68, 56, 85, 80, 49, 78, 131, 93, 88, 74, 100, 58, 31, 75, 30, 63, 97, 94, 62, 65, 84, 65, 68, 42, 73, 40, 81, 50, 81, 79, 72, 76, 133, 75, 97, 65, 50, 67, 127, 62, 46, 80, 27, 59, 62, 36, 29, 56, 58, 55, 80, 43, 82, 71, 77, 98, 101, 55, 111, 59, 81, 107, 57, 91, 72, 94, 81, 83, 106, 64, 51, 22, 56, 72, 87, 116, 44, 53, 70, 53, 57, 65, 75, 104, 72, 82, 51, 69, 60, 74, 94, 104, 90, 101, 93, 93, 106, 86, 85, 68, 87, 83, 93, 72, 82, 69, 78, 58, 58, 57, 112, 77, 100, 51, 51, 51, 66, 88, 67, 83, 49, 98, 75, 31, 66, 37, 54, 78, 50, 58, 71, 41, 47, 43, 64, 83, 120, 123, 94, 40, 74, 75, 100, 67, 157, 136, 54, 64, 44, 99, 146, 77, 77, 87, 36, 63, 50, 40, 54, 44, 86, 65, 52, 96, 81, 57, 76, 61, 107, 53, 47, 84, 64, 76, 108, 52, 47, 183, 81, 75, 67, 41, 104, 90, 105, 72, 61, 107, 74, 91, 104, 122, 65, 93, 74, 108, 75, 82, 85, 142, 64, 41, 64, 47, 68, 73, 78, 124, 71, 109, 69, 64, 67, 66, 47, 77, 73, 106, 104, 102, 47, 59, 94, 130, 138, 121, 53, 93, 52, 30, 49, 53, 110, 109, 94, 73, 75, 39, 72, 70, 77, 122, 95, 58, 136, 89, 80, 89, 56, 152, 93, 105, 89, 76, 94, 42, 94, 67, 96, 40, 24, 32, 39, 49, 52, 178, 47, 143, 39, 206, 30, 41, 37, 51, 32, 87, 20, 26, 24, 70, 28, 41, 40, 28, 44, 31, 23, 25, 89, 54, 41, 62, 47, 54, 52, 115, 59, 51, 53, 84, 20, 32, 23, 37, 33, 32, 34, 28, 32, 32, 43, 29, 46, 35, 33, 49, 83, 38, 23, 32, 41, 48, 22, 24, 39, 23, 23, 54, 25, 45, 47, 75, 50, 58, 62, 127, 113, 62, 53, 119, 88, 28, 45, 85, 36, 29, 59, 47, 38, 76, 63, 33, 125, 50, 71, 49, 61, 35, 42, 111, 49, 39, 39, 78, 88, 54, 67, 64, 87, 99, 31, 41, 38, 31, 35, 44, 51, 51, 44, 36, 43, 29, 28, 37, 20, 31, 51, 32, 47, 36, 39, 42, 25, 62, 28, 71, 22, 58, 76, 82, 39, 36, 26, 35, 38, 78, 42, 89, 85, 100, 41, 62, 42, 28, 44, 34, 45, 35, 37, 25, 44, 60, 47, 68, 36, 30, 45, 55, 71, 90, 42, 45, 38, 42, 138, 25, 56, 42, 51, 35, 41, 34, 44, 42, 62, 54, 59, 97, 95, 105, 38, 41, 56, 42, 70, 28, 37, 53, 70, 24, 53, 29, 39, 25, 24, 60, 42, 31, 50, 60, 30, 40, 30, 34, 51, 28, 37, 37, 31, 71, 47, 50, 65, 54, 57, 28, 74, 37, 95, 93, 49, 28, 20, 52, 50, 20, 78, 116, 68, 60, 51, 60, 74, 105, 43, 30, 83, 76, 81, 87, 46, 47, 55, 72, 127, 61, 49, 56, 63, 46, 54, 113, 51, 81, 106, 68, 62, 67, 66, 80, 58, 48, 50, 76, 62, 47, 58, 77, 86, 71, 58, 98, 30, 45, 64, 106, 80, 61, 87, 53, 47, 52, 44, 68, 47, 29, 102, 47, 97, 80, 87, 63, 74, 119, 70, 64, 126, 41, 85, 43, 50, 63, 61, 49, 64, 117, 109, 96, 51, 107, 103, 41, 99, 85, 63, 86, 78, 108, 79, 89, 78, 100, 62, 103, 95, 41, 125, 37, 92, 208, 46, 75, 54, 55, 119, 71, 44, 89, 118, 90, 45, 46, 58, 51, 45, 24, 40, 48, 114, 48, 61, 40, 55, 70, 39, 96, 90, 71, 60, 129, 22, 47, 45, 28, 56, 55, 50, 63, 86, 66, 48, 53, 71, 45, 41, 61, 66, 40, 69, 36, 52, 80, 61, 55, 80, 54, 66, 43, 87, 44, 39, 48, 53, 39, 57, 74, 76, 79, 47, 33, 42, 59, 26, 50, 41, 32, 74, 88, 101, 128, 67, 55, 69, 57, 78, 103, 70, 52, 71, 92, 44, 67, 47, 37, 60, 66, 70, 52, 116, 50, 42, 45, 75, 68, 53, 51, 90, 60, 58, 67, 50, 50, 56, 34, 114, 117, 111, 204, 80, 74, 59, 107, 71, 50, 71, 73, 62, 94, 26, 76, 52, 43, 70, 52, 125, 57, 48, 65, 47, 50, 41, 73, 44, 51, 151, 52, 150, 63, 56, 78, 63, 32, 63, 46, 75, 57, 170, 119, 68, 53, 61, 70, 147, 73, 116, 172, 80, 86, 92, 98, 96, 32, 67, 77, 57, 67, 59, 63, 43, 82, 43, 67, 46, 58, 81, 65, 60, 69, 64, 77, 49, 52, 64, 74, 136, 49, 61, 54, 74, 65, 50, 40, 64, 37, 56, 72, 69, 71, 51, 43, 42, 45, 82, 98, 59, 76, 94, 93, 57, 78, 45, 90, 38, 63, 57, 62, 79, 26, 61, 66, 25, 60, 155, 26, 102, 77, 38, 54, 50, 99, 96, 47, 71, 41, 97, 106, 53, 66, 91, 58, 111, 58, 91, 58, 45, 87, 37, 41, 37, 62, 41, 52, 116, 74, 47, 30, 76, 70, 71, 54, 59, 55, 42, 83, 56, 43, 21, 46, 68, 52, 45, 69, 48, 63, 82, 83, 81, 130, 77, 63, 46, 49, 51, 63, 69, 32, 34, 71, 37, 86, 58, 93, 29, 47, 87, 97, 65, 70, 66, 67, 43, 18, 28, 60, 46, 63, 31, 52, 35, 33, 50, 30, 41, 64, 42, 25, 27, 30, 48, 75, 50, 48, 60, 31, 64, 51, 42, 29, 56, 78, 45, 48, 54, 44, 35, 45, 104, 73, 92, 90, 78, 79, 60, 88, 50, 83, 52, 97, 117, 72, 38, 92, 37, 39, 75, 175, 49, 122, 62, 118, 43, 45, 43, 59, 32, 40, 21, 70, 55, 49, 46, 49, 67, 46, 50, 70, 68, 72, 79, 39, 98, 70, 54, 66, 66, 73, 121, 58, 122, 102, 70, 101, 79, 116, 86, 80, 105, 86, 70, 115, 68, 107, 87, 80, 71, 108, 98, 86, 103, 102, 110, 76, 85, 128, 103, 104, 62, 87, 64, 80, 72, 100, 80, 93, 126, 71, 99, 65, 61, 76, 124, 102, 101, 89, 88, 104, 61, 88, 89, 79, 110, 40, 64, 122, 97, 90, 74, 102, 47, 77, 69, 78, 49, 56, 132, 77, 67, 84, 80, 75, 66, 76, 67, 120, 88, 74, 58, 111, 114, 119, 43, 106, 84, 77, 60, 95, 106, 75, 71, 138, 112, 99, 105, 75, 92, 82, 46, 103, 75, 94, 78, 64, 74, 81, 68, 100, 78, 73, 120, 68, 61, 107, 97, 108, 98, 109, 132, 93, 129, 93, 99, 94, 62, 93, 102, 102, 58, 99, 81, 90, 120, 98, 106, 100, 107, 130, 74, 73, 73, 40, 86, 86, 83, 116, 100, 99, 63, 111, 68, 77, 94, 86, 65, 90, 71, 89, 123, 117, 109, 58, 78, 113, 98, 108, 113, 74, 82, 68, 105, 100, 110, 63, 90, 72, 83, 97, 78, 102, 70, 64, 57, 85, 91, 107, 78, 99, 106, 87, 63, 113, 93, 106, 67, 113, 101, 89, 80, 96, 73, 72, 76, 77, 100, 96, 65, 100, 71, 105, 107, 89, 74, 83, 83, 64, 51, 46, 108, 91, 94, 97, 92, 106, 85, 69, 47, 62, 96, 77, 43, 61, 92, 117, 82, 71, 104, 81, 57, 103, 99, 80, 77, 70, 46, 73, 92, 83, 44, 90, 92, 116, 83, 72, 66, 102, 87, 105, 43, 78, 117, 110, 64, 88, 78, 79, 97, 47, 67, 46, 54, 67, 70, 64, 88, 73, 82, 102, 70, 104, 105, 84, 105, 82, 86, 114, 79, 97, 125, 71, 131, 78, 67, 117, 85, 85, 100, 73, 49, 44, 66, 46, 38, 80, 81, 93, 111, 61, 98, 77, 98, 104, 88, 56, 62, 51, 55, 55, 76, 72, 87, 48, 69, 55, 66, 126, 57, 90, 73, 70, 79, 80, 59, 105, 71, 104, 99, 46, 110, 111, 98, 114, 118, 42, 124, 99, 113, 67, 83, 82, 74, 91, 85, 72, 75, 79, 46, 40, 68, 48, 81, 95, 130, 73, 101, 81, 46, 52, 73, 55, 98, 63, 100, 92, 96, 73, 82, 70, 81, 77, 53, 103, 40, 73, 78, 82, 89, 72, 46, 45, 96, 108, 95, 41, 100, 89, 48, 59, 86, 45, 99, 53, 97, 82, 90, 77, 97, 109, 81, 95, 99, 106, 89, 100, 57, 99, 107, 108, 95, 53, 124, 112, 96, 74, 93, 76, 72, 77, 88, 45, 89, 85, 99, 82, 44, 55, 103, 71, 72, 60, 73, 79, 75, 63, 87, 105, 88, 51, 64, 61, 73, 47, 90, 103, 105, 88, 108, 105, 55, 115, 104, 69, 95, 104, 89, 94, 108, 108, 82, 47, 56, 101, 100, 81, 66, 121, 90, 123, 80, 98, 102, 116, 110, 81, 101, 102, 74, 76, 74, 79, 107, 99, 87, 112, 78, 114, 91, 70, 107, 86, 64, 63, 41, 84, 49, 43, 65, 110, 80, 46, 116, 81, 104, 44, 108, 110, 194, 89, 105, 47, 109, 97, 67, 94, 92, 65, 91, 69, 99, 74, 84, 70, 73, 69, 105, 89, 78, 104, 101, 39, 59, 79, 73, 101, 104, 74, 109, 106, 80, 73, 65, 46, 69, 55, 60, 59, 97, 75, 98, 60, 83, 73, 100, 59, 82, 62, 85, 71, 77, 54, 50, 79, 77, 77, 82, 46, 44, 118, 94, 82, 76, 78, 92, 77, 77, 97, 101, 104, 79, 86, 86, 79, 67, 99, 77, 94, 47, 59, 109, 63, 100, 90, 42, 76, 100, 105, 70, 50, 46, 57, 89, 79, 81, 76, 65, 97, 81, 94, 82, 53, 55, 69, 89, 51, 102, 79, 70, 98, 64, 112, 95, 89, 85, 92, 118, 74, 42, 54, 111, 92, 55, 82, 40, 47, 85, 78, 65, 67, 98, 70, 44, 41, 87, 72, 83, 79, 93, 89, 114, 89, 109, 97, 51, 40, 78, 101, 58, 93, 54, 57, 88, 82, 68, 101, 76, 63, 66, 79, 113, 78, 113, 71, 76, 65, 53, 39, 46, 46, 67, 45, 74, 37, 121, 86, 80, 75, 56, 100, 76, 108, 72, 110, 65, 55, 39, 93, 63, 38, 91, 73, 59, 74, 80, 51, 105, 79, 88, 56, 58, 91, 74, 94, 79, 118, 42, 99, 70, 116, 62, 86, 91, 83, 63, 64, 111, 55, 76, 88, 86, 67, 71, 90, 88, 64, 48, 104, 68, 52, 98, 70, 87, 85, 81, 45, 59, 99, 104, 40, 65, 67, 86, 84, 99, 46, 89, 74, 99, 70, 49, 46, 64, 89, 102, 53, 44, 76, 69, 69, 86, 88, 70, 57, 58, 111, 66, 57, 108, 70, 87, 78, 85, 56, 103, 75, 71, 89, 88, 89, 104, 95, 119, 66, 102, 92, 86, 91, 134, 100, 95, 62, 99, 73, 69, 55, 102, 85, 96, 76, 104, 64, 74, 85, 52, 118, 48, 104, 108, 88, 107, 46, 95, 46, 88, 65, 72, 59, 50, 98, 82, 72, 120, 64, 88, 76, 86, 89, 105, 69, 73, 97, 55, 86, 77, 96, 90, 70, 47, 112, 92, 98, 105, 53, 96, 67, 83, 83, 89, 110, 82, 70, 89, 64, 97, 124, 90, 76, 59, 79, 93, 114, 72, 74, 87, 74, 59, 71, 86, 86, 100, 73, 103, 58, 91, 42, 89, 56, 92, 71, 106, 105, 99, 72, 99, 82, 73, 68, 112, 80, 100, 78, 48, 71, 100, 85, 99, 111, 70, 113, 78, 66, 79, 83, 92, 106, 52, 69, 64, 70, 92, 55, 83, 65, 56, 73, 45, 103, 71, 89, 97, 105, 97, 111, 76, 82, 65, 105, 69, 87, 111, 81, 46, 86, 45, 95, 37, 101, 57, 73, 106, 72, 103, 58, 107, 84, 57, 70, 53, 85, 95, 50, 73, 46, 53, 98, 74, 70, 88, 164, 39, 123, 69, 84, 77, 84, 79, 95, 63, 54, 82, 173, 77, 58, 54, 37, 48, 36, 52, 75, 71, 77, 74, 187, 72, 73, 82, 63, 170, 92, 36, 85, 80, 74, 133, 41, 70, 63, 67, 108, 69, 116, 77, 71, 48, 55, 41, 213, 115, 67, 74, 46, 235, 46, 42, 67, 87, 88, 99, 50, 40, 82, 41, 48, 63, 86, 69, 49, 54, 54, 84, 95, 80, 39, 68, 50, 76, 175, 102, 56, 63, 94, 109, 75, 85, 56, 76, 52, 83, 138, 36, 69, 73, 62, 53, 118, 53, 110, 59, 68, 130, 50, 58, 53, 117, 42, 44, 48, 49, 79, 127, 77, 94, 49, 73, 88, 75, 79, 47, 52, 98, 36, 65, 70, 98, 104, 144, 97, 69, 83, 65, 84, 64, 61, 73, 70, 48, 36, 81, 48, 57, 142, 89, 69, 51, 41, 95, 50, 57, 36, 96, 88, 52, 46, 52, 58, 88, 46, 79, 74, 77, 127, 65, 83, 125, 76, 75, 53, 100, 65, 98, 39, 57, 84, 55, 54, 50, 71, 91, 86, 41, 96, 77, 66, 93, 27, 51, 26, 37, 74, 57, 98, 128, 46, 122, 91, 88, 49, 97, 92, 43, 90, 67, 64, 82, 70, 63, 47, 157, 77, 64, 92, 32, 44, 37, 41, 64, 59, 65, 37, 80, 86, 46, 66, 63, 51, 141, 34, 50, 64, 73, 62, 29, 65, 114, 53, 62, 54, 68, 94, 54, 54, 84, 41, 44, 56, 99, 78, 93, 109, 50, 74, 98, 37, 64, 40, 37, 37, 53, 50, 40, 43, 62, 72, 53, 59, 64, 168, 63, 97, 68, 68, 96, 97, 81, 72, 37, 77, 54, 99, 105, 59, 74, 45, 48, 65, 45, 68, 54, 109, 68, 78, 79, 37, 92, 57, 216, 56, 92, 46, 54, 80, 44, 64, 73, 69, 64, 48, 57, 40, 82, 64, 104, 61, 60, 47, 60, 103, 95, 100, 77, 67, 85, 53, 56, 100, 54, 60, 37, 55, 75, 58, 54, 98, 46, 74, 32, 45, 31, 74, 69, 47, 40, 48, 52, 36, 60, 66, 70, 89, 88, 82, 68, 57, 46, 58, 129, 92, 110, 63, 58, 99, 80, 60, 53, 53, 102, 64, 97, 56, 112, 79, 127, 106, 51, 103, 59, 72, 96, 69, 70, 100, 60, 36, 37, 73, 94, 54, 60, 72, 91, 47, 170, 99, 78, 64, 69, 83, 82, 66, 99, 61, 71, 41, 138, 41, 58, 52, 67, 85, 100, 71, 93, 53, 62, 53, 41, 61, 64, 61, 53, 83, 122, 38, 87, 42, 45, 54, 61, 39, 67, 90, 99, 39, 48, 39, 46, 76, 85, 57, 35, 64, 148, 43, 51, 44, 55, 78, 57, 42, 58, 52, 86, 58, 63, 67, 88, 74, 62, 55, 69, 56, 45, 105, 53, 140, 86, 58, 82, 53, 54, 119, 53, 79, 44, 108, 55, 82, 87, 99, 55, 88, 76, 67, 52, 35, 41, 71, 62, 96, 34, 83, 94, 36, 101, 105, 41, 73, 26, 65, 58, 100, 70, 37, 71, 78, 65, 56, 61, 41, 36, 43, 62, 96, 41, 68, 74, 52, 62, 61, 108, 80, 109, 107, 118, 75, 59, 230, 69, 53, 55, 127, 77, 55, 71, 62, 78, 88, 140, 125, 37, 46, 54, 115, 56, 51, 78, 56, 53, 81, 81, 184, 85, 120, 64, 50, 60, 72, 70, 60, 127, 59, 37, 50, 61, 49, 63, 117, 91, 138, 51, 109, 67, 69, 83, 78, 73, 49, 102, 104, 99, 100, 123, 71, 88, 73, 72, 103, 25, 152, 42, 62, 138, 72, 109, 60, 71, 83, 98, 64, 34, 34, 70, 78, 53, 77, 56, 93, 99, 59, 68, 91, 75, 53, 67, 56, 69, 82, 67, 61, 79, 40, 62, 65, 105, 50, 70, 47, 83, 97, 79, 65, 59, 150, 64, 37, 44, 110, 65, 80, 41, 48, 130, 29, 52, 55, 47, 74, 69, 95, 52, 47, 60, 53, 146, 117, 127, 54, 53, 78, 57, 82, 73, 25, 97, 46, 50, 67, 86, 89, 83, 35, 86, 53, 65, 84, 56, 53, 102, 57, 83, 56, 112, 53, 60, 62, 71, 105, 39, 51, 83, 138, 83, 50, 70, 79, 68, 57, 68, 63, 64, 74, 73, 125, 95, 122, 85, 138, 56, 73, 48, 47, 82, 46, 105, 57, 166, 43, 57, 49, 120, 52, 92, 81, 47, 52, 110, 71, 53, 36, 88, 70, 127, 95, 75, 41, 54, 64, 50, 66, 95, 44, 78, 91, 74, 82, 78, 71, 74, 57, 65, 58, 47, 108, 66, 51, 121, 83, 52, 48, 86, 50, 89, 77, 56, 53, 129, 84, 103, 90, 57, 114, 47, 74, 62, 51, 85, 103, 60, 52, 59, 87, 83, 45, 62, 44, 55, 79, 105, 86, 54, 70, 41, 61, 68, 75, 81, 65, 79, 55, 58, 115, 58, 77, 91, 100, 86, 56, 134, 60, 95, 61, 74, 108, 103, 95, 99, 39, 95, 94, 111, 104, 149, 50, 73, 55, 79, 41, 58, 35, 44, 88, 119, 91, 71, 47, 68, 36, 67, 39, 50, 59, 87, 107, 85, 76, 39, 154, 60, 61, 45, 48, 81, 41, 103, 94, 125, 81, 54, 86, 84, 59, 60, 36, 106, 40, 23, 60, 128, 34, 166, 242, 99, 45, 63, 82, 99, 155, 41, 68, 33, 72, 43, 76, 60, 84, 60, 112, 98, 67, 65, 60, 73, 60, 133, 53, 35, 34, 49, 101, 138, 33, 59, 58, 84, 63, 41, 70, 50, 89, 93, 41, 158, 58, 86, 52, 52, 65, 50, 47, 82, 105, 53, 70, 79, 114, 40, 82, 80, 53, 63, 111, 115, 148, 53, 79, 57, 60, 46, 82, 52, 49, 81, 63, 60, 53, 66, 76, 111, 43, 116, 42, 41, 98, 81, 196, 72, 60, 39, 70, 36, 60, 37, 82, 112, 125, 98, 57, 53, 68, 62, 41, 53, 58, 80, 82, 36, 44, 108, 68, 62, 69, 44, 31, 37, 47, 83, 57, 101, 98, 54, 47, 53, 60, 53, 75, 41, 53, 63, 154, 82, 50, 103, 66, 41, 96, 46, 58, 35, 149, 86, 54, 90, 54, 40, 67, 93, 82, 53, 44, 52, 45, 102, 58, 61, 78, 50, 55, 83, 145, 60, 79, 67, 78, 62, 82, 126, 103, 46, 163, 56, 68, 53, 71, 95, 45, 50, 68, 95, 85, 59, 97, 83, 70, 75, 140, 65, 92, 95, 76, 77, 70, 134, 44, 86, 67, 110, 86, 45, 91, 125, 64, 57, 67, 83, 108, 44, 64, 118, 75, 83, 79, 114, 41, 70, 56, 62, 169, 63, 116, 90, 55, 82, 54, 50, 54, 55, 76, 54, 55, 104, 78, 66, 53, 26, 48, 57, 83, 121, 42, 82, 77, 109, 103, 59, 71, 160, 33, 68, 38, 114, 75, 142, 59, 38, 46, 54, 108, 49, 53, 105, 56, 90, 35, 87, 99, 54, 41, 92, 55, 26, 50, 35, 69, 40, 62, 76, 55, 46, 48, 63, 42, 72, 53, 38, 73, 35, 86, 152, 64, 111, 159, 63, 46, 52, 55, 74, 85, 143, 156, 154, 37, 99, 103, 102, 37, 53, 82, 53, 118, 41, 95, 91, 75, 69, 68, 88, 39, 73, 153, 64, 88, 166, 81, 101, 46, 119, 81, 53, 50, 40, 134, 118, 128, 42, 45, 92, 80, 88, 122, 60, 53, 92, 42, 85, 79, 39, 85, 160, 41, 52, 79, 105, 88, 54, 52, 76, 48, 93, 117, 53, 53, 58, 199, 36, 119, 134, 42, 132, 70, 66, 69, 39, 112, 93, 53, 37, 230, 67, 79, 66, 42, 63, 51, 54, 53, 55, 94, 60, 41, 68, 66, 73, 47, 66, 105, 83, 53, 50, 53, 50, 167, 41, 72, 70, 73, 60, 75, 88, 166, 76, 159, 58, 119, 86, 62, 45, 117, 53, 75, 53, 129, 53, 59, 74, 97, 66, 62, 50, 125, 36, 58, 166, 56, 44, 55, 148, 82, 85, 43, 82, 122, 71, 61, 103, 60, 100, 77, 95, 39, 37, 61, 68, 113, 118, 130, 109, 131, 74, 51, 52, 81, 46, 45, 53, 62, 44, 107, 86, 52, 107, 69, 71, 62, 53, 52, 28, 63, 42, 83, 45, 101, 47, 70, 41, 38, 52, 25, 27, 32, 35, 30, 35, 41, 50, 81, 35, 55, 60, 72, 67, 72, 79, 41, 124, 67, 55, 91, 30, 51, 63, 84, 45, 41, 38, 32, 70, 39, 50, 38, 23, 97, 28, 41, 33, 44, 42, 34, 21, 37, 26, 66, 36, 23, 67, 49, 84, 51, 39, 52, 35, 51, 25, 54, 47, 38, 101, 99, 68, 87, 42, 51, 52, 75, 47, 25, 35, 34, 30, 54, 34, 38, 49, 51, 50, 82, 53, 46, 42, 79, 62, 48, 35, 45, 64, 63, 56, 75, 95, 38, 34, 96, 88, 68, 51, 106, 82, 82, 47, 52, 61, 63, 59, 28, 25, 39, 37, 47, 36, 35, 21, 25, 40, 41, 167, 41, 165, 20, 107, 82, 80, 89, 31, 47, 44, 45, 92, 23, 68, 42, 101, 93, 41, 33, 43, 24, 30, 64, 30, 25, 21, 50, 89, 29, 60, 45, 44, 28, 75, 65, 41, 78, 81, 74, 30, 35, 56, 28, 42, 31, 56, 39, 91, 81, 104, 97, 104, 62, 82, 73, 64, 100, 115, 84, 132, 79, 64, 76, 52, 89, 103, 74, 52, 44, 33, 82, 79, 64, 97, 55, 84, 57, 136, 41, 74, 46, 56, 96, 62, 46, 40, 104, 78, 82, 110, 112, 105, 79, 40, 31, 79, 90, 41, 30, 39, 82, 65, 78, 51, 56, 35, 64, 42, 44, 30, 63, 42, 102, 23, 43, 37, 118, 55, 89, 45, 73, 60, 53, 55, 46, 80, 67, 65, 44, 37, 42, 85, 28, 23, 42, 26, 92, 76, 76, 86, 42, 101, 88, 103, 49, 46, 63, 67, 26, 46, 34, 36, 42, 35, 52, 40, 75, 29, 46, 36, 32, 43, 38, 17, 69, 37, 93, 49, 31, 27, 43, 21, 40, 33, 27, 46, 57, 23, 30, 60, 52, 46, 41, 24, 71, 86, 85, 85, 30, 29, 46, 37, 40, 34, 20, 83, 41, 54, 56, 112, 32, 112, 41, 39, 41, 78, 41, 53, 40, 90, 63, 50, 75, 96, 81, 87, 51, 33, 38, 60, 43, 25, 47, 80, 70, 76, 54, 125, 53, 34, 78, 38, 69, 49, 74, 97, 63, 75, 52, 35, 64, 84, 60, 74, 40, 59, 44, 83, 45, 38, 47, 103, 86, 100, 106, 68, 71, 60, 30, 33, 54, 43, 98, 32, 46, 96, 74, 50, 56, 41, 35, 41, 81, 85, 77, 61, 105, 80, 52, 73, 98, 86, 59, 51, 85, 70, 56, 63, 30, 57, 58, 45, 91, 119, 47, 68, 51, 83, 89, 56, 67, 66, 37, 76, 42, 76, 73, 38, 62, 46, 56, 65, 40, 46, 63, 75, 96, 37, 69, 111, 69, 78, 48, 68, 97, 69, 60, 71, 39, 31, 40, 49, 65, 38, 41, 59, 73, 30, 47, 30, 61, 40, 68, 78, 37, 42, 29, 32, 75, 49, 90, 57, 74, 80, 122, 68, 65, 53, 46, 38, 37, 46, 38, 46, 68, 80, 66, 46, 20, 19, 20, 24, 42, 35, 48, 26, 29, 26, 60, 58, 92, 42, 84, 68, 76, 122, 28, 43, 59, 42, 23, 37, 52, 95, 83, 51, 54, 93, 29, 25, 54, 35, 27, 54, 75, 40, 93, 32, 77, 57, 71, 62, 86, 40, 45, 62, 105, 90, 45, 68, 67, 56, 38, 63, 38, 91, 54, 94, 63, 74, 48, 38, 91, 84, 99, 57, 66, 57, 59, 56, 43, 87, 76, 80, 57, 98, 66, 75, 106, 47, 98, 76, 79, 51, 67, 72, 57, 56, 46, 51, 42, 54, 103, 81, 50, 78, 50, 78, 71, 71, 55, 50, 43, 35, 57, 71, 74, 50, 47, 122, 104, 120, 78, 38, 125, 98, 99, 74, 33, 47, 67, 32, 36, 27, 53, 158, 39, 129, 104, 81, 80, 64, 93, 110, 98, 84, 60, 89, 81, 114, 117, 66, 79, 86, 57, 102, 81, 58, 44, 90, 70, 88, 93, 77, 44, 126, 41, 79, 98, 92, 84, 55, 62, 41, 64, 50, 61, 84, 59, 60, 107, 94, 54, 68, 70, 69, 72, 76, 81, 96, 97, 85, 83, 91, 113, 99, 78, 66, 102, 94, 96, 101, 68, 99, 95, 92, 85, 107, 111, 132, 129, 82, 94, 62, 103, 87, 87, 83, 83, 85, 87, 52, 106, 107, 122, 112, 92, 99, 90, 98, 66, 72, 84, 95, 59, 71, 74, 74, 94, 101, 56, 51, 82, 107, 36, 112, 106, 77, 94, 85, 99, 72, 73, 92, 43, 104, 87, 77, 83, 98, 112, 102, 55, 99, 87, 48, 375, 87, 81, 93, 46, 86, 102, 94, 96, 98, 77, 107, 87, 68, 54, 84, 83, 67, 91, 74, 96, 73, 58, 102, 88, 84, 46, 88, 134, 74, 88, 75, 48, 103, 101, 46, 121, 106, 46, 42, 72, 62, 98, 88, 80, 99, 79, 95, 105, 89, 72, 114, 73, 82, 91, 92, 118, 101, 94, 80, 67, 76, 71, 61, 77, 54, 96, 78, 56, 67, 72, 77, 86, 98, 122, 86, 89, 71, 88, 79, 74, 59, 59, 99, 45, 105, 99, 76, 46, 105, 46, 120, 65, 91, 92, 87, 84, 75, 62, 62, 114, 60, 71, 82, 79, 98, 72, 65, 93, 92, 77, 64, 110, 81, 83, 59, 66, 45, 61, 60, 63, 83, 54, 68, 58, 83, 80, 111, 52, 66, 57, 65, 133, 81, 106, 67, 118, 124, 109, 112, 62, 113, 63, 64, 84, 77, 77, 69, 76, 94, 103, 78, 81, 98, 76, 46, 45, 61, 47, 69, 79, 92, 99, 86, 83, 79, 85, 79, 100, 98, 93, 75, 90, 77, 65, 45, 88, 90, 65, 114, 94, 88, 59, 64, 114, 59, 59, 64, 59, 108, 62, 72, 45, 94, 80, 57, 101, 78, 46, 90, 94, 66, 84, 112, 51, 114, 95, 71, 82, 122, 70, 68, 59, 59, 70, 64, 122, 53, 93, 92, 107, 80, 51, 120, 65, 94, 43, 61, 83, 74, 135, 101, 102, 97, 83, 70, 100, 59, 117, 98, 81, 141, 70, 95, 74, 112, 137, 87, 87, 107, 66, 90, 98, 60, 98, 55, 113, 71, 73, 61, 90, 120, 74, 103, 87, 99, 62, 67, 93, 64, 113, 115, 69, 67, 112, 90, 83, 73, 84, 84, 96, 110, 76, 96, 108, 73, 93, 94, 107, 99, 98, 68, 84, 63, 76, 72, 70, 72, 91, 45, 56, 69, 113, 96, 83, 85, 93, 60, 80, 71, 117, 39, 82, 73, 93, 94, 86, 74, 67, 117, 102, 86, 45, 55, 84, 101, 121, 97, 93, 72, 87, 75, 58, 83, 102, 96, 99, 123, 85, 91, 67, 98, 103, 78, 65, 72, 113, 92, 104, 109, 119, 77, 93, 84, 78, 93, 68, 92, 116, 98, 96, 68, 86, 65, 74, 68, 71, 94, 59, 95, 67, 76, 110, 67, 65, 88, 95, 121, 81, 108, 113, 86, 85, 89, 95, 102, 74, 66, 105, 104, 76, 73, 105, 99, 46, 45, 109, 170, 73, 72, 55, 93, 69, 30, 102, 74, 66, 84, 82, 97, 54, 77, 83, 79, 77, 111, 85, 86, 98, 79, 59, 99, 89, 98, 42, 77, 54, 89, 48, 48, 66, 86, 78, 37, 107, 129, 108, 88, 80, 52, 97, 59, 85, 67, 79, 91, 61, 67, 74, 47, 96, 71, 75, 71, 98, 99, 97, 63, 84, 106, 106, 101, 79, 83, 109, 77, 111, 135, 102, 114, 92, 72, 99, 48, 61, 50, 58, 45, 71, 77, 65, 120, 94, 66, 52, 96, 85, 79, 100, 107, 98, 60, 103, 82, 95, 112, 100, 80, 85, 88, 104, 111, 64, 62, 66, 88, 107, 78, 97, 95, 101, 106, 110, 88, 87, 103, 124, 83, 105, 63, 81, 89, 93, 98, 90, 232, 90, 91, 68, 97, 89, 72, 127, 90, 114, 70, 99, 95, 121, 110, 85, 64, 87, 97, 102, 90, 121, 71, 93, 74, 89, 87, 113, 59, 83, 65, 113, 103, 66, 104, 110, 104, 105, 85, 101, 104, 91, 115, 100, 98, 77, 104, 107, 88, 109, 108, 48, 69, 80, 105, 107, 109, 77, 90, 69, 66, 95, 80, 77, 78, 98, 87, 62, 80, 105, 66, 93, 120, 80, 58, 102, 79, 58, 83, 104, 135, 39, 90, 106, 126, 100, 70, 83, 65, 101, 61, 78, 71, 161, 61, 97, 69, 88, 58, 108, 61, 44, 69, 69, 110, 92, 80, 101, 69, 113, 88, 77, 108, 94, 46, 74, 69, 84, 86, 52, 77, 86, 86, 100, 77, 104, 89, 85, 50, 77, 93, 46, 68, 76, 87, 46, 94, 98, 82, 94, 62, 96, 63, 93, 44, 89, 110, 68, 117, 88, 73, 76, 65, 106, 53, 89, 88, 59, 99, 64, 46, 92, 66, 76, 62, 77, 83, 111, 102, 70, 83, 90, 100, 106, 113, 70, 69, 126, 94, 74, 114, 78, 112, 90, 96, 70, 88, 84, 85, 94, 61, 82, 89, 91, 74, 104, 88, 91, 87, 124, 51, 96, 112, 103, 54, 69, 96, 81, 66, 46, 52, 110, 78, 74, 61, 64, 61, 78, 86, 104, 69, 63, 43, 118, 74, 121, 60, 52, 99, 69, 89, 52, 79, 85, 113, 63, 66, 71, 87, 93, 104, 71, 72, 83, 95, 103, 97, 86, 93, 77, 84, 59, 46, 63, 99, 97, 85, 75, 85, 89, 60, 66, 97, 60, 49, 60, 76, 84, 104, 69, 70, 71, 78, 82, 80, 48, 98, 94, 69, 91, 65, 72, 82, 59, 69, 111, 103, 89, 68, 109, 48, 53, 103, 106, 82, 63, 90, 46, 44, 46, 38, 84, 87, 62, 125, 96, 70, 73, 49, 54, 48, 63, 106, 52, 83, 95, 109, 63, 97, 74, 73, 105, 69, 55, 86, 101, 63, 59, 100, 96, 85, 89, 87, 108, 57, 116, 133, 80, 80, 81, 55, 103, 74, 86, 67, 71, 68, 59, 113, 93, 81, 62, 88, 104, 43, 95, 88, 65, 104, 105, 80, 92, 114, 78, 119, 83, 97, 64, 114, 102, 73, 94, 85, 97, 89, 118, 82, 74, 68, 59, 81, 85, 71, 57, 71, 75, 63, 77, 94, 81, 55, 82, 59, 91, 84, 85, 74, 90, 74, 72, 77, 90, 62, 96, 71, 68, 73, 80, 80, 56, 119, 108, 107, 83, 101, 107, 114, 89, 110, 85, 76, 57, 92, 96, 99, 76, 72, 96, 59, 98, 121, 110, 64, 105, 101, 105, 125, 94, 58, 83, 71, 124, 96, 101, 62, 69, 58, 91, 77, 57, 115, 101, 67, 118, 70, 106, 82, 69, 60, 53, 54, 66, 110, 57, 77, 93, 79, 96, 79, 72, 85, 83, 76, 63, 65, 66, 70, 64, 126, 133, 67, 45, 57, 48, 61, 38, 70, 93, 105, 92, 80, 50, 92, 75, 105, 49, 57, 125, 118, 100, 89, 97, 95, 91, 71, 76, 59, 102, 99, 98, 102, 87, 106, 119, 85, 75, 99, 89, 116, 118, 91, 88, 69, 129, 100, 86, 77, 63, 96, 54, 96, 45, 46, 98, 93, 106, 116, 63, 50, 83, 71, 46, 63, 109, 62, 102, 72, 93, 69, 85, 96, 113, 118, 39, 75, 79, 40, 96, 90, 73, 86, 109, 122, 82, 87, 90, 116, 67, 122, 113, 135, 118, 48, 43, 65, 97, 101, 121, 97, 80, 108, 102, 91, 103, 114, 50, 88, 81, 71, 85, 76, 79, 76, 67, 71, 65, 67, 138, 85, 87, 76, 63, 76, 77, 93, 113, 50, 96, 85, 98, 120, 40, 75, 98, 72, 69, 83, 97, 45, 70, 59, 98, 77, 109, 102, 56, 84, 99, 97, 105, 97, 86, 112, 74, 100, 107, 87, 84, 71, 100, 54, 47, 45, 80, 79, 66, 44, 48, 107, 95, 105, 35, 46, 105, 51, 52, 79, 59, 97, 64, 62, 73, 39, 63, 72, 71, 92, 93, 46, 65, 81, 91, 77, 72, 44, 98, 59, 100, 105, 94, 90, 48, 85, 49, 97, 71, 44, 95, 90, 88, 75, 85, 112, 96, 113, 94, 126, 105, 64, 90, 113, 113, 92, 77, 70, 78, 78, 112, 88, 55, 68, 90, 89, 83, 116, 100, 67, 72, 84, 82, 79, 62, 95, 72, 68, 78, 69, 88, 99, 73, 64, 78, 110, 80, 89, 74, 98, 79, 87, 105, 73, 69, 65, 83, 46, 101, 144, 73, 90, 96, 96, 94, 97, 90, 73, 107, 102, 60, 59, 67, 63, 102, 85, 113, 76, 116, 87, 115, 101, 90, 102, 57, 77, 69, 90, 72, 83, 112, 87, 45, 59, 94, 51, 57, 49, 86, 85, 108, 150, 112, 93, 115, 102, 47, 50, 105, 76, 98, 91, 99, 76, 113, 90, 96, 115, 65, 102, 106, 66, 44, 106, 58, 91, 86, 110, 52, 93, 49, 60, 67, 97, 132, 112, 126, 110, 87, 124, 102, 106, 67, 59, 94, 84, 80, 72, 64, 118, 85, 55, 84, 76, 74, 97, 50, 126, 64, 63, 65, 84, 71, 67, 69, 91, 93, 72, 92, 88, 96, 84, 74, 98, 86, 54, 106, 102, 74, 101, 133, 87, 62, 72, 72, 62, 80, 46, 108, 84, 113, 43, 63, 58, 67, 103, 109, 61, 49, 103, 88, 116, 111, 82, 96, 130, 99, 108, 97, 81, 88, 67, 72, 67, 54, 58, 66, 77, 54, 53, 97, 83, 76, 112, 53, 45, 109, 80, 86, 82, 59, 59, 40, 59, 48, 57, 108, 121, 111, 99, 127, 64, 99, 137, 108, 59, 136, 59, 103, 86, 103, 48, 130, 60, 83, 55, 54, 50, 77, 94, 100, 83, 85, 82, 76, 77, 64, 97, 136, 124, 127, 110, 103, 64, 63, 67, 75, 77, 97, 80, 99, 97, 55, 52, 49, 120, 105, 61, 69, 80, 85, 58, 69, 58, 86, 40, 55, 94, 72, 46, 51, 74, 42, 98, 84, 96, 135, 94, 86, 86, 54, 72, 51, 97, 41, 99, 90, 82, 72, 122, 97, 91, 119, 96, 93, 94, 97, 63, 59, 46, 95, 52, 81, 63, 88, 90, 57, 55, 108, 109, 101, 89, 75, 73, 98, 59, 66, 67, 43, 72, 52, 84, 73, 125, 61, 106, 98, 128, 72, 89, 91, 70, 72, 57, 76, 53, 87, 56, 49, 66, 92, 60, 122, 61, 103, 94, 114, 87, 109, 125, 90, 104, 110, 92, 141, 62, 77, 63, 85, 119, 58, 71, 74, 59, 108, 93, 82, 108, 80, 106, 79, 63, 80, 115, 120, 90, 85, 69, 100, 85, 71, 55, 45, 105, 103, 65, 55, 82, 61, 96, 128, 46, 93, 72, 66, 81, 83, 72, 91, 70, 79, 55, 70, 94, 105, 113, 111, 83, 90, 73, 96, 108, 90, 77, 110, 115, 57, 65, 115, 40, 95, 113, 68, 58, 57, 71, 67, 76, 78, 68, 63, 98, 68, 53, 80, 85, 64, 68, 92, 93, 72, 73, 93, 76, 116, 81, 123, 75, 105, 125, 58, 69, 65, 88, 95, 72, 122, 90, 88, 99, 107, 105, 96, 85, 88, 63, 67, 84, 44, 102, 73, 70, 22, 86, 65, 99, 74, 101, 69, 84, 136, 69, 46, 61, 108, 92, 91, 104, 97, 54, 94, 112, 105, 92, 92, 86, 70, 66, 115, 122, 98, 117, 77, 99, 96, 66, 74, 122, 60, 79, 63, 89, 77, 115, 117, 119, 112, 72, 92, 96, 94, 93, 58, 112, 98, 96, 59, 73, 82, 69, 111, 40, 65, 97, 107, 61, 70, 95, 45, 55, 94, 65, 101, 100, 125, 108, 75, 104, 63, 84, 96, 94, 103, 79, 103, 92, 100, 68, 61, 96, 87, 75, 109, 93, 65, 121, 103, 127, 55, 93, 97, 82, 67, 87, 105, 79, 73, 61, 106, 61, 107, 74, 64, 48, 61, 72, 76, 67, 79, 86, 62, 83, 57, 58, 84, 122, 99, 73, 58, 107, 76, 74, 104, 57, 85, 40, 51, 30, 111, 52, 71, 111, 93, 80, 39, 59, 51, 91, 76, 43, 60, 114, 46, 45, 112, 98, 77, 44, 60, 74, 83, 56, 74, 59, 45, 84, 78, 37, 68, 65, 66, 99, 76, 77, 62, 80, 64, 61, 54, 69, 72, 49, 50, 140, 78, 45, 82, 49, 116, 140, 40, 84, 91, 66, 119, 97, 43, 42, 99, 83, 62, 54, 58, 157, 114, 61, 97, 40, 140, 43, 112, 90, 42, 65, 89, 152, 88, 28, 91, 114, 117, 38, 109, 62, 46, 66, 95, 45, 58, 40, 51, 46, 89, 74, 59, 66, 97, 70, 62, 49, 21, 115, 58, 38, 77, 89, 82, 90, 82, 50, 80, 76, 66, 58, 66, 63, 83, 92, 61, 78, 37, 113, 88, 86, 152, 50, 37, 59, 68, 56, 57, 68, 32, 67, 200, 113, 59, 94, 92, 73, 100, 84, 111, 89, 70, 74, 73, 97, 80, 46, 87, 81, 44, 94, 43, 96, 82, 110, 84, 98, 128, 136, 76, 73, 116, 36, 71, 79, 78, 75, 107, 123, 66, 107, 64, 103, 78, 90, 59, 102, 92, 62, 125, 48, 79, 101, 72, 124, 92, 113, 100, 79, 96, 79, 97, 106, 64, 98, 117, 129, 115, 50, 87, 104, 57, 100, 65, 66, 89, 70, 70, 93, 92, 74, 53, 41, 63, 93, 56, 90, 40, 55, 43, 105, 88, 108, 60, 57, 65, 118, 142, 49, 94, 108, 60, 61, 69, 70, 122, 202, 69, 57, 92, 98, 116, 90, 89, 99, 54, 41, 86, 67, 53, 81, 59, 73, 58, 92, 41, 78, 36, 119, 117, 134, 72, 115, 100, 95, 90, 104, 157, 122, 97, 74, 61, 89, 85, 75, 127, 99, 103, 102, 62, 85, 38, 62, 82, 70, 158, 41, 100, 58, 72, 65, 97, 70, 41, 69, 56, 72, 109, 50, 42, 97, 61, 43, 106, 103, 58, 83, 119, 41, 82, 94, 86, 75, 58, 43, 45, 106, 40, 65, 59, 79, 57, 108, 77, 69, 147, 65, 78, 135, 73, 154, 102, 38, 117, 98, 92, 73, 152, 94, 104, 20, 53, 43, 49, 43, 49, 30, 47, 75, 62, 44, 89, 19, 57, 38, 26, 30, 20, 51, 54, 32, 19, 48, 44, 49, 35, 40, 97, 32, 58, 73, 51, 46, 64, 29, 27, 55, 68, 36, 34, 54, 89, 67, 79, 32, 70, 84, 35, 37, 53, 46, 46, 25, 19, 23, 36, 43, 43, 27, 43, 28, 22, 37, 38, 33, 69, 59, 62, 25, 29, 48, 65, 31, 26, 48, 24, 26, 41, 50, 65, 35, 23, 51, 54, 72, 28, 54, 73, 80, 40, 106, 38, 36, 38, 48, 22, 27, 22, 34, 45, 24, 33, 25, 31, 19, 18, 39, 38, 98, 26, 20, 43, 26, 76, 33, 17, 54, 28, 36, 70, 41, 46, 20, 81, 29, 27, 32, 34, 100, 139, 93, 35, 28, 64, 42, 63, 51, 54, 115, 67, 56, 40, 46, 82, 79, 40, 73, 89, 47, 33, 37, 48, 28, 42, 35, 49, 37, 40, 37, 91, 23, 50, 67, 48, 34, 46, 102, 36, 108, 102, 54, 57, 43, 79, 43, 76, 43, 50, 43, 89, 41, 99, 64, 44, 26, 43, 50, 31, 28, 34, 33, 25, 28, 46, 42, 71, 93, 35, 29, 39, 34, 40, 49, 100, 92, 113, 67, 48, 54, 64, 72, 56, 43, 56, 43, 41, 43, 34, 43, 45, 43, 84, 28, 73, 50, 56, 43, 58, 46, 89, 105, 61, 83, 40, 41, 67, 57, 57, 57, 25, 94, 41, 44, 78, 51, 90, 78, 51, 45, 68, 42, 71, 65, 25, 80, 32, 82, 44, 122, 73, 70, 49, 43, 45, 43, 59, 32, 40, 21, 70, 55, 49, 48, 57, 69, 48, 49, 97, 73, 55, 51, 85, 33, 29, 35, 43, 66, 63, 26, 35, 45, 37, 59, 81, 49, 84, 59, 60, 37, 72, 39, 34, 84, 83, 60, 85, 50, 48, 41, 79, 40, 44, 25, 24, 68, 26, 25, 23, 23, 26, 18, 34, 46, 35, 29, 27, 50, 36, 39, 37, 32, 36, 21, 37, 43, 42, 36, 96, 100, 47, 79, 66, 18, 66, 45, 78, 47, 82, 51, 34, 75, 43, 37, 43, 32, 99, 31, 55, 25, 50, 26, 33, 45, 39, 52, 59, 67, 39, 71, 41, 25, 83, 43, 29, 79, 54, 137, 72, 140, 71, 94, 70, 46, 47, 41, 55, 107, 19, 89, 83, 29, 58, 46, 31, 105, 92, 36, 70, 88, 69, 59, 90, 46, 27, 53, 47, 63, 140, 98, 16, 22, 74, 28, 31, 45, 25, 32, 46, 26, 95, 76, 88, 29, 67, 48, 43, 62, 60, 41, 53, 41, 53, 41, 23, 31, 36, 25, 32, 82, 43, 40, 32, 29, 35, 59, 37, 45, 45, 99, 87, 37, 53, 49, 92, 47, 74, 54, 73, 89, 100, 67, 62, 44, 82, 60, 90, 71, 50, 32, 128, 125, 75, 43, 49, 43, 39, 43, 40, 102, 33, 90, 35, 43, 35, 43, 80, 98, 73, 50, 102, 73, 85, 56, 71, 59, 26, 29, 20, 36, 45, 49, 36, 68, 87, 59, 70, 68, 112, 93, 96, 35, 72, 46, 50, 28, 60, 98, 27, 56, 73, 83, 57, 78, 59, 48, 62, 52, 56, 78, 65, 50, 85, 43, 67, 43, 39, 43, 40, 52, 90, 52, 49, 50, 41, 50, 65, 90, 61, 88, 45, 92, 26, 86, 66, 66, 29, 58, 87, 32, 37, 136, 50, 24, 61, 41, 69, 42, 41, 42, 110, 48, 81, 24, 23, 36, 41, 48, 97, 85, 116, 35, 31, 43, 64, 43, 40, 43, 61, 43, 37, 50, 54, 44, 94, 155, 60, 103, 58, 79, 56, 61, 49, 31, 61, 62, 62, 50, 84, 81, 53, 85, 68, 40, 43, 56, 26, 29, 37, 33, 84, 99, 29, 39, 21, 100, 50, 50, 70, 105, 76, 76, 88, 42, 45, 61, 45, 46, 80, 60, 40, 77, 52, 32, 42, 54, 109, 127, 54, 99, 81, 78, 114, 66, 59, 81, 89, 55, 120, 70, 45, 72, 112, 65, 88, 57, 39, 29, 49, 79, 27, 44, 27, 29, 44, 65, 47, 24, 31, 47, 95, 82, 32, 41, 96, 47, 35, 45, 61, 70, 69, 86, 44, 96, 62, 93, 19, 95, 55, 91, 73, 69, 17, 37, 39, 22, 47, 49, 49, 32, 56, 48, 102, 54, 93, 76, 98, 103, 38, 123, 71, 108, 50, 45, 48, 103, 60, 54, 95, 54, 50, 66, 69, 43, 41, 22, 62, 80, 103, 62, 47, 73, 168, 39, 52, 64, 29, 37, 35, 34, 49, 43, 107, 75, 56, 49, 32, 105, 55, 112, 41, 75, 45, 43, 51, 43, 48, 88, 65, 104, 79, 81, 77, 59, 62, 40, 30, 83, 80, 99, 81, 82, 52, 29, 67, 48, 43, 60, 62, 41, 53, 41, 53, 74, 38, 52, 65, 42, 52, 95, 81, 80, 69, 67, 27, 54, 49, 91, 46, 55, 47, 95, 56, 52, 46, 51, 25, 27, 47, 40, 37, 39, 111, 41, 70, 99, 27, 29, 56, 57, 67, 48, 77, 43, 48, 43, 23, 43, 40, 54, 22, 104, 34, 43, 102, 43, 102, 43, 91, 43, 41, 52, 43, 65, 43, 66, 102, 102, 116, 66, 105, 104, 60, 94, 98, 100, 72, 73, 87, 68, 76, 82, 64, 56, 79, 72, 104, 67, 52, 83, 55, 98, 84, 16, 27, 22, 29, 98, 28, 45, 59, 97, 84, 56, 75, 59, 58, 65, 61, 78, 61, 69, 60, 43, 56, 43, 95, 43, 81, 43, 84, 72, 71, 64, 34, 75, 73, 77, 56, 86, 156, 85, 75, 42, 52, 98, 87, 43, 51, 81, 65, 147, 59, 71, 96, 57, 93, 97, 49, 108, 73, 58, 80, 34, 84, 35, 45, 49, 63, 63, 63, 34, 52, 43, 49, 43, 86, 43, 85, 102, 112, 105, 80, 41, 27, 33, 56, 83, 56, 52, 87, 72, 73, 85, 33, 75, 85, 79, 50, 61, 64, 91, 80, 30, 90, 126, 97, 50, 30, 62, 42, 63, 78, 34, 94, 63, 53, 50, 22, 48, 53, 31, 35, 23, 45, 37, 43, 29, 50, 33, 53, 80, 49, 94, 66, 100, 68, 38, 102, 110, 71, 73, 37, 56, 76, 78, 29, 50, 94, 31, 97, 51, 110, 43, 74, 119, 65, 63, 44, 49, 64, 56, 68, 72, 56, 70, 96, 69, 28, 69, 70, 103, 54, 56, 84, 38, 68, 24, 100, 83, 72, 49, 68, 41, 35, 104, 91, 61, 79, 127, 45, 95, 99, 91, 59, 71, 79, 59, 50, 74, 83, 62, 77, 83, 120, 46, 50, 61, 72, 41, 75, 79, 67, 66, 40, 64, 58, 88, 72, 76, 67, 37, 87, 96, 62, 93, 28, 69, 91, 47, 28, 47, 27, 64, 98, 48, 65, 96, 112, 78, 74, 107, 110, 40, 62, 30, 33, 70, 43, 26, 35, 53, 31, 50, 59, 37, 72, 60, 27, 85, 35, 98, 20, 61, 59, 43, 56, 100, 72, 44, 30, 49, 66, 43, 95, 43, 81, 43, 66, 90, 97, 90, 74, 90, 87, 97, 47, 41, 74, 63, 53, 73, 61, 43, 45, 83, 95, 46, 83, 59, 52, 68, 51, 40, 30, 76, 31, 84, 19, 24, 146, 26, 80, 47, 32, 72, 118, 96, 117, 58, 81, 71, 77, 58, 74, 81, 176, 95, 43, 53, 86, 73, 123, 68, 94, 61, 82, 80, 98, 64, 57, 67, 65, 62, 49, 104, 33, 85, 50, 85, 47, 62, 58, 95, 81, 53, 47, 60, 19, 34, 36, 63, 61, 54, 67, 66, 72, 222, 81, 90, 74, 106, 54, 43, 87, 43, 57, 43, 80, 43, 48, 47, 51, 42, 41, 62, 50, 45, 106, 81, 24, 34, 50, 54, 102, 87, 67, 89, 94, 58, 52, 51, 89, 82, 68, 84, 73, 110, 84, 139, 116, 131, 80, 38, 36, 41, 27, 95, 33, 106, 56, 63, 79, 96, 79, 81, 88, 27, 87, 86, 31, 25, 160, 68, 47, 71, 58, 54, 102, 66, 77, 43, 84, 54, 43, 70, 52, 60, 41, 53, 41, 63, 30, 40, 57, 34, 93, 52, 70, 21, 100, 114, 65, 103, 86, 65, 94, 75, 75, 139, 86, 46, 83, 60, 69, 91, 24, 85, 67, 21, 62, 16, 53, 85, 50, 66, 102, 56, 64, 86, 56, 47, 50, 56, 48, 110, 42, 43, 70, 31, 56, 83, 53, 92, 52, 50, 57, 61, 83, 83, 77, 84, 76, 94, 77, 68, 58, 108, 88, 92, 91, 52, 72, 43, 56, 43, 73, 43, 67, 83, 86, 130, 98, 65, 42, 73, 35, 43, 34, 51, 52, 72, 184, 30, 56, 36, 66, 47, 31, 48, 45, 119, 51, 88, 88, 94, 70, 108, 51, 51, 116, 99, 58, 92, 17, 76, 68, 110, 59, 77, 68, 91, 46, 43, 41, 43, 89, 43, 53, 43, 75, 43, 53, 49, 69, 95, 59, 99, 75, 53, 87, 102, 114, 98, 65, 97, 60, 61, 81, 98, 69, 84, 79, 91, 60, 132, 85, 37, 92, 83, 75, 58, 46, 35, 49, 65, 103, 55, 99, 74, 86, 36, 82, 69, 40, 131, 60, 106, 110, 87, 43, 87, 46, 93, 96, 69, 71, 132, 73, 105, 109, 53, 63, 65, 65, 83, 72, 95, 60, 72, 104, 92, 49, 75, 63, 54, 100, 106, 70, 68, 111, 142, 42, 49, 32, 79, 45, 103, 77, 34, 22, 78, 96, 59, 59, 112, 81, 86, 77, 79, 89, 66, 53, 47, 101, 59, 38, 73, 50, 86, 74, 50, 81, 58, 57, 60, 60, 104, 46, 58, 129, 100, 85, 37, 64, 62, 42, 80, 52, 65, 100, 41, 51, 93, 24, 69, 80, 81, 84, 42, 88, 53, 55, 120, 85, 91, 108, 61, 53, 81, 79, 116, 81, 71, 53, 58, 66, 69, 179, 80, 70, 50, 43, 71, 46, 49, 36, 42, 51, 56, 35, 92, 54, 86, 68, 90, 101, 38, 87, 115, 98, 78, 84, 67, 95, 103, 63, 79, 106, 57, 91, 81, 84, 69, 83, 65, 85, 104, 99, 83, 45, 57, 53, 40, 80, 46, 91, 68, 118, 22, 56, 89, 57, 99, 80, 69, 118, 66, 59, 111, 47, 111, 100, 59, 74, 83, 71, 100, 46, 64, 98, 101, 79, 73, 115, 52, 74, 53, 78, 82, 71, 106, 94, 119, 101, 87, 87, 78, 77, 77, 54, 65, 80, 68, 69, 56, 88, 52, 82, 92, 85, 62, 46, 90, 93, 104, 98, 57, 50, 58, 90, 82, 46, 101, 54, 93, 82, 70, 75, 87, 65, 82, 74, 109, 60, 59, 59, 78, 62, 46, 101, 54, 64, 92, 95, 124, 102, 89, 87, 78, 99, 52, 68, 57, 57, 125, 94, 80, 98, 102, 88, 68, 83, 69, 68, 79, 117, 105, 77, 76, 92, 136, 89, 69, 77, 84, 65, 46, 99, 89, 68, 61, 53, 77, 46, 53, 46, 95, 85, 96, 67, 117, 104, 83, 122, 91, 37, 106, 105, 63, 38, 106, 95, 53, 122, 105, 78, 50, 98, 96, 46, 49, 46, 94, 95, 139, 63, 56, 100, 93, 77, 80, 109, 69, 57, 94, 101, 61, 69, 73, 108, 76, 96, 70, 80, 70, 81, 98, 106, 136, 77, 120, 72, 82, 92, 80, 67, 110, 64, 59, 78, 62, 97, 100, 122, 121, 116, 131, 83, 78, 57, 79, 59, 68, 60, 107, 76, 62, 129, 99, 102, 71, 102, 72, 87, 57, 83, 76, 83, 79, 46, 46, 67, 58, 123, 106, 146, 93, 98, 62, 93, 105, 62, 54, 72, 69, 76, 43, 93, 79, 45, 109, 57, 50, 98, 80, 79, 61, 69, 38, 68, 99, 77, 79, 103, 45, 67, 51, 88, 98, 92, 99, 72, 46, 78, 57, 87, 58, 69, 57, 77, 80, 82, 95, 70, 79, 99, 123, 79, 73, 87, 63, 75, 115, 47, 86, 57, 80, 85, 48, 68, 107, 69, 73, 79, 100, 116, 100, 81, 99, 83, 75, 60, 103, 67, 105, 117, 66, 42, 73, 85, 39, 80, 62, 64, 80, 76, 78, 101, 62, 93, 105, 46, 98, 78, 88, 49, 94, 52, 71, 74, 70, 92, 69, 60, 72, 68, 60, 110, 81, 69, 71, 105, 82, 69, 74, 88, 73, 60, 66, 69, 108, 45, 106, 56, 107, 101, 65, 101, 73, 71, 100, 99, 75, 76, 104, 65, 76, 98, 65, 69, 64, 112, 46, 82, 59, 66, 63, 95, 107, 87, 103, 121, 66, 63, 94, 46, 96, 60, 84, 72, 58, 106, 82, 78, 71, 94, 86, 106, 99, 87, 90, 87, 94, 92, 75, 103, 115, 74, 91, 129, 59, 90, 61, 54, 98, 59, 54, 54, 61, 69, 50, 45, 105, 89, 129, 76, 108, 97, 101, 53, 54, 77, 56, 68, 53, 82, 57, 56, 62, 135, 51, 128, 55, 67, 61, 77, 56, 62, 76, 64, 48, 84, 53, 103, 85, 65, 57, 51, 74, 103, 108, 86, 106, 116, 61, 68, 66, 100, 58, 51, 64, 77, 56, 64, 45, 68, 49, 76, 53, 78, 94, 46, 46, 57, 51, 98, 110, 46, 107, 94, 102, 92, 97, 82, 87, 69, 80, 109, 65, 69, 96, 86, 77, 86, 85, 94, 49, 110, 135, 93, 85, 81, 104, 98, 93, 67, 82, 84, 60, 69, 86, 121, 130, 90, 86, 69, 68, 118, 91, 69, 36, 83, 91, 46, 98, 83, 86, 57, 90, 59, 101, 54, 137, 61, 88, 56, 54, 88, 55, 104, 101, 100, 50, 39, 90, 83, 87, 79, 82, 121, 62, 103, 96, 115, 94, 68, 78, 90, 71, 91, 62, 113, 65, 62, 89, 60, 75, 63, 74, 63, 76, 75, 58, 66, 77, 68, 56, 85, 102, 71, 66, 35, 71, 118, 101, 84, 74, 56, 63, 88, 91, 61, 94, 81, 107, 85, 49, 58, 78, 65, 61, 98, 101, 114, 98, 83, 87, 95, 108, 217, 96, 85, 93, 38, 50, 105, 71, 71, 101, 46, 100, 94, 69, 75, 57, 59, 71, 69, 78, 122, 36, 74, 115, 121, 62, 57, 80, 57, 116, 123, 87, 78, 67, 81, 99, 66, 126, 69, 80, 81, 48, 60, 36, 90, 72, 102, 46, 128, 80, 76, 46, 92, 98, 42, 73, 115, 71, 53, 106, 82, 74, 65, 105, 78, 59, 67, 83, 46, 99, 99, 78, 85, 75, 78, 65, 78, 69, 71, 88, 84, 72, 44, 72, 106, 76, 75, 52, 49, 102, 56, 46, 86, 92, 99, 76, 71, 79, 68, 82, 100, 135, 101, 108, 110, 80, 55, 43, 66, 56, 69, 90, 51, 46, 42, 97, 90, 70, 94, 73, 146, 89, 96, 102, 127, 71, 82, 69, 103, 69, 79, 72, 76, 90, 78, 90, 87, 54, 94, 97, 68, 60, 78, 96, 46, 142, 96, 112, 111, 96, 115, 97, 103, 58, 42, 73, 78, 108, 90, 82, 75, 76, 84, 107, 88, 81, 112, 53, 111, 39, 89, 59, 112, 103, 103, 75, 79, 84, 80, 60, 84, 90, 80, 71, 83, 57, 94, 69, 53, 99, 71, 91, 63, 102, 98, 75, 81, 42, 93, 32, 54, 78, 70, 82, 67, 82, 111, 38, 85, 98, 70, 125, 96, 51, 97, 71, 64, 83, 93, 90, 94, 90, 98, 80, 64, 103, 113, 104, 94, 88, 80, 64, 91, 67, 46, 89, 67, 73, 72, 118, 90, 63, 73, 70, 97, 71, 69, 83, 80, 105, 46, 79, 54, 66, 102, 71, 68, 50, 39, 53, 137, 43, 91, 91, 130, 76, 98, 91, 59, 77, 77, 62, 79, 60, 85, 69, 92, 68, 92, 71, 110, 101, 123, 89, 97, 67, 62, 62, 38, 54, 65, 53, 57, 38, 86, 81, 64, 94, 53, 70, 77, 71, 69, 109, 78, 71, 57, 66, 96, 62, 106, 69, 128, 68, 62, 138, 110, 122, 48, 94, 102, 103, 87, 80, 67, 119, 99, 91, 73, 538, 99, 50, 67, 72, 65, 69, 56, 106, 42, 77, 77, 48, 63, 87, 45, 94, 106, 89, 76, 99, 69, 82, 103, 106, 77, 70, 80, 103, 148, 81, 80, 70, 75, 89, 68, 89, 56, 42, 76, 70, 40, 73, 106, 121, 117, 73, 73, 81, 77, 94, 103, 73, 596, 96, 69, 71, 97, 59, 42, 80, 40, 101, 65, 72, 87, 49, 98, 81, 75, 71, 45, 74, 96, 101, 101, 104, 104, 103, 104, 98, 48, 99, 56, 120, 56, 56, 46, 97, 62, 46, 120, 131, 98, 90, 92, 88, 82, 108, 66, 93, 111, 116, 101, 73, 96, 68, 99, 105, 81, 82, 78, 75, 117, 110, 92, 69, 73, 66, 103, 71, 89, 40, 83, 79, 70, 82, 57, 89, 87, 93, 43, 48, 94, 53, 101, 52, 57, 44, 57, 99, 49, 60, 65, 70, 79, 57, 67, 96, 114, 78, 68, 87, 63, 108, 75, 95, 59, 98, 99, 111, 43, 100, 96, 90, 92, 90, 61, 89, 44, 74, 82, 57, 125, 55, 98, 98, 84, 75, 85, 98, 96, 51, 57, 109, 75, 80, 40, 48, 82, 87, 131, 50, 48, 82, 46, 95, 61, 84, 87, 68, 91, 79, 72, 68, 86, 69, 76, 58, 109, 86, 67, 62, 66, 77, 93, 108, 100, 97, 81, 87, 77, 105, 92, 124, 78, 53, 73, 69, 109, 94, 116, 102, 70, 46, 89, 69, 66, 128, 64, 70, 86, 66, 76, 67, 101, 69, 69, 80, 100, 99, 94, 92, 81, 94, 81, 103, 111, 69, 62, 44, 120, 90, 69, 68, 80, 73, 82, 119, 65, 109, 102, 88, 69, 94, 64, 86, 96, 96, 88, 60, 85, 87, 82, 68, 99, 61, 106, 81, 43, 106, 57, 49, 93, 106, 54, 107, 93, 91, 140, 107, 81, 46, 87, 102, 68, 79, 88, 88, 100, 107, 69, 85, 121, 109, 92, 108, 69, 106, 101, 92, 93, 102, 56, 48, 104, 69, 121, 99, 89, 107, 75, 111, 96, 80, 44, 84, 22, 78, 103, 93, 82, 72, 69, 72, 23, 97, 59, 67, 89, 45, 70, 108, 56, 42, 49, 42, 84, 45, 74, 38, 98, 93, 44, 78, 50, 84, 59, 58, 84, 108, 96, 91, 66, 66, 56, 69, 62, 76, 77, 126, 79, 87, 95, 94, 97, 76, 69, 68, 77, 56, 60, 48, 94, 90, 100, 69, 86, 53, 51, 112, 73, 55, 78, 89, 112, 112, 125, 44, 74, 68, 110, 57, 98, 47, 83, 49, 80, 73, 70, 96, 74, 92, 65, 101, 82, 74, 112, 74, 48, 79, 89, 98, 69, 75, 64, 86, 77, 91, 95, 60, 101, 93, 80, 80, 97, 70, 72, 57, 101, 72, 82, 45, 73, 129, 77, 67, 79, 74, 86, 100, 59, 83, 76, 89, 99, 69, 112, 62, 112, 66, 122, 102, 99, 88, 145, 156, 118, 62, 51, 52, 70, 69, 91, 34, 41, 73, 69, 106, 83, 84, 96, 57, 71, 93, 85, 69, 59, 45, 84, 68, 56, 86, 128, 99, 108, 69, 89, 48, 92, 120, 73, 82, 71, 127, 89, 69, 90, 66, 103, 71, 73, 88, 89, 100, 108, 69, 75, 77, 57, 107, 98, 124, 124, 72, 84, 93, 68, 83, 92, 83, 76, 85, 77, 77, 97, 86, 57, 64, 71, 92, 82, 119, 87, 93, 116, 81, 69, 99, 60, 79, 72, 93, 60, 72, 80, 63, 84, 90, 97, 69, 72, 91, 68, 60, 127, 101, 85, 69, 65, 65, 101, 75, 66, 115, 77, 76, 48, 92, 111, 67, 75, 65, 79, 62, 89, 69, 65, 89, 72, 67, 62, 86, 74, 74, 67, 87, 59, 93, 103, 95, 71, 66, 102, 116, 77, 94, 69, 96, 77, 117, 84, 77, 73, 109, 81, 115, 86, 75, 99, 87, 46, 45, 64, 69, 69, 99, 92, 102, 60, 57, 78, 71, 69, 81, 92, 82, 70, 106, 106, 53, 100, 89, 76, 116, 71, 103, 81, 61, 82, 89, 78, 79, 79, 77, 97, 106, 48, 90, 79, 88, 94, 65, 85, 75, 97, 85, 121, 80, 74, 78, 60, 109, 94, 68, 97, 85, 99, 96, 91, 99, 71, 87, 78, 90, 100, 59, 85, 84, 65, 95, 90, 72, 80, 69, 86, 89, 68, 91, 82, 74, 125, 85, 71, 49, 77, 92, 79, 84, 74, 93, 72, 80, 70, 97, 85, 67, 60, 82, 75, 53, 96, 62, 66, 75, 60, 125, 77, 88, 74, 108, 71, 91, 77, 95, 96, 104, 72, 106, 61, 95, 64, 105, 50, 97, 84, 91, 82, 90, 69, 71, 97, 66, 93, 81, 97, 65, 119, 58, 71, 76, 112, 50, 58, 58, 59, 76, 105, 58, 69, 85, 74, 88, 91, 66, 95, 97, 62, 63, 91, 106, 77, 85, 85, 110, 81, 61, 72, 70, 91, 66, 93, 62, 72, 74, 68, 97, 40, 64, 48, 61, 77, 54, 101, 81, 71, 91, 78, 81, 86, 82, 108, 76, 87, 95, 99, 96, 62, 74, 78, 101, 72, 112, 96, 46, 124, 96, 82, 112, 112, 77, 87, 63, 66, 85, 81, 94, 50, 121, 88, 78, 104, 83, 103, 56, 50, 76, 72, 82, 72, 71, 101, 92, 81, 74, 84, 81, 79, 97, 101, 82, 66, 81, 95, 68, 55, 102, 90, 94, 104, 107, 91, 56, 104, 108, 88, 66, 49, 93, 54, 52, 99, 110, 91, 67, 70, 47, 74, 72, 98, 61, 65, 58, 80, 113, 66, 104, 91, 103, 105, 76, 67, 78, 86, 80, 92, 73, 64, 80, 86, 71, 69, 95, 80, 64, 87, 96, 90, 48, 46, 68, 94, 46, 82, 72, 46, 106, 113, 69, 77, 94, 86, 77, 78, 89, 57, 46, 83, 81, 80, 63, 135, 84, 45, 95, 46, 63, 69, 85, 98, 69, 88, 62, 62, 86, 86, 96, 81, 78, 99, 96, 80, 75, 79, 95, 87, 56, 45, 57, 58, 69, 61, 82, 75, 49, 123, 119, 45, 151, 42, 41, 68, 85, 48, 79, 36, 76, 63, 48, 48, 98, 45, 65, 55, 66, 79, 68, 63, 58, 60, 85, 62, 54, 50, 79, 55, 67, 71, 47, 60, 41, 94, 38, 66, 53, 54, 88, 110, 50, 71, 48, 64, 25, 42, 56, 82, 76, 54, 76, 72, 72, 82, 44, 61, 67, 78, 56, 57, 61, 45, 36, 55, 59, 59, 59, 48, 41, 65, 56, 57, 28, 52, 64, 36, 48, 51, 99, 41, 50, 41, 74, 65, 53, 103, 84, 87, 36, 78, 63, 67, 48, 64, 109, 89, 49, 63, 45, 68, 74, 39, 55, 47, 32, 48, 42, 79, 82, 72, 188, 41, 50, 74, 50, 73, 71, 92, 58, 82, 78, 49, 78, 30, 57, 66, 86, 58, 46, 62, 108, 97, 36, 55, 64, 55, 88, 33, 25, 41, 55, 95, 24, 53, 51, 29, 39, 49, 44, 54, 87, 46, 53, 85, 53, 41, 87, 41, 45, 48, 66, 43, 61, 35, 54, 23, 36, 44, 87, 53, 43, 53, 62, 64, 57, 41, 53, 86, 68, 104, 117, 53, 41, 56, 52, 104, 115, 76, 58, 104, 85, 64, 75, 64, 99, 89, 62, 50, 54, 45, 52, 71, 70, 52, 40, 36, 62, 98, 77, 68, 47, 56, 67, 64, 79, 64, 47, 69, 61, 57, 56, 35, 77, 80, 49, 63, 56, 84, 85, 83, 68, 65, 68, 65, 51, 103, 71, 32, 32, 33, 41, 108, 84, 101, 48, 35, 116, 59, 69, 33, 60, 80, 76, 60, 41, 61, 125, 89, 56, 64, 81, 50, 87, 85, 76, 89, 62, 94, 55, 65, 59, 65, 73, 62, 96, 87, 69, 66, 75, 35, 38, 42, 59, 41, 118, 41, 88, 59, 63, 74, 68, 66, 65, 60, 49, 65, 75, 68, 64, 63, 53, 72, 73, 88, 61, 106, 65, 48, 73, 64, 90, 70, 52, 64, 45, 84, 67, 60, 33, 57, 96, 112, 35, 46, 24, 41, 63, 55, 76, 62, 59, 51, 43, 46, 64, 76, 74, 55, 72, 74, 38, 51, 56, 64, 29, 76, 102, 89, 46, 37, 51, 32, 41, 72, 68, 54, 86, 86, 23, 70, 29, 74, 41, 49, 67, 68, 55, 73, 35, 55, 66, 63, 69, 48, 50, 104, 66, 56, 73, 95, 89, 54, 69, 69, 73, 55, 70, 62, 56, 61, 67, 72, 68, 53, 44, 71, 47, 57, 71, 85, 75, 61, 58, 71, 87, 61, 38, 61, 78, 97, 83, 60, 62, 63, 84, 58, 29, 42, 63, 68, 57, 67, 85, 60, 35, 69, 55, 77, 100, 79, 72, 53, 71, 55, 55, 69, 69, 50, 86, 55, 70, 87, 76, 63, 93, 82, 96, 56, 57, 115, 73, 73, 108, 65, 76, 94, 93, 48, 49, 80, 47, 72, 55, 49, 43, 74, 72, 53, 92, 61, 42, 68, 66, 66, 52, 51, 58, 68, 64, 88, 41, 65, 68, 46, 60, 80, 58, 85, 49, 72, 84, 66, 55, 53, 61, 57, 51, 50, 53, 80, 51, 108, 49, 45, 57, 99, 53, 49, 62, 59, 57, 77, 88, 78, 94, 75, 121, 64, 50, 64, 60, 98, 57, 108, 41, 67, 49, 91, 44, 49, 47, 72, 54, 41, 77, 45, 51, 71, 64, 76, 48, 44, 80, 46, 57, 113, 77, 102, 52, 83, 63, 45, 67, 44, 52, 50, 47, 56, 49, 50, 57, 47, 77, 71, 82, 72, 54, 53, 99, 58, 66, 49, 85, 85, 73, 90, 83, 64, 63, 59, 65, 47, 97, 60, 109, 61, 97, 80, 58, 76, 50, 70, 66, 57, 77, 55, 91, 53, 66, 56, 77, 61, 58, 89, 56, 66, 64, 63, 51, 69, 43, 63, 39, 90, 65, 67, 72, 58, 67, 76, 64, 67, 73, 72, 86, 61, 53, 63, 65, 64, 59, 62, 43, 55, 31, 84, 48, 66, 60, 53, 82, 41, 58, 41, 71, 41, 95, 41, 82, 79, 75, 26, 42, 56, 19, 85, 108, 66, 73, 54, 48, 58, 55, 57, 64, 72, 51, 55, 75, 65, 54, 62, 59, 39, 66, 47, 37, 41, 59, 71, 92, 77, 61, 56, 55, 55, 85, 69, 73, 49, 71, 51, 49, 47, 47, 30, 60, 91, 64, 64, 80, 53, 64, 78, 61, 70, 64, 65, 33, 54, 127, 41, 48, 43, 68, 73, 77, 34, 40, 57, 54, 49, 50, 24, 45, 85, 63, 59, 47, 84, 56, 41, 51, 92, 40, 54, 41, 41, 69, 75, 96, 118, 97, 54, 65, 56, 84, 78, 82, 76, 74, 103, 72, 41, 68, 31, 87, 83, 48, 84, 98, 48, 121, 57, 141, 58, 110, 96, 55, 52, 69, 99, 51, 45, 46, 72, 70, 72, 55, 85, 84, 111, 104, 121, 72, 58, 96, 108, 57, 63, 52, 49, 37, 64, 54, 94, 46, 65, 48, 75, 78, 99, 64, 78, 79, 62, 87, 32, 73, 70, 61, 65, 72, 61, 69, 77, 57, 87, 80, 73, 69, 65, 94, 85, 76, 78, 57, 57, 64, 42, 40, 61, 59, 46, 70, 66, 27, 78, 32, 62, 66, 46, 58, 62, 42, 40, 65, 56, 50, 70, 60, 52, 54, 56, 44, 73, 94, 66, 27, 58, 47, 78, 56, 56, 72, 64, 83, 38, 85, 57, 98, 61, 59, 84, 75, 64, 48, 72, 58, 78, 80, 65, 117, 104, 57, 80, 53, 56, 55, 45, 68, 65, 64, 86, 65, 72, 72, 77, 81, 63, 51, 84, 62, 80, 82, 70, 44, 57, 94, 63, 19, 74, 71, 66, 76, 76, 50, 34, 128, 57, 66, 43, 78, 72, 49, 83, 64, 45, 50, 44, 65, 50, 52, 67, 38, 48, 41, 43, 49, 46, 76, 41, 48, 103, 49, 84, 53, 90, 106, 60, 56, 65, 68, 61, 58, 67, 88, 66, 74, 68, 87, 53, 51, 75, 164, 70, 57, 83, 50, 65, 75, 80, 93, 42, 128, 55, 43, 59, 53, 59, 47, 69, 41, 44, 46, 127, 83, 62, 59, 54, 72, 54, 63, 61, 47, 68, 62, 58, 81, 89, 49, 62, 92, 53, 41, 78, 80, 90, 73, 61, 76, 59, 84, 77, 41, 86, 52, 48, 59, 58, 73, 96, 147, 79, 85, 70, 88, 41, 68, 78, 66, 63, 69, 105, 73, 65, 52, 199, 50, 50, 77, 63, 57, 66, 93, 80, 76, 43, 55, 78, 46, 72, 63, 106, 47, 63, 49, 90, 48, 88, 70, 58, 45, 84, 53, 51, 92, 93, 65, 55, 66, 53, 57, 54, 95, 53, 73, 56, 39, 33, 43, 59, 28, 30, 27, 34, 44, 43, 71, 117, 53, 97, 66, 24, 41, 47, 64, 72, 64, 46, 73, 94, 65, 60, 66, 60, 81, 60, 33, 60, 65, 72, 60, 62, 37, 61, 115, 28, 73, 52, 59, 55, 66, 51, 108, 57, 56, 64, 66, 90, 120, 96, 57, 83, 94, 42, 48, 58, 81, 104, 72, 71, 101, 78, 80, 110, 73, 81, 66, 59, 55, 61, 41, 94, 41, 121, 64, 53, 69, 91, 52, 95, 43, 62, 53, 66, 49, 98, 91, 56, 53, 71, 53, 71, 71, 57, 66, 43, 37, 71, 62, 68, 57, 60, 49, 65, 51, 85, 49, 122, 43, 84, 79, 93, 95, 56, 82, 49, 67, 61, 73, 99, 34, 69, 72, 60, 24, 64, 54, 69, 112, 83, 63, 81, 60, 82, 73, 66, 82, 65, 70, 122, 59, 69, 88, 76, 49, 44, 105, 48, 45, 47, 88, 55, 74, 62, 68, 40, 44, 57, 47, 67, 68, 61, 56, 54, 41, 69, 60, 91, 49, 81, 27, 62, 60, 26, 70, 48, 44, 61, 123, 31, 41, 31, 34, 77, 50, 35, 63, 91, 95, 79, 80, 92, 99, 62, 66, 45, 55, 63, 87, 74, 113, 88, 98, 150, 104, 79, 91, 94, 103, 91, 68, 80, 101, 125, 121, 33, 22, 63, 57, 50, 76, 75, 62, 50, 54, 54, 80, 49, 56, 57, 47, 120, 93, 64, 42, 44, 54, 50, 62, 82, 82, 82, 93, 50, 82, 62, 47, 53, 58, 49, 67, 75, 64, 46, 101, 107, 58, 66, 83, 72, 53, 55, 123, 45, 44, 60, 45, 67, 69, 58, 91, 73, 49, 97, 112, 70, 71, 51, 44, 74, 57, 72, 58, 44, 56, 44, 68, 72, 73, 58, 69, 54, 92, 81, 57, 48, 59, 85, 66, 72, 62, 48, 32, 77, 56, 60, 108, 78, 86, 64, 68, 91, 78, 80, 73, 67, 93, 73, 82, 41, 78, 65, 65, 84, 49, 56, 67, 94, 80, 69, 56, 44, 48, 70, 41, 96, 94, 78, 76, 94, 63, 73, 71, 64, 97, 61, 46, 69, 70, 59, 48, 48, 32, 65, 76, 77, 51, 62, 71, 56, 71, 75, 102, 80, 85, 55, 69, 68, 75, 44, 74, 65, 71, 46, 55, 77, 52, 115, 48, 80, 56, 59, 73, 119, 78, 111, 90, 77, 67, 59, 89, 90, 54, 78, 111, 70, 64, 82, 63, 60, 63, 97, 64, 104, 84, 65, 99, 115, 76, 86, 65, 98, 86, 32, 107, 72, 102, 56, 62, 49, 81, 40, 79, 47, 69, 84, 80, 66, 89, 104, 67, 71, 24, 62, 56, 57, 84, 69, 55, 73, 82, 79, 64, 62, 56, 60, 64, 146, 96, 88, 150, 64, 110, 35, 59, 90, 70, 70, 100, 78, 66, 64, 100, 57, 92, 59, 58, 22, 121, 93, 88, 58, 117, 59, 71, 128, 41, 92, 72, 61, 111, 67, 61, 93, 62, 34, 71, 63, 70, 79, 105, 68, 53, 93, 62, 90, 66, 77, 74, 66, 55, 87, 73, 83, 44, 61, 49, 57, 51, 63, 44, 47, 61, 49, 70, 96, 92, 74, 52, 59, 87, 50, 56, 47, 52, 51, 31, 28, 71, 68, 30, 35, 82, 26, 68, 77, 81, 248, 34, 55, 55, 107, 95, 49, 65, 49, 48, 53, 86, 108, 73, 41, 90, 70, 76, 67, 121, 85, 73, 61, 61, 65, 129, 74, 54, 40, 76, 58, 75, 96, 57, 55, 53, 44, 50, 45, 82, 69, 83, 74, 103, 71, 85, 75, 72, 69, 61, 89, 29, 67, 74, 62, 56, 77, 91, 37, 68, 66, 76, 63, 67, 83, 64, 65, 61, 71, 60, 79, 58, 62, 73, 47, 86, 51, 86, 50, 70, 62, 59, 60, 57, 53, 94, 63, 45, 72, 68, 91, 58, 70, 49, 74, 67, 79, 70, 53, 63, 67, 82, 83, 89, 97, 55, 91, 44, 47, 68, 62, 68, 76, 59, 40, 61, 50, 75, 57, 85, 83, 29, 81, 113, 55, 77, 42, 71, 36, 89, 47, 80, 50, 82, 65, 56, 41, 39, 86, 26, 46, 48, 112, 48, 83, 48, 62, 61, 43, 72, 90, 83, 112, 65, 87, 119, 71, 82, 67, 70, 69, 70, 47, 40, 69, 90, 25, 65, 73, 89, 56, 67, 94, 86, 73, 54, 93, 78, 91, 70, 68, 61, 62, 77, 115, 56, 51, 65, 83, 45, 56, 47, 84, 49, 57, 51, 62, 63, 66, 65, 63, 54, 63, 58, 54, 49, 36, 46, 132, 67, 107, 61, 67, 74, 68, 49, 64, 98, 57, 80, 103, 73, 91, 88, 95, 68, 73, 78, 48, 43, 78, 110, 67, 87, 82, 57, 51, 78, 119, 45, 64, 65, 51, 63, 53, 41, 66, 67, 90, 71, 89, 65, 61, 57, 87, 39, 79, 88, 100, 86, 92, 115, 53, 52, 74, 88, 35, 27, 98, 114, 88, 30, 85, 75, 60, 98, 50, 114, 46, 64, 71, 69, 44, 92, 75, 90, 76, 85, 224, 98, 79, 56, 67, 49, 115, 78, 59, 49, 72, 40, 73, 100, 145, 54, 119, 97, 144, 31, 97, 69, 73, 59, 44, 85, 53, 65, 61, 108, 50, 95, 58, 88, 106, 105, 96, 73, 55, 74, 81, 40, 35, 35, 34, 66, 35, 83, 53, 32, 72, 78, 51, 81, 90, 75, 59, 61, 33, 61, 65, 70, 94, 61, 99, 62, 61, 99, 103, 108, 74, 110, 79, 81, 83, 59, 90, 113, 75, 44, 55, 109, 91, 67, 74, 87, 62, 65, 53, 137, 85, 108, 70, 70, 70, 80, 63, 124, 77, 118, 67, 84, 79, 79, 98, 96, 78, 85, 101, 90, 84, 85, 61, 90, 85, 103, 68, 92, 80, 98, 103, 116, 79, 73, 62, 62, 91, 65, 114, 88, 52, 59, 85, 76, 83, 97, 71, 64, 79, 77, 71, 117, 63, 97, 44, 44, 44, 90, 60, 137, 73, 91, 95, 97, 47, 74, 97, 102, 35, 102, 102, 74, 86, 97, 90, 94, 83, 83, 90, 89, 65, 103, 83, 69, 74, 90, 86, 96, 62, 67, 56, 80, 71, 71, 99, 72, 94, 66, 59, 74, 89, 75, 86, 78, 112, 112, 92, 53, 123, 56, 101, 88, 87, 82, 103, 72, 84, 98, 83, 96, 88, 68, 66, 58, 84, 63, 66, 68, 85, 85, 70, 104, 91, 85, 93, 57, 103, 83, 59, 71, 71, 44, 85, 69, 63, 90, 85, 76, 77, 64, 83, 69, 88, 69, 74, 81, 82, 73, 115, 85, 69, 104, 128, 68, 68, 65, 87, 82, 77, 85, 87, 75, 45, 70, 75, 99, 80, 63, 108, 102, 67, 77, 57, 73, 88, 72, 71, 85, 85, 87, 101, 66, 95, 98, 79, 67, 69, 69, 73, 79, 81, 75, 79, 78, 86, 65, 68, 63, 92, 45, 95, 74, 81, 61, 70, 46, 72, 73, 117, 80, 77, 78, 125, 88, 73, 49, 88, 91, 67, 65, 68, 42, 113, 62, 53, 90, 114, 85, 74, 75, 94, 90, 55, 80, 82, 69, 64, 67, 78, 112, 72, 92, 91, 101, 85, 108, 92, 92, 92, 103, 109, 69, 112, 64, 71, 112, 109, 86, 57, 114, 61, 79, 93, 57, 77, 76, 98, 97, 42, 88, 83, 63, 62, 79, 61, 63, 68, 61, 61, 65, 62, 70, 84, 83, 72, 76, 83, 116, 55, 110, 56, 62, 104, 92, 85, 98, 88, 95, 73, 122, 64, 101, 103, 82, 59, 81, 97, 84, 69, 90, 79, 60, 62, 64, 66, 81, 61, 94, 54, 84, 97, 69, 101, 74, 68, 76, 65, 69, 71, 72, 59, 49, 72, 65, 48, 70, 79, 57, 86, 63, 96, 90, 90, 79, 82, 89, 101, 65, 78, 50, 68, 98, 107, 57, 63, 108, 57, 70, 85, 62, 43, 86, 97, 92, 77, 98, 58, 81, 86, 79, 105, 81, 62, 87, 84, 92, 70, 43, 63, 65, 67, 111, 104, 111, 78, 78, 121, 57, 60, 72, 123, 74, 90, 70, 61, 73, 110, 88, 75, 94, 88, 88, 107, 87, 84, 66, 61, 87, 85, 95, 85, 79, 48, 58, 69, 76, 94, 76, 94, 51, 66, 68, 84, 77, 103, 76, 115, 98, 97, 73, 81, 88, 84, 96, 93, 55, 85, 94, 75, 83, 85, 80, 95, 85, 62, 44, 82, 78, 57, 116, 95, 58, 55, 57, 73, 96, 66, 66, 65, 51, 71, 68, 56, 69, 91, 102, 90, 62, 87, 90, 90, 99, 68, 87, 75, 96, 85, 72, 73, 87, 79, 97, 48, 82, 78, 76, 40, 91, 50, 90, 42, 58, 127, 95, 79, 64, 114, 54, 84, 70, 70, 73, 117, 74, 91, 68, 81, 117, 86, 100, 89, 89, 109, 52, 69, 57, 70, 86, 67, 67, 90, 129, 84, 88, 81, 50, 93, 116, 116, 88, 70, 108, 76, 61, 79, 114, 105, 77, 95, 52, 54, 87, 64, 62, 87, 90, 117, 82, 124, 75, 76, 61, 75, 69, 50, 51, 79, 65, 57, 73, 74, 87, 80, 77, 95, 110, 65, 71, 86, 62, 85, 114, 59, 89, 72, 106, 64, 100, 100, 81, 76, 83, 77, 96, 66, 94, 77, 96, 100, 73, 77, 67, 59, 101, 63, 64, 54, 66, 87, 68, 46, 45, 94, 90, 78, 90, 55, 91, 55, 74, 73, 95, 106, 95, 112, 73, 140, 87, 78, 92, 87, 50, 92, 106, 67, 59, 66, 78, 49, 102, 51, 57, 62, 100, 96, 74, 60, 64, 72, 57, 111, 67, 47, 83, 72, 103, 33, 75, 102, 73, 69, 73, 47, 95, 81, 99, 96, 67, 73, 68, 64, 80, 68, 86, 63, 80, 117, 73, 88, 68, 45, 98, 58, 76, 104, 111, 112, 60, 105, 76, 105, 75, 91, 94, 85, 83, 72, 66, 59, 125, 101, 74, 102, 102, 80, 112, 73, 106, 67, 105, 81, 83, 92, 72, 71, 81, 63, 114, 91, 78, 82, 95, 90, 62, 66, 68, 61, 71, 76, 81, 77, 103, 91, 111, 106, 103, 97, 98, 105, 120, 100, 85, 70, 49, 86, 81, 102, 61, 80, 116, 95, 135, 87, 82, 93, 74, 77, 102, 117, 114, 77, 54, 72, 87, 112, 82, 82, 92, 91, 87, 101, 111, 87, 83, 104, 41, 114, 43, 116, 45, 114, 56, 48, 54, 45, 109, 75, 83, 80, 62, 49, 109, 51, 99, 63, 94, 85, 100, 110, 94, 96, 101, 83, 61, 82, 98, 74, 99, 56, 94, 87, 92, 89, 102, 128, 68, 82, 68, 79, 118, 91, 89, 69, 86, 77, 83, 81, 109, 74, 104, 57, 68, 53, 67, 69, 79, 88, 91, 83, 87, 85, 121, 80, 91, 88, 105, 58, 51, 62, 34, 93, 74, 54, 105, 93, 78, 68, 108, 79, 80, 87, 86, 76, 92, 97, 81, 57, 77, 90, 71, 50, 118, 89, 113, 83, 61, 105, 96, 104, 73, 106, 100, 92, 110, 93, 97, 118, 100, 79, 86, 110, 48, 82, 94, 77, 113, 58, 69, 56, 93, 85, 56, 129, 104, 124, 81, 88, 43, 119, 93, 92, 97, 79, 74, 88, 85, 79, 83, 91, 84, 97, 100, 76, 93, 128, 71, 116, 116, 85, 109, 100, 54, 49, 114, 44, 61, 29, 82, 66, 57, 49, 119, 55, 113, 97, 75, 96, 97, 53, 71, 78, 86, 63, 87, 110, 108, 97, 114, 92, 96, 49, 140, 139, 116, 92, 71, 93, 71, 108, 148, 77, 89, 99, 84, 111, 88, 110, 46, 78, 101, 67, 73, 93, 65, 85, 82, 116, 97, 62, 87, 54, 79, 101, 71, 75, 45, 110, 116, 63, 54, 65, 78, 94, 101, 99, 105, 119, 84, 102, 96, 99, 112, 124, 116, 96, 92, 85, 84, 80, 65, 56, 74, 90, 88, 92, 78, 81, 107, 65, 86, 101, 76, 105, 102, 67, 77, 86, 109, 97, 55, 94, 104, 73, 50, 82, 91, 80, 64, 88, 85, 69, 73, 77, 85, 81, 103, 83, 76, 75, 60, 83, 83, 71, 88, 99, 88, 84, 107, 98, 110, 60, 89, 90, 88, 78, 43, 90, 69, 82, 102, 88, 67, 74, 79, 73, 73, 73, 74, 73, 74, 73, 65, 88, 47, 84, 86, 53, 101, 76, 100, 105, 107, 101, 67, 110, 96, 80, 104, 102, 91, 69, 71, 83, 112, 75, 75, 104, 75, 66, 77, 72, 92, 80, 71, 64, 82, 92, 95, 64, 62, 83, 90, 100, 105, 89, 76, 78, 105, 104, 109, 99, 98, 84, 59, 88, 66, 52, 119, 67, 82, 120, 102, 96, 63, 111, 62, 48, 93, 105, 118, 79, 69, 79, 68, 77, 108, 102, 101, 117, 57, 118, 62, 46, 90, 65, 75, 102, 73, 55, 62, 112, 97, 93, 74, 91, 87, 92, 104, 99, 81, 60, 114, 101, 65, 57, 283, 89, 70, 116, 113, 63, 92, 68, 79, 53, 45, 91, 50, 66, 85, 46, 111, 117, 93, 115, 88, 88, 81, 69, 559, 114, 73, 86, 112, 68, 88, 99, 42, 94, 102, 57, 93, 98, 102, 77, 87, 82, 81, 112, 90, 70, 101, 92, 105, 75, 110, 98, 108, 78, 116, 92, 87, 71, 72, 125, 106, 100, 57, 65, 83, 75, 70, 105, 82, 74, 84, 107, 79, 73, 124, 89, 78, 96, 111, 106, 89, 122, 57, 71, 123, 68, 100, 97, 90, 83, 99, 94, 93, 92, 95, 95, 78, 106, 87, 133, 99, 109, 60, 98, 88, 102, 75, 58, 74, 52, 68, 111, 60, 69, 74, 90, 73, 60, 94, 71, 113, 70, 82, 78, 58, 97, 85, 118, 102, 92, 84, 101, 87, 99, 82, 78, 105, 102, 93, 101, 122, 48, 55, 98, 39, 75, 72, 69, 99, 57, 103, 53, 112, 73, 91, 75, 62, 102, 83, 58, 93, 52, 101, 100, 73, 93, 68, 85, 50, 106, 86, 57, 80, 100, 73, 113, 68, 108, 99, 94, 91, 112, 51, 124, 113, 93, 95, 74, 86, 82, 94, 70, 86, 71, 75, 79, 73, 91, 82, 71, 128, 81, 71, 106, 75, 80, 93, 39, 63, 42, 69, 59, 80, 72, 95, 77, 61, 96, 68, 71, 107, 82, 60, 152, 84, 66, 105, 88, 112, 75, 67, 92, 91, 83, 89, 139, 97, 102, 118, 67, 58, 71, 88, 79, 93, 72, 61, 92, 83, 79, 92, 46, 87, 79, 108, 99, 128, 103, 76, 80, 101, 81, 71, 74, 108, 108, 87, 103, 80, 120, 63, 72, 66, 110, 70, 85, 93, 76, 101, 103, 76, 73, 79, 77, 46, 85, 84, 78, 79, 97, 84, 70, 75, 118, 119, 85, 98, 58, 85, 54, 107, 95, 115, 75, 52, 89, 98, 84, 131, 79, 60, 98, 116, 53, 83, 61, 46, 101, 87, 85, 54, 58, 80, 59, 111, 110, 101, 122, 91, 115, 87, 94, 54, 88, 80, 118, 94, 96, 100, 87, 110, 102, 70, 86, 107, 87, 116, 62, 91, 91, 80, 77, 88, 79, 78, 102, 94, 63, 94, 59, 84, 111, 101, 119, 108, 94, 65, 92, 92, 82, 73, 85, 70, 113, 104, 86, 96, 105, 102, 76, 108, 109, 90, 79, 86, 104, 59, 59, 53, 95, 54, 82, 115, 73, 73, 75, 90, 112, 81, 106, 93, 81, 93, 48, 122, 107, 64, 61, 48, 67, 81, 60, 51, 85, 138, 103, 125, 136, 68, 104, 69, 93, 82, 79, 55, 119, 76, 73, 46, 62, 75, 112, 44, 108, 105, 63, 112, 106, 89, 63, 57, 40, 53, 59, 74, 64, 67, 90, 54, 45, 67, 104, 72, 58, 86, 58, 82, 88, 112, 75, 56, 110, 101, 87, 91, 85, 109, 124, 89, 115, 66, 113, 60, 93, 91, 66, 72, 94, 103, 93, 74, 87, 82, 82, 108, 88, 67, 87, 88, 71, 112, 56, 63, 121, 90, 87, 89, 63, 79, 90, 78, 78, 65, 68, 87, 98, 95, 78, 104, 105, 89, 86, 105, 103, 107, 87, 84, 65, 153, 44, 101, 89, 51, 112, 106, 44, 80, 83, 108, 68, 70, 98, 101, 101, 93, 98, 102, 85, 109, 92, 66, 99, 113, 87, 58, 101, 125, 70, 52, 77, 50, 103, 111, 71, 73, 99, 82, 96, 85, 103, 91, 97, 87, 100, 77, 96, 96, 71, 94, 90, 88, 62, 98, 92, 82, 70, 66, 82, 82, 90, 85, 102, 88, 120, 82, 65, 106, 57, 78, 51, 63, 62, 130, 58, 117, 72, 79, 45, 68, 61, 96, 76, 75, 58, 92, 69, 104, 73, 86, 81, 100, 88, 81, 86, 117, 88, 64, 48, 69, 72, 55, 35, 72, 94, 83, 50, 92, 102, 63, 86, 68, 108, 75, 71, 51, 114, 58, 71, 62, 63, 81, 89, 103, 93, 103, 58, 89, 78, 84, 93, 109, 53, 92, 119, 90, 86, 88, 88, 63, 62, 42, 51, 49, 48, 99, 80, 93, 117, 94, 98, 114, 94, 64, 105, 66, 63, 62, 113, 52, 108, 155, 57, 78, 56, 97, 85, 119, 118, 78, 113, 82, 67, 92, 63, 112, 62, 96, 119, 87, 80, 105, 617, 93, 100, 98, 42, 92, 88, 98, 103, 99, 72, 81, 105, 103, 111, 72, 100, 71, 95, 68, 81, 67, 71, 105, 88, 92, 62, 57, 68, 56, 86, 72, 98, 87, 79, 69, 61, 54, 82, 75, 91, 79, 72, 114, 102, 67, 95, 101, 82, 103, 86, 96, 103, 65, 102, 78, 51, 65, 78, 69, 62, 53, 137, 54, 41, 75, 85, 124, 36, 98, 39, 48, 26, 64, 53, 60, 71, 47, 41, 34, 46, 76, 91, 36, 65, 23, 55, 27, 70, 54, 63, 33, 65, 91, 97, 43, 74, 43, 54, 68, 66, 93, 64, 75, 74, 56, 67, 56, 74, 72, 85, 93, 83, 38, 53, 43, 60, 43, 69, 43, 98, 43, 103, 83, 65, 52, 77, 27, 75, 41, 78, 41, 59, 76, 92, 158, 28, 63, 70, 58, 80, 54, 61, 157, 76, 60, 28, 79, 65, 51, 31, 53, 69, 45, 82, 39, 35, 75, 26, 90, 22, 23, 71, 41, 26, 91, 71, 64, 72, 55, 52, 35, 29, 131, 33, 67, 41, 63, 41, 31, 53, 22, 97, 18, 90, 43, 41, 43, 75, 36, 32, 44, 110, 65, 67, 59, 74, 73, 52, 71, 70, 61, 59, 86, 65, 96, 75, 106, 22, 93, 33, 81, 103, 81, 36, 70, 83, 99, 78, 52, 54, 80, 65, 70, 72, 60, 79, 93, 82, 92, 60, 70, 88, 78, 71, 58, 119, 84, 72, 64, 24, 35, 79, 25, 37, 35, 32, 49, 41, 40, 41, 42, 41, 93, 41, 55, 51, 58, 90, 73, 58, 85, 89, 89, 56, 64, 90, 36, 30, 103, 41, 106, 41, 80, 88, 51, 109, 69, 122, 41, 92, 90, 76, 87, 85, 82, 47, 94, 65, 62, 51, 75, 82, 87, 111, 79, 39, 81, 73, 100, 70, 48, 85, 73, 99, 43, 56, 43, 33, 43, 54, 43, 54, 99, 78, 45, 104, 75, 110, 74, 86, 64, 85, 62, 114, 60, 61, 62, 54, 58, 85, 82, 91, 83, 72, 57, 50, 94, 58, 74, 70, 53, 55, 78, 52, 98, 70, 77, 116, 64, 96, 68, 87, 53, 42, 41, 68, 59, 35, 58, 56, 27, 28, 39, 32, 79, 58, 85, 62, 91, 69, 57, 41, 99, 44, 53, 24, 35, 32, 93, 32, 48, 127, 17, 33, 96, 67, 81, 63, 55, 71, 98, 100, 83, 85, 80, 111, 79, 53, 41, 53, 40, 140, 53, 62, 43, 29, 36, 32, 40, 56, 38, 54, 41, 55, 86, 65, 97, 73, 56, 50, 73, 69, 121, 51, 61, 98, 101, 86, 77, 59, 53, 93, 60, 125, 90, 65, 104, 57, 96, 96, 43, 128, 56, 63, 109, 92, 41, 46, 95, 108, 34, 69, 91, 69, 45, 85, 69, 21, 36, 24, 21, 79, 84, 23, 43, 54, 43, 68, 19, 20, 104, 55, 72, 65, 84, 48, 136, 81, 41, 60, 41, 53, 41, 62, 55, 80, 56, 66, 73, 46, 65, 53, 76, 110, 49, 46, 53, 73, 61, 98, 83, 26, 96, 67, 66, 90, 63, 55, 83, 43, 49, 77, 94, 98, 61, 94, 64, 89, 103, 80, 100, 62, 77, 92, 50, 40, 41, 52, 72, 38, 46, 58, 54, 52, 32, 92, 78, 47, 42, 99, 81, 87, 92, 33, 60, 42, 62, 33, 51, 80, 68, 49, 80, 49, 79, 124, 111, 62, 90, 70, 44, 52, 128, 73, 69, 53, 77, 35, 76, 64, 56, 93, 53, 54, 51, 56, 82, 54, 56, 57, 43, 69, 87, 85, 75, 82, 123, 90, 77, 69, 53, 68, 77, 95, 60, 63, 123, 63, 93, 119, 65, 73, 58, 83, 59, 65, 59, 122, 92, 68, 98, 46, 76, 97, 81, 67, 50, 90, 105, 69, 49, 82, 91, 100, 33, 57, 30, 79, 17, 29, 41, 29, 21, 41, 53, 25, 25, 31, 70, 34, 37, 30, 49, 51, 78, 60, 125, 85, 107, 69, 53, 62, 91, 89, 39, 74, 43, 77, 59, 58, 104, 93, 80, 99, 78, 80, 53, 62, 41, 73, 41, 76, 62, 56, 111, 91, 86, 104, 58, 86, 70, 103, 101, 67, 82, 53, 106, 66, 26, 51, 52, 77, 74, 66, 57, 72, 120, 68, 51, 51, 41, 92, 41, 79, 38, 52, 100, 78, 53, 96, 76, 80, 37, 52, 82, 84, 66, 59, 86, 105, 93, 84, 46, 69, 77, 64, 56, 81, 65, 121, 114, 69, 110, 76, 140, 64, 74, 75, 90, 91, 81, 93, 115, 109, 23, 61, 33, 95, 96, 83, 25, 120, 41, 99, 78, 44, 28, 76, 53, 62, 82, 66, 64, 49, 43, 67, 43, 54, 56, 97, 62, 97, 63, 76, 39, 64, 100, 79, 79, 47, 70, 47, 40, 80, 68, 76, 76, 43, 57, 90, 57, 92, 60, 117, 54, 69, 73, 68, 89, 134, 105, 75, 67, 105, 34, 41, 64, 69, 40, 70, 104, 76, 97, 49, 37, 67, 47, 103, 56, 38, 50, 67, 59, 73, 50, 95, 47, 68, 50, 31, 62, 121, 130, 69, 71, 80, 86, 65, 71, 95, 126, 69, 66, 81, 61, 68, 123, 57, 57, 56, 82, 41, 76, 41, 45, 58, 43, 35, 54, 70, 41, 52, 64, 57, 50, 120, 46, 31, 51, 90, 21, 74, 77, 147, 46, 94, 53, 75, 79, 74, 67, 73, 59, 56, 70, 76, 91, 76, 74, 87, 49, 67, 115, 53, 74, 32, 92, 64, 69, 38, 39, 102, 80, 119, 127, 121, 127, 103, 138, 94, 73, 106, 87, 82, 40, 46, 53, 62, 53, 75, 41, 85, 41, 84, 56, 83, 42, 52, 55, 52, 39, 37, 68, 67, 136, 150, 75, 131, 95, 122, 75, 43, 138, 53, 61, 43, 40, 62, 67, 74, 76, 87, 48, 82, 74, 105, 61, 109, 64, 142, 59, 72, 109, 68, 44, 29, 73, 44, 27, 74, 62, 74, 56, 71, 88, 57, 48, 103, 63, 27, 120, 89, 129, 54, 71, 39, 105, 77, 70, 86, 108, 87, 98, 40, 89, 63, 57, 98, 74, 75, 96, 91, 62, 31, 40, 103, 46, 62, 71, 102, 92, 88, 72, 68, 92, 41, 86, 41, 84, 62, 73, 53, 76, 53, 117, 52, 125, 103, 64, 68, 55, 92, 98, 67, 111, 61, 83, 45, 82, 55, 95, 74, 86, 61, 69, 50, 66, 76, 61, 69, 46, 96, 87, 54, 94, 102, 28, 76, 94, 45, 55, 93, 106, 111, 93, 111, 87, 101, 91, 83, 96, 92, 86, 98, 60, 91, 82, 88, 70, 54, 46, 41, 58, 40, 37, 71, 41, 111, 81, 62, 73, 48, 73, 103, 102, 48, 74, 87, 49, 53, 80, 64, 61, 100, 69, 87, 91, 78, 86, 89, 70, 118, 64, 96, 68, 75, 114, 78, 98, 63, 59, 77, 67, 106, 71, 102, 50, 45, 85, 59, 26, 77, 76, 49, 50, 51, 74, 78, 56, 101, 51, 48, 95, 71, 61, 79, 75, 49, 57, 41, 114, 41, 53, 93, 43, 70, 64, 82, 47, 95, 52, 79, 83, 69, 64, 43, 67, 74, 95, 92, 87, 105, 71, 64, 105, 111, 67, 79, 41, 90, 61, 49, 100, 93, 68, 93, 55, 74, 53, 135, 95, 114, 53, 41, 88, 102, 68, 34, 65, 137, 49, 27, 99, 57, 82, 71, 67, 79, 80, 70, 78, 119, 90, 67, 152, 68, 53, 84, 98, 50, 90, 61, 72, 69, 79, 89, 81, 63, 91, 68, 48, 67, 71, 58, 88, 84, 99, 94, 53, 80, 87, 55, 103, 41, 62, 73, 68, 87, 48, 50, 41, 58, 53, 55, 77, 92, 69, 92, 57, 65, 127, 69, 56, 68, 66, 55, 84, 72, 44, 69, 86, 48, 53, 76, 71, 44, 53, 98, 67, 56, 61, 76, 76, 152, 90, 73, 82, 63, 76, 57, 53, 78, 112, 43, 57, 25, 87, 35, 117, 174, 29, 57, 65, 28, 47, 104, 58, 99, 52, 67, 51, 120, 99, 83, 94, 75, 79, 102, 79, 99, 77, 87, 80, 144, 82, 71, 106, 73, 64, 137, 46, 98, 53, 85, 83, 84, 62, 71, 77, 78, 69, 57, 84, 108, 21, 132, 35, 113, 46, 30, 77, 53, 48, 85, 138, 89, 94, 66, 53, 81, 57, 92, 60, 98, 93, 23, 46, 36, 92, 67, 106, 33, 75, 55, 85, 41, 65, 53, 69, 47, 63, 69, 69, 72, 89, 34, 117, 80, 59, 96, 31, 79, 35, 22, 97, 131, 69, 98, 78, 77, 83, 74, 64, 83, 118, 84, 40, 60, 46, 52, 101, 111, 89, 120, 120, 110, 68, 164, 73, 134, 144, 149, 61, 54, 115, 71, 98, 74, 69, 105, 80, 73, 148, 81, 70, 98, 77, 69, 116, 68, 96, 64, 62, 42, 84, 78, 64, 66, 86, 58, 57, 56, 108, 84, 94, 70, 61, 75, 52, 34, 37, 64, 36, 68, 91, 109, 104, 40, 113, 114, 56, 37, 40, 87, 167, 59, 97, 41, 93, 53, 64, 53, 46, 104, 61, 30, 71, 42, 56, 78, 39, 54, 30, 44, 67, 99, 98, 96, 86, 68, 62, 66, 94, 83, 65, 53, 83, 78, 82, 106, 68, 75, 61, 107, 67, 60, 27, 93, 56, 82, 39, 61, 48, 45, 53, 30, 41, 66, 71, 56, 58, 57, 57, 33, 41, 45, 53, 79, 53, 75, 76, 112, 59, 104, 70, 104, 68, 53, 25, 53, 110, 86, 97, 42, 92, 68, 63, 66, 53, 62, 66, 41, 41, 95, 97, 72, 89, 61, 78, 50, 71, 57, 86, 72, 61, 88, 79, 61, 45, 90, 41, 80, 41, 55, 111, 101, 76, 53, 45, 53, 69, 81, 55, 71, 40, 80, 58, 95, 99, 36, 123, 67, 82, 74, 37, 50, 69, 40, 23, 103, 63, 41, 16, 36, 31, 42, 36, 119, 43, 75, 87, 74, 55, 129, 51, 58, 47, 89, 36, 130, 118, 49, 81, 70, 43, 73, 43, 75, 43, 142, 43, 104, 167, 144, 68, 62, 51, 38, 87, 68, 91, 74, 136, 105, 144, 74, 121, 36, 116, 117, 39, 55, 150, 105, 81, 79, 67, 58, 100, 50, 62, 100, 58, 90, 83, 63, 112, 82, 61, 79, 52, 49, 66, 79, 74, 102, 108, 104, 89, 138, 74, 96, 71, 44, 92, 61, 105, 53, 102, 41, 84, 41, 101, 50, 70, 70, 55, 61, 83, 100, 82, 117, 61, 186, 139, 84, 53, 86, 53, 121, 80, 73, 41, 80, 41, 79, 53, 60, 84, 67, 70, 143, 82, 62, 100, 233, 75, 91, 176, 128, 153, 79, 61, 54, 146, 38, 134, 164, 41, 40, 68, 23, 105, 77, 85, 19, 93, 44, 51, 66, 74, 84, 105, 45, 59, 93, 58, 89, 154, 85, 85, 72, 116, 54, 69, 85, 62, 116, 61, 90, 76, 48, 81, 71, 85, 102, 61, 105, 54, 95, 53, 57, 198, 39, 99, 53, 147, 47, 64, 88, 117, 66, 62, 78, 141, 69, 127, 65, 72, 60, 65, 90, 60, 69, 51, 53, 41, 51, 41, 50, 82, 101, 67, 72, 38, 68, 31, 25, 44, 20, 23, 31, 83, 34, 42, 68, 37, 50, 48, 50, 36, 140, 34, 103, 27, 40, 51, 35, 30, 42, 37, 75, 60, 84, 40, 36, 36, 41, 70, 37, 39, 48, 50, 38, 38, 29, 32, 23, 41, 22, 145, 36, 28, 26, 56, 74, 40, 35, 40, 66, 74, 47, 110, 39, 19, 53, 18, 14, 24, 24, 32, 53, 17, 141, 25, 45, 32, 25, 23, 60, 33, 23, 29, 29, 17, 34, 17, 22, 27, 47, 34, 61, 27, 63, 92, 51, 55, 24, 48, 65, 36, 109, 37, 141, 24, 27, 37, 50, 21, 39, 31, 31, 33, 23, 38, 16, 30, 23, 41, 28, 28, 30, 51, 26, 27, 45, 48, 25, 30, 23, 24, 27, 139, 40, 20, 43, 40, 53, 35, 32, 117, 55, 23, 56, 48, 35, 70, 54, 24, 72, 113, 45, 34, 90, 46, 43, 72, 47, 76, 59, 66, 47, 59, 40, 49, 46, 29, 30, 73, 25, 27, 20, 67, 48, 40, 55, 49, 38, 35, 72, 32, 29, 61, 50, 44, 42, 39, 69, 44, 44, 57, 32, 80, 37, 44, 77, 62, 70, 65, 69, 58, 59, 79, 53, 69, 103, 79, 49, 86, 116, 104, 92, 28, 67, 61, 88, 61, 89, 110, 73, 83, 99, 97, 93, 44, 114, 81, 96, 76, 45, 99, 78, 111, 93, 48, 85, 59, 44, 42, 90, 41, 61, 82, 56, 81, 124, 96, 63, 80, 62, 131, 91, 79, 82, 85, 72, 101, 77, 77, 82, 89, 61, 50, 41, 36, 67, 66, 81, 102, 65, 101, 103, 55, 72, 69, 90, 44, 71, 70, 69, 94, 114, 104, 78, 72, 73, 103, 65, 76, 105, 76, 76, 87, 71, 103, 95, 69, 87, 76, 72, 103, 69, 43, 103, 96, 78, 84, 108, 91, 104, 90, 45, 94, 54, 63, 40, 48, 75, 62, 86, 64, 64, 47, 65, 52, 78, 67, 56, 42, 35, 81, 82, 40, 90, 112, 54, 80, 60, 67, 101, 51, 111, 87, 73, 22, 29, 23, 26, 26, 21, 69, 41, 30, 24, 126, 95, 74, 54, 101, 66, 45, 98, 46, 83, 93, 57, 73, 65, 98, 74, 70, 71, 76, 63, 79, 60, 67, 53, 87, 62, 84, 62, 95, 71, 31, 85, 71, 37, 89, 97, 140, 95, 67, 97, 61, 44, 76, 64, 67, 108, 87, 66, 84, 74, 109, 61, 100, 68, 77, 54, 59, 77, 46, 84, 21, 32, 36, 29, 94, 22, 53, 60, 106, 30, 57, 65, 96, 88, 32, 81, 78, 84, 66, 111, 55, 77, 89, 111, 75, 86, 103, 53, 68, 120, 78, 80, 90, 98, 61, 68, 48, 67, 99, 98, 116, 92, 49, 62, 96, 53, 41, 66, 98, 73, 98, 43, 59, 86, 83, 95, 117, 79, 93, 119, 65, 78, 78, 78, 76, 106, 60, 47, 68, 79, 77, 80, 67, 83, 98, 91, 57, 81, 75, 64, 77, 85, 91, 59, 94, 73, 86, 99, 104, 92, 97, 107, 72, 109, 73, 78, 78, 101, 82, 88, 76, 67, 87, 61, 81, 60, 97, 83, 76, 85, 37, 60, 84, 81, 87, 129, 80, 67, 75, 101, 71, 101, 71, 66, 94, 79, 86, 55, 99, 95, 67, 52, 61, 89, 81, 46, 108, 102, 107, 57, 66, 55, 79, 114, 95, 62, 73, 85, 80, 92, 55, 50, 58, 51, 61, 64, 60, 68, 66, 55, 52, 80, 80, 88, 96, 73, 96, 91, 95, 88, 56, 89, 68, 51, 70, 84, 79, 107, 98, 72, 71, 108, 74, 103, 103, 79, 120, 58, 106, 110, 63, 73, 61, 47, 72, 60, 108, 79, 81, 98, 38, 36, 88, 93, 71, 46, 50, 59, 114, 84, 75, 107, 64, 87, 71, 77, 81, 95, 88, 110, 73, 114, 89, 58, 46, 109, 70, 110, 87, 92, 57, 56, 46, 81, 115, 56, 69, 64, 81, 42, 81, 53, 71, 99, 110, 63, 120, 39, 92, 61, 97, 67, 56, 90, 116, 104, 130, 50, 66, 97, 65, 72, 106, 83, 92, 80, 52, 65, 92, 90, 76, 62, 84, 67, 54, 87, 81, 107, 86, 87, 79, 79, 100, 52, 46, 56, 62, 95, 91, 72, 80, 96, 50, 77, 98, 78, 86, 104, 125, 80, 104, 105, 86, 103, 96, 42, 112, 99, 94, 100, 62, 84, 85, 125, 45, 62, 80, 103, 70, 98, 89, 58, 52, 103, 82, 55, 95, 78, 91, 101, 104, 92, 99, 112, 100, 91, 36, 86, 91, 78, 101, 103, 68, 108, 118, 101, 59, 85, 95, 74, 60, 89, 67, 69, 57, 63, 86, 88, 62, 52, 77, 46, 62, 114, 121, 112, 62, 123, 118, 65, 97, 89, 95, 101, 52, 84, 95, 50, 109, 134, 52, 80, 102, 55, 77, 86, 93, 64, 80, 61, 103, 66, 45, 43, 145, 103, 103, 131, 93, 124, 84, 72, 93, 91, 106, 67, 84, 91, 81, 49, 81, 66, 53, 95, 93, 64, 99, 82, 71, 55, 78, 61, 59, 55, 88, 78, 60, 78, 62, 108, 88, 64, 107, 62, 119, 76, 88, 98, 46, 74, 92, 59, 83, 52, 55, 69, 96, 57, 106, 94, 78, 96, 61, 79, 46, 72, 106, 76, 99, 90, 101, 117, 121, 72, 106, 97, 93, 94, 80, 33, 106, 106, 103, 70, 98, 119, 96, 110, 98, 98, 83, 60, 105, 85, 43, 96, 120, 72, 62, 94, 76, 84, 58, 86, 62, 77, 106, 129, 58, 118, 85, 66, 70, 121, 68, 58, 83, 107, 91, 85, 93, 46, 120, 84, 60, 115, 94, 113, 65, 85, 98, 80, 85, 61, 48, 80, 107, 105, 143, 60, 85, 66, 87, 97, 106, 111, 96, 89, 83, 95, 75, 97, 69, 82, 90, 64, 71, 52, 136, 141, 55, 61, 43, 53, 68, 75, 77, 76, 76, 76, 67, 109, 112, 86, 128, 98, 45, 89, 99, 72, 115, 116, 110, 70, 79, 116, 87, 132, 94, 88, 69, 96, 83, 91, 72, 105, 85, 92, 46, 75, 103, 65, 97, 69, 95, 55, 56, 108, 78, 78, 92, 137, 69, 69, 55, 128, 88, 68, 67, 130, 86, 109, 71, 107, 122, 57, 90, 48, 113, 118, 77, 61, 91, 129, 130, 106, 94, 88, 124, 72, 93, 86, 132, 78, 98, 77, 71, 40, 82, 118, 76, 79, 99, 118, 114, 68, 88, 82, 68, 96, 118, 115, 138, 115, 67, 84, 22, 118, 111, 64, 55, 116, 43, 49, 116, 108, 43, 70, 79, 70, 81, 82, 56, 105, 78, 42, 101, 102, 55, 79, 96, 109, 76, 44, 53, 123, 69, 110, 90, 102, 162, 85, 61, 61, 107, 88, 77, 108, 105, 76, 81, 100, 100, 78, 88, 94, 114, 111, 84, 56, 98, 83, 75, 78, 67, 61, 86, 105, 96, 68, 44, 48, 45, 49, 90, 86, 88, 97, 85, 106, 109, 52, 111, 107, 101, 113, 94, 71, 94, 39, 56, 70, 97, 65, 106, 97, 86, 83, 65, 78, 23, 48, 96, 124, 41, 73, 96, 90, 88, 126, 46, 84, 53, 85, 65, 69, 54, 81, 90, 117, 55, 69, 78, 96, 91, 108, 52, 65, 77, 97, 68, 36, 59, 63, 72, 89, 92, 99, 90, 66, 64, 58, 53, 75, 59, 85, 69, 108, 103, 101, 111, 89, 44, 100, 65, 103, 108, 113, 62, 79, 82, 81, 77, 71, 47, 95, 97, 111, 38, 96, 94, 84, 80, 100, 59, 114, 68, 76, 96, 81, 51, 54, 53, 54, 78, 83, 104, 55, 59, 102, 56, 81, 80, 87, 41, 92, 76, 110, 122, 111, 96, 85, 89, 87, 81, 109, 52, 118, 64, 78, 69, 97, 61, 53, 79, 92, 62, 81, 89, 81, 81, 59, 85, 73, 63, 82, 72, 93, 46, 80, 94, 100, 96, 50, 107, 65, 38, 99, 56, 63, 61, 56, 83, 87, 79, 68, 106, 92, 37, 109, 85, 73, 78, 127, 74, 69, 71, 62, 77, 66, 113, 102, 44, 80, 109, 79, 79, 68, 82, 62, 85, 76, 84, 67, 86, 93, 87, 87, 71, 93, 89, 66, 79, 100, 71, 94, 94, 104, 83, 63, 45, 85, 92, 101, 97, 84, 64, 115, 94, 112, 48, 49, 79, 81, 84, 71, 112, 91, 67, 99, 91, 56, 103, 88, 102, 68, 86, 72, 78, 104, 101, 108, 50, 63, 107, 43, 23, 57, 97, 85, 106, 80, 84, 72, 52, 79, 84, 109, 121, 76, 88, 57, 93, 67, 74, 92, 114, 64, 112, 96, 57, 74, 73, 102, 58, 82, 89, 62, 106, 97, 64, 107, 97, 72, 104, 67, 112, 123, 89, 102, 67, 105, 101, 56, 116, 52, 57, 69, 119, 68, 56, 86, 67, 63, 130, 77, 88, 85, 75, 85, 92, 98, 63, 80, 83, 84, 80, 79, 45, 51, 120, 83, 89, 85, 53, 123, 91, 99, 102, 103, 72, 92, 63, 98, 72, 118, 91, 76, 95, 89, 63, 60, 77, 64, 90, 89, 72, 81, 48, 98, 74, 107, 99, 138, 104, 83, 102, 86, 84, 85, 107, 75, 110, 97, 78, 96, 88, 67, 88, 107, 59, 61, 77, 81, 143, 97, 64, 111, 48, 81, 67, 76, 99, 84, 112, 96, 68, 89, 62, 96, 85, 98, 46, 94, 100, 95, 91, 56, 83, 88, 96, 108, 82, 75, 86, 81, 74, 135, 91, 115, 49, 85, 88, 116, 54, 63, 76, 43, 52, 61, 61, 80, 69, 67, 52, 62, 59, 72, 51, 76, 77, 82, 65, 112, 77, 74, 95, 149, 74, 79, 106, 47, 92, 46, 69, 84, 102, 122, 99, 122, 126, 91, 42, 51, 84, 105, 52, 93, 46, 136, 135, 77, 94, 124, 90, 93, 43, 80, 122, 53, 67, 142, 81, 93, 110, 86, 59, 103, 122, 80, 66, 89, 98, 90, 92, 93, 109, 90, 132, 47, 57, 99, 82, 92, 102, 91, 91, 90, 85, 92, 112, 92, 84, 64, 44, 53, 73, 92, 44, 78, 57, 78, 75, 109, 103, 95, 94, 96, 84, 96, 76, 60, 67, 100, 43, 120, 76, 72, 83, 113, 63, 110, 100, 66, 92, 90, 92, 91, 107, 64, 80, 58, 96, 88, 95, 55, 102, 73, 108, 106, 78, 52, 72, 142, 83, 66, 85, 100, 97, 97, 61, 57, 56, 53, 188, 105, 81, 97, 173, 66, 80, 78, 73, 116, 88, 80, 104, 80, 124, 108, 95, 57, 104, 118, 100, 50, 118, 108, 66, 62, 94, 118, 78, 126, 116, 85, 100, 69, 92, 89, 104, 93, 98, 57, 88, 76, 60, 76, 116, 99, 109, 124, 91, 90, 98, 105, 87, 110, 83, 97, 57, 108, 113, 107, 70, 82, 67, 80, 97, 103, 93, 71, 137, 79, 110, 120, 141, 122, 58, 74, 74, 98, 60, 97, 59, 82, 96, 86, 119, 88, 71, 64, 127, 86, 79, 89, 101, 66, 100, 49, 102, 64, 53, 49, 81, 59, 120, 55, 43, 91, 107, 118, 96, 55, 77, 95, 87, 103, 72, 80, 121, 65, 58, 79, 72, 153, 107, 88, 37, 51, 79, 62, 142, 87, 96, 99, 86, 135, 65, 93, 70, 51, 74, 44, 83, 70, 78, 71, 74, 93, 90, 96, 121, 107, 115, 92, 72, 109, 95, 23, 60, 88, 97, 80, 60, 145, 65, 90, 118, 85, 90, 95, 62, 91, 101, 66, 161, 37, 62, 72, 80, 66, 101, 82, 98, 103, 87, 99, 76, 94, 97, 69, 132, 98, 100, 93, 76, 54, 43, 140, 121, 86, 82, 113, 87, 62, 118, 87, 90, 66, 98, 85, 68, 81, 48, 99, 115, 99, 109, 44, 97, 121, 79, 70, 66, 92, 78, 112, 115, 85, 54, 104, 117, 83, 68, 97, 61, 98, 99, 130, 107, 87, 121, 110, 101, 97, 84, 111, 97, 101, 81, 71, 86, 73, 55, 46, 94, 114, 84, 63, 78, 75, 71, 106, 42, 115, 77, 80, 93, 48, 97, 79, 78, 57, 66, 102, 109, 103, 77, 62, 76, 77, 110, 57, 67, 75, 66, 107, 93, 56, 85, 75, 86, 78, 74, 66, 85, 58, 119, 91, 98, 89, 116, 98, 77, 58, 83, 77, 78, 85, 130, 67, 87, 63, 80, 91, 90, 117, 45, 102, 90, 72, 69, 82, 103, 85, 56, 100, 90, 95, 107, 137, 45, 114, 131, 122, 146, 112, 105, 82, 88, 61, 89, 117, 108, 106, 69, 93, 93, 90, 105, 36, 86, 98, 93, 78, 81, 58, 42, 89, 106, 125, 102, 78, 117, 109, 83, 67, 101, 83, 75, 78, 103, 89, 95, 59, 97, 93, 99, 102, 77, 120, 108, 96, 98, 117, 101, 69, 87, 71, 55, 103, 99, 90, 110, 107, 59, 87, 109, 95, 50, 56, 99, 89, 116, 98, 76, 113, 80, 108, 83, 57, 82, 68, 61, 78, 86, 80, 79, 46, 113, 92, 61, 131, 87, 83, 100, 121, 51, 101, 81, 58, 107, 86, 75, 77, 105, 113, 64, 93, 96, 80, 71, 127, 98, 90, 95, 95, 112, 98, 222, 61, 55, 47, 104, 71, 56, 126, 54, 93, 97, 103, 110, 66, 105, 107, 77, 130, 107, 101, 49, 133, 60, 79, 45, 77, 97, 87, 57, 94, 76, 99, 101, 73, 98, 72, 98, 106, 69, 54, 99, 36, 84, 73, 95, 52, 89, 176, 104, 77, 83, 74, 56, 106, 56, 91, 27, 96, 51, 86, 51, 55, 60, 82, 71, 91, 72, 66, 80, 118, 108, 45, 44, 136, 100, 120, 61, 55, 96, 98, 67, 62, 63, 116, 69, 56, 73, 73, 44, 59, 90, 53, 83, 94, 105, 88, 91, 114, 81, 52, 107, 85, 89, 116, 111, 56, 62, 89, 75, 74, 59, 28, 67, 45, 67, 55, 65, 88, 57, 104, 92, 53, 96, 77, 84, 41, 75, 41, 79, 69, 63, 63, 60, 78, 118, 76, 79, 149, 87, 115, 59, 62, 46, 44, 41, 18, 41, 61, 21, 73, 41, 76, 75, 52, 61, 32, 53, 145, 67, 115, 69, 91, 96, 77, 78, 54, 68, 99, 45, 51, 70, 90, 73, 70, 67, 77, 93, 130, 58, 100, 67, 208, 135, 115, 91, 132, 75, 107, 24, 40, 69, 117, 73, 49, 67, 96, 67, 175, 87, 60, 85, 107, 27, 86, 110, 60, 105, 111, 156, 117, 92, 95, 103, 88, 229, 52, 68, 45, 93, 140, 53, 108, 95, 76, 101, 32, 61, 68, 84, 41, 179, 106, 34, 44, 67, 101, 69, 51, 69, 135, 108, 96, 99, 99, 43, 83, 61, 81, 90, 47, 53, 58, 91, 78, 80, 72, 39, 108, 98, 132, 109, 40, 88, 81, 118, 112, 114, 51, 128, 67, 53, 57, 44, 118, 93, 51, 70, 53, 46, 91, 60, 41, 48, 105, 67, 28, 67, 61, 65, 48, 112, 19, 108, 74, 25, 67, 108, 87, 53, 57, 54, 67, 59, 41, 61, 79, 71, 91, 63, 53, 66, 66, 102, 79, 83, 74, 51, 86, 82, 58, 118, 73, 39, 88, 93, 32, 76, 51, 67, 133, 66, 100, 42, 101, 110, 85, 73, 98, 159, 84, 68, 129, 88, 101, 85, 71, 52, 82, 81, 61, 119, 109, 45, 89, 58, 79, 73, 82, 86, 115, 32, 87, 49, 55, 36, 74, 97, 45, 56, 56, 65, 94, 95, 71, 115, 86, 86, 94, 98, 50, 67, 71, 74, 46, 83, 53, 73, 51, 63, 89, 118, 182, 93, 122, 70, 127, 78, 169, 52, 66, 61, 87, 46, 56, 93, 62, 100, 57, 57, 63, 75, 88, 58, 90, 44, 71, 102, 31, 74, 32, 101, 150, 94, 88, 91, 94, 76, 71, 82, 93, 75, 41, 107, 144, 102, 83, 68, 99, 73, 131, 41, 58, 140, 53, 103, 56, 62, 108, 76, 48, 81, 62, 87, 88, 57, 88, 58, 32, 112, 71, 78, 104, 53, 73, 78, 90, 95, 118, 123, 101, 102, 61, 45, 55, 84, 41, 70, 53, 60, 107, 60, 77, 84, 69, 112, 80, 32, 96, 32, 42, 64, 77, 98, 101, 52, 134, 129, 78, 55, 51, 67, 127, 56, 51, 53, 62, 96, 57, 71, 91, 37, 31, 30, 81, 60, 54, 36, 104, 52, 83, 90, 91, 64, 92, 51, 69, 53, 64, 95, 69, 98, 71, 83, 74, 191, 71, 64, 59, 69, 128, 97, 61, 162, 139, 97, 62, 105, 82, 128, 66, 107, 41, 133, 107, 86, 84, 83, 171, 66, 91, 53, 67, 36, 81, 73, 112, 60, 48, 67, 70, 44, 41, 46, 41, 32, 74, 32, 40, 32, 55, 105, 122, 55, 169, 40, 102, 52, 51, 36, 87, 89, 65, 92, 70, 118, 53, 117, 111, 59, 30, 37, 110, 68, 144, 58, 66, 70, 122, 100, 96, 80, 81, 71, 64, 44, 91, 92, 117, 49, 100, 53, 113, 54, 104, 139, 83, 50, 53, 97, 41, 90, 98, 99, 93, 105, 54, 83, 91, 59, 44, 32, 76, 64, 87, 54, 64, 58, 77, 128, 87, 77, 85, 47, 86, 50, 55, 84, 65, 90, 106, 29, 132, 167, 91, 45, 150, 154, 117, 94, 75, 76, 73, 74, 130, 89, 16, 91, 90, 81, 96, 60, 103, 101, 86, 67, 59, 119, 33, 49, 23, 95, 57, 115, 64, 131, 85, 182, 55, 90, 150, 76, 128, 84, 49, 84, 59, 48, 110, 193, 60, 43, 115, 127, 100, 152, 43, 141, 115, 57, 135, 108, 40, 100, 60, 94, 88, 153, 68, 32, 95, 59, 56, 84, 97, 150, 126, 65, 72, 97, 64, 60, 105, 41, 44, 37, 24, 53, 72, 53, 111, 53, 41, 53, 62, 84, 255, 161, 67, 63, 52, 55, 41, 96, 202, 98, 126, 67, 104, 92, 67, 163, 70, 95, 79, 104, 94, 66, 91, 53, 72, 50, 53, 41, 53, 41, 53, 73, 62, 66, 72, 110, 71, 53, 77, 90, 88, 79, 95, 89, 74, 75, 102, 95, 104, 44, 106, 107, 87, 79, 85, 171, 104, 201, 143, 104, 51, 76, 81, 68, 95, 81, 79, 120, 53, 38, 120, 69, 44, 86, 59, 60, 126, 190, 130, 98, 104, 55, 113, 52, 50, 77, 87, 45, 101, 26, 136, 76, 146, 98, 46, 106, 53, 76, 104, 77, 69, 86, 56, 80, 54, 143, 131, 96, 66, 78, 67, 102, 77, 68, 63, 81, 64, 111, 94, 85, 88, 108, 118, 135, 75, 53, 77, 53, 113, 50, 146, 76, 79, 177, 68, 38, 28, 39, 31, 98, 46, 43, 56, 34, 50, 55, 55, 67, 49, 50, 76, 75, 54, 67, 42, 37, 66, 27, 50, 29, 50, 58, 50, 54, 51, 72, 56, 54, 40, 85, 47, 72, 85, 54, 36, 26, 30, 27, 48, 34, 56, 41, 29, 34, 32, 29, 72, 26, 39, 65, 35, 64, 38, 69, 87, 37, 36, 40, 56, 17, 33, 23, 47, 29, 22, 28, 21, 53, 33, 54, 47, 45, 58, 37, 46, 37, 29, 44, 31, 29, 30, 31, 23, 35, 26, 30, 31, 24, 30, 25, 33, 31, 20, 31, 36, 25, 31, 26, 18, 32, 58, 60, 28, 31, 40, 26, 29, 54, 38, 34, 46, 61, 30, 22, 35, 39, 33, 43, 21, 31, 39, 20, 23, 22, 22, 56, 85, 31, 28, 103, 32, 29, 31, 25, 51, 37, 30, 59, 29, 50, 27, 56, 45, 27, 33, 39, 61, 28, 29, 43, 30, 28, 70, 52, 130, 29, 28, 39, 31, 53, 57, 58, 70, 67, 93, 31, 33, 20, 31, 24, 39, 40, 30, 32, 20, 74, 34, 46, 34, 94, 38, 52, 37, 35, 57, 48, 78, 51, 35, 59, 72, 54, 70, 22, 29, 53, 35, 72, 36, 63, 51, 68, 85, 64, 65, 36, 60, 30, 64, 55, 60, 39, 51, 117, 65, 52, 71, 51, 62, 69, 64, 73, 44, 100, 30, 27, 42, 75, 40, 63, 39, 47, 101, 66, 44, 28, 24, 93, 68, 40, 39, 26, 28, 37, 32, 28, 27, 48, 26, 61, 41, 32, 45, 42, 63, 46, 42, 49, 58, 41, 55, 45, 48, 37, 48, 122, 89, 51, 52, 45, 60, 72, 53, 42, 40, 72, 58, 38, 64, 82, 31, 65, 21, 96, 41, 39, 42, 39, 27, 49, 24, 89, 144, 50, 39, 80, 58, 75, 60, 61, 93, 45, 115, 122, 53, 33, 46, 29, 41, 32, 30, 34, 61, 28, 23, 78, 79, 60, 104, 83, 88, 50, 52, 97, 35, 31, 42, 44, 48, 21, 38, 30, 51, 45, 30, 40, 42, 68, 73, 48, 93, 49, 86, 67, 76, 31, 31, 26, 49, 40, 32, 37, 52, 40, 100, 28, 43, 38, 53, 22, 68, 46, 48, 60, 54, 31, 53, 49, 73, 55, 91, 52, 73, 127, 61, 63, 144, 45, 55, 110, 68, 61, 97, 54, 55, 28, 33, 36, 45, 46, 67, 43, 42, 101, 40, 33, 66, 56, 56, 52, 99, 65, 58, 98, 104, 44, 66, 88, 67, 19, 69, 26, 48, 52, 78, 45, 29, 23, 55, 42, 50, 49, 38, 46, 39, 41, 29, 38, 20, 38, 31, 29, 30, 32, 29, 42, 48, 25, 66, 29, 72, 49, 23, 27, 25, 70, 59, 64, 52, 64, 64, 39, 53, 111, 71, 30, 25, 43, 34, 41, 49, 45, 29, 137, 72, 79, 98, 35, 25, 110, 65, 60, 25, 50, 48, 41, 21, 35, 31, 59, 42, 45, 26, 52, 22, 30, 80, 65, 90, 85, 65, 66, 61, 62, 136, 82, 20, 68, 42, 115, 72, 61, 59, 87, 48, 37, 29, 40, 60, 31, 99, 26, 75, 35, 58, 79, 52, 63, 62, 78, 80, 70, 97, 77, 71, 25, 24, 56, 73, 52, 63, 47, 65, 51, 30, 20, 21, 39, 73, 44, 30, 27, 43, 48, 49, 28, 52, 30, 75, 48, 39, 44, 43, 21, 26, 72, 48, 31, 33, 37, 76, 59, 61, 33, 86, 38, 38, 72, 58, 56, 44, 56, 44, 44, 59, 58, 86, 67, 46, 40, 71, 60, 56, 85, 52, 57, 77, 47, 61, 41, 55, 83, 37, 47, 50, 39, 116, 48, 40, 60, 39, 127, 85, 61, 75, 25, 26, 27, 28, 27, 94, 29, 24, 37, 28, 56, 30, 51, 42, 103, 47, 65, 159, 69, 37, 43, 32, 26, 75, 22, 45, 25, 47, 42, 33, 20, 56, 24, 48, 52, 59, 57, 55, 57, 46, 26, 50, 50, 57, 53, 38, 65, 100, 81, 100, 51, 51, 90, 64, 69, 51, 46, 54, 47, 85, 42, 30, 27, 23, 29, 26, 31, 24, 22, 29, 28, 36, 32, 61, 40, 23, 38, 40, 93, 42, 23, 21, 36, 27, 43, 22, 60, 56, 79, 100, 68, 29, 82, 38, 55, 58, 41, 58, 36, 68, 35, 115, 38, 35, 68, 29, 43, 53, 31, 59, 42, 56, 69, 113, 97, 107, 74, 50, 64, 88, 37, 30, 39, 51, 39, 34, 65, 30, 28, 52, 26, 35, 29, 22, 89, 50, 93, 87, 36, 57, 56, 43, 63, 64, 83, 119, 63, 72, 74, 74, 34, 56, 38, 55, 93, 79, 102, 81, 88, 53, 39, 86, 53, 78, 95, 66, 71, 66, 84, 50, 102, 72, 51, 61, 90, 44, 70, 66, 63, 80, 54, 100, 66, 33, 44, 33, 52, 67, 34, 80, 33, 101, 112, 70, 99, 27, 54, 49, 55, 61, 76, 92, 64, 32, 33, 77, 80, 82, 72, 57, 31, 36, 35, 43, 34, 49, 41, 50, 29, 28, 68, 57, 85, 81, 64, 62, 58, 62, 58, 93, 65, 89, 58, 91, 67, 72, 87, 102, 110, 93, 89, 66, 72, 59, 106, 91, 67, 72, 79, 112, 73, 76, 71, 84, 44, 96, 54, 48, 70, 52, 64, 81, 63, 74, 62, 82, 101, 56, 63, 58, 48, 75, 72, 60, 83, 55, 28, 69, 96, 90, 77, 95, 51, 69, 33, 40, 46, 64, 58, 81, 136, 104, 77, 73, 65, 83, 42, 52, 88, 102, 56, 78, 76, 43, 64, 79, 67, 74, 45, 63, 76, 105, 27, 69, 83, 63, 81, 27, 35, 52, 63, 22, 82, 61, 71, 85, 52, 26, 97, 50, 25, 63, 37, 65, 24, 69, 89, 45, 80, 43, 51, 53, 79, 56, 44, 57, 72, 48, 45, 49, 28, 26, 29, 33, 52, 60, 53, 35, 56, 50, 48, 52, 71, 73, 61, 60, 61, 66, 85, 72, 53, 53, 81, 43, 71, 49, 66, 66, 51, 77, 67, 86, 77, 66, 53, 65, 48, 41, 40, 93, 89, 43, 29, 33, 75, 31, 97, 89, 42, 29, 34, 84, 27, 109, 69, 119, 32, 132, 41, 25, 88, 72, 102, 88, 105, 39, 76, 102, 97, 53, 60, 78, 58, 96, 70, 58, 65, 29, 79, 104, 82, 55, 61, 97, 86, 72, 83, 105, 82, 120, 115, 45, 56, 46, 80, 81, 66, 74, 83, 61, 85, 56, 36, 54, 51, 56, 62, 71, 53, 70, 30, 80, 55, 45, 66, 117, 44, 85, 91, 62, 76, 62, 77, 66, 64, 80, 77, 86, 52, 39, 53, 31, 101, 89, 58, 89, 78, 97, 49, 77, 61, 47, 64, 52, 83, 77, 88, 51, 62, 40, 103, 57, 42, 64, 71, 76, 69, 59, 66, 95, 97, 99, 60, 69, 79, 79, 90, 110, 65, 108, 108, 98, 79, 97, 92, 72, 86, 94, 81, 81, 90, 67, 100, 68, 95, 90, 84, 98, 96, 102, 70, 91, 91, 101, 109, 84, 74, 78, 99, 116, 102, 65, 71, 62, 69, 45, 77, 98, 64, 65, 98, 114, 69, 80, 73, 60, 98, 104, 75, 67, 80, 64, 95, 51, 111, 54, 70, 71, 94, 117, 76, 81, 88, 75, 70, 40, 77, 69, 68, 22, 109, 88, 100, 60, 74, 119, 63, 72, 59, 74, 75, 71, 104, 114, 95, 76, 91, 44, 61, 59, 44, 83, 67, 72, 71, 95, 99, 77, 65, 79, 72, 46, 73, 118, 59, 59, 71, 56, 49, 55, 59, 64, 66, 62, 76, 58, 118, 57, 110, 99, 59, 99, 66, 71, 96, 85, 72, 79, 69, 76, 89, 112, 44, 84, 77, 112, 67, 77, 55, 73, 72, 67, 51, 59, 54, 58, 53, 88, 69, 55, 78, 108, 92, 84, 99, 44, 72, 67, 39, 83, 104, 78, 91, 93, 87, 85, 81, 89, 74, 114, 85, 65, 77, 66, 99, 86, 114, 76, 88, 106, 73, 69, 91, 55, 47, 67, 55, 66, 83, 50, 77, 88, 86, 79, 83, 90, 86, 67, 98, 103, 51, 60, 51, 55, 51, 119, 59, 84, 51, 51, 81, 56, 68, 80, 66, 54, 97, 100, 92, 90, 47, 53, 78, 83, 85, 65, 67, 66, 55, 131, 81, 116, 71, 58, 90, 108, 86, 84, 91, 85, 109, 100, 96, 96, 91, 63, 98, 94, 84, 107, 79, 115, 76, 93, 73, 81, 130, 63, 131, 66, 98, 85, 92, 76, 87, 95, 93, 78, 88, 68, 78, 92, 81, 76, 75, 87, 92, 80, 72, 84, 103, 74, 87, 92, 82, 87, 84, 105, 80, 74, 82, 84, 125, 100, 102, 51, 86, 53, 99, 64, 87, 92, 65, 68, 83, 75, 104, 92, 82, 76, 82, 101, 81, 71, 71, 67, 83, 96, 81, 86, 63, 56, 65, 83, 74, 36, 30, 67, 60, 30, 75, 44, 81, 77, 75, 85, 68, 73, 68, 62, 66, 82, 96, 83, 96, 57, 71, 98, 248, 55, 50, 61, 82, 97, 56, 48, 95, 87, 77, 78, 86, 81, 87, 81, 65, 97, 111, 66, 78, 94, 51, 100, 58, 92, 106, 91, 101, 113, 65, 96, 104, 78, 95, 92, 96, 103, 95, 102, 91, 98, 98, 99, 98, 92, 91, 90, 98, 73, 93, 104, 127, 67, 80, 92, 122, 69, 111, 84, 106, 75, 71, 76, 70, 48, 53, 114, 87, 84, 68, 70, 83, 78, 83, 100, 71, 107, 95, 119, 78, 114, 45, 94, 118, 96, 90, 85, 98, 71, 71, 91, 94, 79, 89, 112, 105, 85, 92, 76, 83, 109, 67, 97, 66, 72, 71, 103, 77, 79, 94, 77, 71, 77, 105, 104, 81, 98, 81, 72, 110, 50, 66, 69, 62, 69, 76, 56, 45, 60, 55, 76, 97, 75, 77, 117, 72, 91, 67, 85, 86, 84, 97, 84, 86, 110, 104, 64, 51, 103, 72, 82, 106, 81, 67, 63, 100, 128, 64, 75, 44, 64, 84, 71, 82, 94, 107, 89, 96, 52, 84, 83, 54, 83, 98, 98, 77, 96, 93, 124, 81, 73, 82, 86, 86, 84, 102, 60, 87, 98, 97, 84, 86, 97, 90, 95, 104, 67, 90, 58, 106, 67, 103, 91, 60, 93, 84, 111, 81, 58, 45, 75, 75, 80, 94, 82, 57, 60, 74, 76, 63, 72, 80, 81, 92, 87, 72, 75, 117, 83, 65, 86, 47, 57, 65, 43, 78, 54, 42, 65, 120, 95, 108, 86, 103, 75, 85, 99, 80, 65, 89, 105, 78, 98, 53, 91, 107, 110, 70, 86, 48, 51, 50, 107, 98, 98, 94, 65, 107, 106, 80, 72, 89, 103, 106, 81, 94, 85, 92, 91, 77, 74, 106, 58, 72, 53, 99, 55, 96, 84, 101, 85, 71, 71, 66, 64, 74, 81, 86, 87, 101, 73, 97, 44, 75, 113, 92, 67, 77, 99, 104, 75, 113, 58, 104, 88, 101, 89, 89, 75, 95, 85, 89, 79, 72, 82, 95, 93, 51, 109, 116, 74, 81, 91, 72, 87, 89, 76, 94, 78, 90, 74, 80, 91, 96, 109, 108, 88, 103, 86, 84, 104, 68, 100, 64, 103, 72, 92, 102, 66, 69, 97, 91, 92, 70, 79, 104, 58, 67, 66, 96, 66, 98, 106, 101, 96, 95, 106, 55, 54, 51, 85, 85, 86, 84, 80, 80, 98, 82, 106, 98, 67, 71, 85, 85, 59, 69, 74, 86, 67, 70, 78, 66, 73, 106, 94, 123, 64, 64, 80, 52, 82, 93, 97, 70, 61, 81, 99, 68, 81, 112, 107, 79, 89, 88, 105, 95, 90, 51, 130, 49, 79, 96, 91, 67, 72, 76, 81, 90, 81, 64, 89, 59, 108, 84, 104, 62, 73, 72, 82, 122, 72, 69, 98, 98, 77, 86, 59, 80, 69, 53, 87, 62, 108, 103, 104, 82, 94, 86, 69, 92, 86, 106, 80, 75, 106, 76, 61, 86, 99, 92, 86, 98, 85, 97, 98, 93, 92, 99, 107, 77, 70, 92, 89, 86, 84, 89, 75, 59, 44, 77, 87, 97, 89, 82, 80, 76, 108, 77, 81, 82, 22, 87, 98, 80, 123, 84, 45, 55, 76, 76, 89, 66, 85, 102, 68, 108, 75, 67, 77, 104, 64, 68, 98, 80, 78, 71, 53, 81, 63, 75, 44, 91, 95, 81, 90, 88, 44, 69, 121, 98, 92, 79, 84, 97, 74, 113, 116, 94, 71, 85, 81, 86, 65, 82, 113, 90, 67, 103, 69, 96, 96, 127, 92, 60, 90, 113, 69, 102, 93, 104, 98, 96, 102, 81, 92, 66, 73, 71, 96, 102, 75, 91, 109, 82, 74, 84, 89, 107, 94, 119, 61, 79, 55, 87, 73, 73, 74, 76, 59, 70, 72, 97, 129, 107, 72, 87, 98, 107, 78, 85, 65, 69, 63, 86, 84, 57, 93, 71, 77, 77, 76, 108, 70, 74, 75, 52, 152, 55, 61, 85, 132, 74, 89, 62, 109, 71, 67, 79, 75, 147, 76, 92, 84, 111, 108, 98, 64, 85, 92, 72, 58, 100, 95, 96, 126, 60, 87, 103, 111, 91, 86, 66, 85, 44, 112, 92, 89, 64, 92, 85, 95, 86, 77, 96, 80, 74, 73, 101, 82, 83, 62, 93, 104, 96, 93, 103, 73, 89, 82, 86, 101, 55, 57, 53, 78, 97, 103, 82, 88, 96, 81, 92, 58, 131, 111, 80, 90, 81, 123, 101, 107, 67, 86, 64, 87, 58, 63, 100, 107, 71, 59, 80, 86, 88, 77, 80, 79, 72, 93, 94, 86, 93, 49, 61, 74, 81, 83, 72, 72, 70, 85, 120, 96, 84, 87, 68, 80, 85, 77, 78, 65, 87, 73, 94, 63, 103, 77, 85, 94, 107, 105, 110, 93, 92, 76, 73, 62, 96, 91, 72, 81, 104, 88, 92, 90, 85, 58, 81, 85, 83, 103, 55, 74, 112, 110, 83, 102, 92, 97, 105, 64, 70, 91, 53, 59, 87, 62, 48, 43, 64, 45, 51, 45, 52, 74, 95, 74, 40, 99, 73, 79, 62, 104, 91, 86, 99, 102, 84, 77, 113, 80, 75, 98, 57, 89, 82, 112, 61, 66, 107, 64, 93, 72, 93, 48, 93, 65, 46, 122, 75, 69, 104, 68, 104, 78, 52, 93, 89, 55, 104, 107, 86, 65, 72, 54, 78, 65, 64, 103, 65, 42, 80, 81, 75, 91, 86, 38, 112, 96, 47, 57, 68, 74, 83, 96, 95, 75, 87, 93, 80, 76, 74, 72, 83, 74, 108, 85, 76, 78, 101, 82, 90, 96, 80, 44, 84, 67, 81, 57, 81, 51, 85, 93, 93, 94, 86, 81, 95, 87, 97, 89, 111, 98, 64, 97, 92, 99, 64, 58, 66, 101, 78, 76, 102, 80, 104, 80, 71, 59, 77, 107, 59, 61, 125, 78, 64, 99, 64, 62, 94, 83, 108, 93, 67, 71, 86, 92, 96, 62, 46, 98, 98, 69, 95, 102, 97, 75, 102, 82, 53, 112, 77, 84, 96, 77, 76, 86, 90, 81, 90, 104, 98, 83, 95, 84, 95, 89, 82, 84, 98, 83, 44, 87, 77, 82, 71, 52, 95, 68, 100, 45, 65, 64, 58, 58, 79, 78, 64, 58, 53, 72, 75, 69, 69, 87, 93, 87, 69, 102, 91, 75, 120, 59, 66, 82, 90, 89, 77, 87, 98, 101, 88, 99, 85, 67, 89, 120, 96, 84, 91, 75, 70, 64, 65, 69, 73, 75, 66, 101, 62, 63, 88, 78, 97, 60, 106, 114, 89, 94, 82, 90, 77, 82, 57, 57, 57, 57, 57, 51, 57, 57, 58, 76, 63, 64, 82, 94, 116, 108, 74, 81, 95, 62, 84, 80, 80, 98, 71, 44, 85, 85, 89, 98, 77, 90, 50, 100, 65, 79, 64, 94, 95, 99, 86, 73, 112, 86, 76, 65, 98, 95, 78, 59, 75, 76, 108, 73, 80, 54, 71, 73, 92, 100, 98, 87, 82, 91, 81, 80, 92, 85, 81, 83, 95, 85, 76, 104, 86, 70, 84, 104, 102, 81, 95, 75, 63, 97, 86, 79, 72, 102, 126, 73, 81, 88, 58, 51, 124, 50, 103, 96, 75, 103, 73, 55, 54, 46, 87, 92, 85, 103, 98, 81, 83, 77, 65, 117, 71, 71, 94, 69, 73, 84, 59, 79, 96, 90, 103, 80, 84, 67, 116, 78, 88, 57, 89, 102, 84, 78, 79, 70, 108, 81, 93, 99, 70, 85, 46, 93, 51, 73, 79, 92, 73, 76, 72, 60, 76, 104, 52, 76, 111, 92, 106, 69, 53, 97, 44, 58, 93, 59, 91, 86, 96, 79, 82, 103, 112, 70, 44, 59, 55, 64, 76, 103, 62, 69, 78, 96, 79, 67, 82, 72, 88, 90, 67, 76, 81, 92, 80, 96, 92, 79, 86, 71, 81, 92, 83, 84, 82, 69, 94, 96, 73, 67, 49, 90, 71, 71, 83, 89, 72, 72, 98, 67, 79, 93, 85, 95, 44, 73, 55, 97, 77, 69, 83, 73, 81, 85, 82, 86, 84, 98, 98, 92, 102, 108, 80, 92, 85, 82, 109, 96, 60, 75, 84, 112, 98, 86, 75, 97, 73, 106, 110, 66, 54, 109, 67, 87, 97, 86, 99, 83, 78, 88, 95, 89, 38, 98, 78, 103, 44, 95, 90, 63, 87, 95, 111, 91, 60, 80, 86, 95, 93, 82, 63, 68, 55, 87, 103, 86, 103, 71, 75, 104, 120, 101, 89, 71, 99, 60, 68, 86, 76, 102, 83, 88, 110, 57, 69, 71, 72, 98, 44, 79, 111, 78, 72, 85, 92, 96, 104, 44, 80, 63, 82, 53, 84, 94, 42, 104, 122, 87, 62, 52, 153, 72, 110, 86, 64, 80, 92, 82, 86, 74, 95, 85, 90, 54, 111, 90, 70, 60, 49, 56, 59, 65, 92, 59, 47, 78, 76, 45, 108, 51, 87, 52, 55, 86, 81, 97, 58, 89, 91, 76, 79, 82, 82, 84, 76, 83, 109, 73, 99, 97, 94, 74, 68, 57, 51, 61, 60, 97, 92, 86, 85, 98, 123, 59, 97, 44, 96, 90, 116, 82, 94, 131, 76, 72, 80, 79, 58, 44, 72, 72, 63, 77, 102, 98, 72, 120, 111, 115, 94, 118, 67, 103, 44, 105, 96, 44, 75, 73, 80, 104, 109, 75, 89, 93, 80, 96, 95, 86, 67, 88, 82, 96, 84, 105, 70, 106, 91, 84, 74, 103, 80, 102, 124, 57, 57, 57, 39, 61, 57, 55, 46, 57, 57, 73, 44, 70, 84, 66, 56, 85, 58, 60, 109, 121, 43, 74, 64, 95, 106, 69, 98, 84, 106, 118, 87, 76, 84, 108, 67, 108, 97, 87, 97, 61, 90, 103, 82, 86, 81, 96, 84, 79, 99, 103, 67, 83, 72, 95, 82, 73, 72, 96, 110, 93, 64, 73, 64, 77, 103, 104, 60, 76, 85, 87, 85, 56, 73, 59, 73, 122, 51, 83, 53, 111, 65, 105, 45, 105, 119, 100, 113, 122, 73, 89, 58, 58, 82, 46, 51, 61, 108, 124, 71, 25, 25, 71, 26, 26, 28, 38, 66, 35, 81, 23, 31, 58, 30, 38, 31, 25, 32, 59, 20, 31, 24, 69, 41, 38, 29, 25, 144, 37, 47, 28, 47, 52, 35, 36, 31, 26, 36, 56, 81, 41, 60, 22, 32, 23, 35, 83, 61, 54, 62, 39, 58, 52, 50, 95, 50, 28, 84, 54, 57, 31, 55, 37, 36, 50, 38, 80, 25, 66, 59, 36, 95, 70, 49, 58, 54, 76, 97, 95, 29, 40, 74, 69, 51, 47, 38, 53, 35, 49, 25, 44, 20, 24, 131, 29, 95, 28, 41, 26, 28, 35, 91, 36, 50, 90, 114, 96, 51, 185, 56, 49, 25, 72, 43, 47, 73, 62, 92, 55, 63, 40, 41, 69, 22, 68, 37, 50, 32, 58, 41, 40, 68, 41, 69, 41, 74, 37, 45, 58, 56, 51, 34, 30, 39, 33, 35, 40, 22, 36, 34, 58, 25, 20, 44, 19, 74, 34, 92, 105, 48, 62, 48, 81, 84, 43, 71, 40, 85, 61, 71, 26, 60, 47, 55, 144, 64, 34, 24, 117, 47, 26, 52, 67, 57, 122, 50, 96, 38, 167, 104, 52, 37, 37, 40, 50, 47, 41, 50, 78, 53, 47, 39, 38, 43, 53, 96, 59, 46, 58, 91, 37, 50, 41, 40, 59, 50, 42, 53, 115, 94, 56, 46, 59, 108, 60, 97, 53, 26, 120, 28, 34, 48, 142, 34, 51, 80, 54, 76, 41, 63, 42, 71, 25, 54, 34, 50, 92, 84, 129, 93, 23, 42, 37, 26, 21, 30, 24, 18, 35, 20, 40, 47, 29, 93, 46, 64, 82, 50, 63, 110, 49, 27, 48, 87, 58, 42, 56, 70, 42, 49, 49, 48, 87, 27, 58, 35, 45, 38, 58, 70, 37, 59, 95, 97, 83, 64, 100, 92, 120, 104, 30, 140, 28, 113, 38, 51, 37, 53, 27, 62, 26, 34, 56, 43, 37, 47, 39, 102, 51, 35, 79, 43, 48, 74, 70, 48, 68, 29, 64, 96, 51, 41, 34, 52, 54, 28, 55, 48, 58, 41, 30, 25, 54, 33, 31, 46, 35, 33, 37, 72, 49, 34, 47, 40, 61, 59, 87, 91, 36, 101, 65, 49, 55, 49, 48, 41, 88, 46, 85, 64, 50, 69, 55, 54, 60, 96, 48, 32, 50, 72, 45, 80, 81, 67, 35, 64, 48, 83, 144, 68, 69, 49, 42, 96, 39, 58, 90, 56, 93, 55, 86, 58, 43, 81, 49, 43, 74, 110, 82, 69, 76, 103, 40, 95, 48, 72, 125, 88, 53, 97, 48, 47, 44, 63, 25, 72, 56, 58, 49, 30, 48, 40, 49, 32, 30, 63, 101, 25, 30, 61, 35, 37, 47, 58, 63, 61, 69, 52, 41, 41, 48, 56, 72, 79, 94, 67, 91, 67, 126, 64, 30, 46, 84, 28, 88, 82, 47, 44, 59, 66, 55, 40, 80, 43, 80, 36, 72, 49, 70, 58, 20, 29, 28, 24, 28, 22, 30, 26, 49, 27, 55, 54, 28, 48, 49, 73, 54, 65, 64, 48, 70, 61, 60, 49, 74, 37, 48, 63, 95, 49, 37, 47, 23, 18, 89, 21, 74, 134, 77, 66, 29, 53, 27, 40, 90, 41, 52, 65, 20, 78, 23, 53, 34, 88, 114, 39, 41, 63, 40, 103, 68, 122, 41, 62, 33, 46, 89, 53, 76, 155, 60, 41, 54, 80, 65, 86, 75, 81, 83, 115, 31, 42, 69, 41, 47, 36, 47, 32, 46, 24, 64, 43, 99, 48, 48, 71, 125, 74, 79, 36, 50, 49, 32, 93, 89, 114, 67, 41, 97, 40, 45, 42, 74, 46, 52, 67, 117, 92, 38, 59, 69, 80, 69, 84, 68, 96, 65, 66, 45, 105, 34, 28, 30, 137, 35, 27, 34, 40, 43, 83, 43, 25, 49, 46, 49, 102, 29, 32, 50, 63, 47, 64, 27, 72, 74, 63, 29, 55, 65, 63, 27, 100, 34, 72, 61, 41, 75, 90, 64, 30, 48, 34, 42, 53, 36, 33, 50, 97, 122, 72, 30, 48, 66, 28, 125, 54, 25, 25, 47, 41, 33, 36, 42, 29, 54, 20, 58, 133, 71, 30, 103, 43, 45, 46, 61, 55, 72, 55, 85, 60, 30, 26, 127, 25, 132, 41, 43, 81, 77, 30, 25, 49, 33, 41, 101, 48, 29, 50, 38, 34, 38, 83, 24, 77, 43, 77, 75, 77, 103, 77, 26, 20, 19, 25, 47, 22, 58, 70, 55, 46, 74, 37, 46, 40, 44, 42, 22, 37, 33, 44, 23, 59, 28, 47, 133, 40, 41, 135, 50, 36, 19, 48, 20, 43, 77, 31, 47, 35, 77, 48, 92, 37, 75, 49, 57, 74, 67, 58, 54, 97, 41, 76, 54, 100, 46, 53, 52, 42, 152, 79, 54, 49, 72, 43, 60, 36, 64, 41, 50, 50, 48, 65, 93, 44, 55, 58, 85, 60, 29, 57, 26, 41, 56, 112, 55, 19, 47, 28, 38, 62, 32, 24, 20, 29, 132, 28, 28, 51, 27, 72, 115, 53, 48, 41, 70, 87, 101, 51, 117, 50, 63, 65, 65, 84, 111, 66, 61, 55, 92, 79, 78, 56, 74, 96, 98, 116, 66, 82, 69, 97, 36, 58, 20, 30, 28, 30, 81, 48, 78, 45, 24, 26, 28, 26, 36, 21, 72, 25, 29, 55, 22, 49, 40, 22, 82, 43, 26, 81, 25, 32, 41, 55, 95, 54, 48, 45, 64, 159, 42, 38, 31, 48, 34, 57, 28, 57, 62, 57, 54, 57, 27, 24, 48, 25, 45, 38, 37, 49, 30, 37, 48, 88, 95, 50, 27, 75, 42, 68, 58, 111, 24, 43, 36, 39, 23, 46, 28, 72, 30, 72, 36, 41, 34, 73, 47, 39, 73, 65, 40, 50, 78, 75, 75, 72, 78, 102, 67, 201, 44, 41, 25, 41, 40, 38, 46, 34, 34, 89, 73, 95, 64, 85, 41, 87, 73, 94, 58, 81, 129, 124, 76, 65, 115, 82, 107, 40, 41, 190, 90, 53, 79, 52, 122, 39, 49, 79, 106, 26, 83, 67, 57, 108, 80, 62, 66, 54, 32, 62, 55, 25, 31, 66, 72, 42, 47, 45, 53, 76, 78, 70, 135, 97, 71, 89, 60, 61, 64, 66, 32, 72, 84, 54, 42, 60, 76, 93, 132, 49, 85, 69, 82, 58, 33, 73, 74, 64, 60, 58, 51, 74, 95, 50, 113, 58, 84, 115, 64, 67, 96, 48, 57, 51, 40, 92, 100, 44, 58, 106, 98, 91, 25, 34, 38, 19, 48, 69, 49, 74, 40, 28, 80, 34, 48, 73, 40, 62, 64, 33, 58, 118, 31, 44, 96, 55, 86, 58, 63, 69, 72, 66, 84, 33, 101, 71, 36, 89, 68, 43, 121, 104, 56, 33, 69, 68, 65, 69, 77, 62, 62, 59, 51, 82, 40, 96, 123, 45, 29, 48, 30, 70, 133, 47, 96, 78, 70, 82, 61, 91, 60, 40, 49, 48, 28, 41, 26, 73, 28, 23, 60, 72, 42, 32, 88, 97, 84, 28, 129, 117, 74, 113, 89, 57, 108, 35, 55, 66, 97, 91, 66, 57, 58, 96, 55, 82, 101, 48, 55, 93, 107, 83, 48, 29, 63, 26, 49, 29, 56, 48, 44, 55, 73, 54, 82, 83, 35, 56, 31, 48, 91, 84, 30, 28, 24, 72, 43, 26, 57, 62, 73, 92, 56, 56, 86, 49, 58, 136, 41, 105, 52, 105, 54, 50, 49, 92, 48, 101, 62, 48, 33, 113, 81, 92, 82, 41, 75, 60, 94, 97, 48, 90, 79, 43, 51, 47, 67, 111, 55, 42, 68, 67, 40, 117, 95, 107, 79, 74, 88, 49, 73, 45, 89, 103, 37, 68, 36, 56, 50, 45, 61, 72, 54, 50, 40, 36, 116, 72, 66, 103, 58, 189, 50, 66, 50, 66, 41, 64, 93, 41, 44, 84, 20, 84, 69, 95, 69, 65, 70, 38, 70, 45, 27, 34, 20, 112, 25, 29, 55, 78, 26, 57, 55, 35, 26, 79, 46, 93, 62, 49, 119, 63, 40, 47, 21, 35, 21, 27, 82, 57, 24, 89, 20, 26, 21, 35, 67, 112, 25, 21, 104, 98, 56, 53, 56, 122, 20, 76, 53, 92, 130, 115, 93, 65, 115, 85, 128, 55, 67, 85, 59, 53, 64, 38, 111, 68, 46, 50, 44, 50, 68, 87, 74, 72, 24, 55, 28, 74, 51, 72, 79, 63, 73, 38, 88, 97, 106, 73, 64, 77, 57, 60, 59, 66, 89, 71, 53, 64, 125, 56, 75, 88, 80, 96, 82, 53, 68, 71, 54, 74, 41, 60, 82, 53, 65, 66, 71, 65, 66, 103, 73, 100, 109, 93, 50, 35, 39, 45, 59, 116, 109, 47, 35, 144, 81, 36, 45, 94, 151, 92, 63, 114, 27, 27, 81, 74, 34, 85, 56, 71, 118, 46, 43, 80, 43, 70, 43, 95, 38, 65, 68, 42, 82, 49, 36, 47, 67, 96, 29, 55, 83, 58, 59, 58, 60, 56, 80, 43, 91, 81, 69, 82, 20, 43, 31, 49, 55, 56, 22, 42, 134, 97, 60, 79, 74, 90, 79, 71, 56, 46, 71, 34, 42, 55, 78, 35, 85, 72, 75, 65, 70, 57, 33, 27, 43, 20, 84, 16, 57, 47, 106, 129, 118, 112, 67, 41, 67, 37, 86, 59, 40, 53, 53, 95, 34, 55, 72, 73, 49, 64, 59, 44, 49, 42, 79, 56, 90, 55, 53, 97, 61, 96, 49, 27, 35, 58, 98, 58, 48, 99, 78, 53, 84, 109, 56, 99, 103, 62, 148, 58, 95, 71, 50, 104, 90, 82, 97, 81, 86, 67, 112, 66, 44, 93, 58, 133, 71, 32, 45, 120, 45, 48, 24, 38, 27, 39, 49, 37, 28, 38, 22, 62, 23, 113, 38, 83, 46, 49, 42, 51, 74, 67, 59, 61, 50, 83, 104, 112, 45, 72, 55, 67, 98, 30, 36, 30, 28, 84, 101, 62, 29, 28, 78, 58, 85, 108, 35, 107, 49, 90, 49, 67, 34, 37, 38, 61, 19, 31, 38, 26, 26, 44, 53, 116, 90, 115, 36, 33, 86, 140, 58, 87, 76, 37, 25, 40, 73, 28, 47, 50, 55, 47, 68, 64, 84, 49, 82, 68, 91, 59, 30, 70, 106, 92, 82, 93, 100, 63, 132, 104, 103, 117, 57, 93, 55, 66, 49, 60, 48, 74, 122, 50, 71, 93, 120, 87, 27, 73, 74, 50, 61, 50, 27, 72, 133, 79, 78, 63, 63, 67, 55, 38, 37, 19, 42, 26, 38, 72, 52, 48, 38, 44, 120, 69, 100, 74, 85, 67, 138, 53, 66, 82, 59, 31, 119, 58, 89, 48, 100, 58, 75, 107, 58, 82, 77, 30, 77, 87, 60, 73, 31, 64, 32, 66, 52, 100, 45, 75, 64, 22, 35, 46, 43, 68, 75, 72, 121, 101, 67, 95, 51, 107, 25, 61, 50, 85, 91, 87, 53, 62, 68, 70, 55, 71, 46, 36, 109, 105, 63, 49, 98, 94, 26, 98, 81, 45, 115, 56, 79, 60, 53, 122, 30, 90, 92, 50, 61, 134, 35, 85, 32, 72, 73, 71, 23, 69, 86, 48, 98, 58, 103, 69, 61, 56, 73, 59, 45, 44, 91, 81, 66, 101, 75, 71, 43, 97, 104, 77, 71, 104, 42, 84, 54, 50, 135, 41, 133, 73, 44, 23, 42, 47, 63, 110, 89, 53, 92, 91, 59, 123, 106, 60, 49, 61, 71, 62, 86, 125, 63, 96, 70, 60, 92, 90, 176, 67, 122, 97, 80, 147, 63, 141, 65, 93, 55, 61, 85, 81, 85, 70, 44, 63, 72, 114, 58, 33, 44, 79, 57, 37, 40, 56, 48, 59, 44, 102, 165, 74, 84, 92, 67, 40, 115, 65, 102, 36, 62, 124, 64, 72, 64, 53, 75, 56, 53, 110, 86, 82, 74, 41, 63, 53, 129, 96, 102, 102, 43, 58, 90, 67, 84, 126, 33, 122, 103, 79, 68, 68, 103, 114, 55, 70, 58, 26, 55, 110, 70, 75, 35, 42, 54, 98, 60, 90, 67, 27, 108, 77, 92, 68, 72, 33, 45, 72, 57, 27, 87, 59, 65, 74, 110, 75]\n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for a in df.Address:\n",
    "    lens.append(len(a))\n",
    "print(max(lens))\n",
    "print(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_dataset = CustomDataset(df_train.Address.values, df_train.Topic.values, len(class_id), vocab_dict, bert_tokenizer, doc_length=256)\n",
    "test_dataset = CustomDataset(df_test.Address.values, df_test.Topic.values, len(class_id), vocab_dict, bert_tokenizer, doc_length=256)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "[101, 16770, 1024, 1013, 1013, 7479, 1012, 26866, 1012, 8917, 1013, 2739, 1013, 2865, 1011, 6325, 102]\n",
      "[101, 16770, 1024, 1013, 1013, 12043, 15166, 29337, 5339, 14287, 1012, 6187, 1013, 25682, 1013, 5890, 1013, 2403, 1013, 3319, 1011, 8987, 1011, 1037, 1011, 8348, 1011, 5877, 25820, 1011, 2208, 1013, 102]\n"
     ]
    }
   ],
   "source": [
    "for val in df_train.Address.values[:1]:\n",
    "    print(train_dataset.tokenizer(val).keys())\n",
    "for val in df_train.Address.values[:2]:\n",
    "    print(train_dataset.tokenizer(val)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset time = 0.6469950675964355\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "X, y = next(iter(test_dataloader))\n",
    "print(f'dataset time = {time.time() - st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_weight,batch_size, max_token_count, dropout=0.3, num_out_features=4, train_embedding=False, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_count = max_token_count\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(embedding_weight.shape[0], embedding_weight.shape[1])\n",
    "        self.embedding.weight = torch.nn.Parameter(copy(embedding_weight))\n",
    "        self.embedding.weight.requires_grad=train_embedding\n",
    "        \n",
    "        embedding_dim = embedding_weight.shape[1]\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 64, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=5)\n",
    "        self.globalpool = nn.AdaptiveMaxPool1d(64)\n",
    "        self.fc1 = nn.Linear(64 * max_token_count//4, 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.globalpool(x)\n",
    "        x = F.relu(self.fc1(x.view(self.batch_size, -1)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_for_Text(bert_model.bert.embeddings.word_embeddings.weight, batch_size=batch_size, max_token_count=256, num_out_features=len(class_id), train_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import lightning as L\n",
    "# from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(ClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(\"model\", logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr=  0.001380384264602885\n",
    "# 0.00010631317724117211\n",
    "output_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.3804e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "embedding_dim = 128\n",
    "label_size = 1\n",
    "\n",
    "classifier_torch_model = CNN_for_Text(bert_model.bert.embeddings.word_embeddings.weight, batch_size=batch_size, max_token_count=256, dropout=0.2, num_out_features=len(class_id), train_embedding=False).to(device)\n",
    "optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=0.00012)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 90, 120],gamma=0.5, verbose=True)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "classfier_lightning_model = ClassifierLightningModel(classifier_torch_model, \n",
    "                                                     num_classes=len(class_id),\n",
    "                                            learning_rate=lr,\n",
    "                                            batch_size=batch_size,\n",
    "                                            optimizer=optimizer,\n",
    "                                            loss_func=loss_func,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            user_lr_scheduler=True\n",
    "                                            ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import lightning as L\n",
    "\n",
    "# from scripts.utils.CustomCallbacks.ModelCheckpoint import CustomModelCheckpoint\n",
    "\n",
    "# callbacks = [\n",
    "#         CustomModelCheckpoint(dirpath=r'models\\model2_word_embedding-256-2', filename='str_embedding', every_n_epochs=1, mode='min', monitor='train_loss', save_on_train_epoch_end=True),\n",
    "#         ModelCheckpoint(save_top_k=5, mode='min', monitor='train_loss', save_last=True)\n",
    "#         ]\n",
    "trainer = L.Trainer(\n",
    "            # callbacks=callbacks,\n",
    "            max_epochs=400,\n",
    "            accelerator= 'gpu' if device==torch.device(\"cuda\") else 'cpu',\n",
    "            logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "            num_sanity_val_steps=0,\n",
    "        #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightning.pytorch.tuner import Tuner\n",
    "# tuner = Tuner(trainer)\n",
    "# tuning_result = tuner.lr_find(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader, min_lr=0.00001,max_lr=0.01, num_training=100)\n",
    "\n",
    "# fig = tuning_result.plot(suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | CNN_for_Text       | 23.8 M\n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | val_acc   | MulticlassAccuracy | 0     \n",
      "4 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "397 K     Trainable params\n",
      "23.4 M    Non-trainable params\n",
      "23.8 M    Total params\n",
      "95.355    Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|█████████▋| 30/31 [00:05<00:00,  5.62it/s, v_num=494, train_loss_step=0.312, train_acc_step=0.0967]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 1:  97%|█████████▋| 30/31 [00:03<00:00,  9.50it/s, v_num=494, train_loss_step=0.301, train_acc_step=0.0869, val_loss_step=0.298, val_acc_step=0.0811, val_loss_epoch=0.297, val_acc_epoch=0.0876, train_loss_epoch=0.403, train_acc_epoch=0.0795]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 2:  97%|█████████▋| 30/31 [00:03<00:00,  9.60it/s, v_num=494, train_loss_step=0.297, train_acc_step=0.0752, val_loss_step=0.301, val_acc_step=0.0811, val_loss_epoch=0.300, val_acc_epoch=0.0876, train_loss_epoch=0.304, train_acc_epoch=0.0826]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 3:  97%|█████████▋| 30/31 [00:03<00:00,  9.94it/s, v_num=494, train_loss_step=0.295, train_acc_step=0.0957, val_loss_step=0.298, val_acc_step=0.0811, val_loss_epoch=0.297, val_acc_epoch=0.0876, train_loss_epoch=0.298, train_acc_epoch=0.0823]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 4:  97%|█████████▋| 30/31 [00:03<00:00,  9.59it/s, v_num=494, train_loss_step=0.291, train_acc_step=0.121, val_loss_step=0.293, val_acc_step=0.102, val_loss_epoch=0.293, val_acc_epoch=0.108, train_loss_epoch=0.296, train_acc_epoch=0.0881]   Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 5:  97%|█████████▋| 30/31 [00:03<00:00,  9.95it/s, v_num=494, train_loss_step=0.280, train_acc_step=0.151, val_loss_step=0.294, val_acc_step=0.140, val_loss_epoch=0.293, val_acc_epoch=0.149, train_loss_epoch=0.292, train_acc_epoch=0.105] Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 6:  97%|█████████▋| 30/31 [00:03<00:00,  9.89it/s, v_num=494, train_loss_step=0.270, train_acc_step=0.188, val_loss_step=0.279, val_acc_step=0.191, val_loss_epoch=0.278, val_acc_epoch=0.190, train_loss_epoch=0.286, train_acc_epoch=0.130]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 7:  97%|█████████▋| 30/31 [00:03<00:00,  9.58it/s, v_num=494, train_loss_step=0.264, train_acc_step=0.201, val_loss_step=0.270, val_acc_step=0.188, val_loss_epoch=0.268, val_acc_epoch=0.199, train_loss_epoch=0.273, train_acc_epoch=0.170]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 8:  97%|█████████▋| 30/31 [00:03<00:00,  8.97it/s, v_num=494, train_loss_step=0.258, train_acc_step=0.228, val_loss_step=0.265, val_acc_step=0.217, val_loss_epoch=0.263, val_acc_epoch=0.232, train_loss_epoch=0.264, train_acc_epoch=0.201]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 9:  97%|█████████▋| 30/31 [00:03<00:00,  8.98it/s, v_num=494, train_loss_step=0.254, train_acc_step=0.247, val_loss_step=0.261, val_acc_step=0.243, val_loss_epoch=0.259, val_acc_epoch=0.247, train_loss_epoch=0.258, train_acc_epoch=0.226]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 10:  97%|█████████▋| 30/31 [00:02<00:00, 10.16it/s, v_num=494, train_loss_step=0.251, train_acc_step=0.243, val_loss_step=0.251, val_acc_step=0.259, val_loss_epoch=0.249, val_acc_epoch=0.269, train_loss_epoch=0.254, train_acc_epoch=0.237]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 11:  97%|█████████▋| 30/31 [00:03<00:00,  9.95it/s, v_num=494, train_loss_step=0.248, train_acc_step=0.262, val_loss_step=0.250, val_acc_step=0.265, val_loss_epoch=0.247, val_acc_epoch=0.277, train_loss_epoch=0.250, train_acc_epoch=0.256]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 12:  97%|█████████▋| 30/31 [00:02<00:00, 10.29it/s, v_num=494, train_loss_step=0.244, train_acc_step=0.273, val_loss_step=0.252, val_acc_step=0.263, val_loss_epoch=0.249, val_acc_epoch=0.279, train_loss_epoch=0.247, train_acc_epoch=0.268]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 13:  97%|█████████▋| 30/31 [00:03<00:00,  9.41it/s, v_num=494, train_loss_step=0.238, train_acc_step=0.289, val_loss_step=0.246, val_acc_step=0.288, val_loss_epoch=0.243, val_acc_epoch=0.309, train_loss_epoch=0.244, train_acc_epoch=0.281]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 14:  97%|█████████▋| 30/31 [00:03<00:00,  9.56it/s, v_num=494, train_loss_step=0.235, train_acc_step=0.306, val_loss_step=0.239, val_acc_step=0.311, val_loss_epoch=0.236, val_acc_epoch=0.332, train_loss_epoch=0.241, train_acc_epoch=0.295]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 15:  97%|█████████▋| 30/31 [00:02<00:00, 10.10it/s, v_num=494, train_loss_step=0.228, train_acc_step=0.342, val_loss_step=0.233, val_acc_step=0.352, val_loss_epoch=0.230, val_acc_epoch=0.364, train_loss_epoch=0.237, train_acc_epoch=0.314]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 16:  97%|█████████▋| 30/31 [00:03<00:00,  9.17it/s, v_num=494, train_loss_step=0.220, train_acc_step=0.393, val_loss_step=0.225, val_acc_step=0.400, val_loss_epoch=0.222, val_acc_epoch=0.408, train_loss_epoch=0.231, train_acc_epoch=0.342]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 17:  97%|█████████▋| 30/31 [00:02<00:00, 10.25it/s, v_num=494, train_loss_step=0.213, train_acc_step=0.421, val_loss_step=0.220, val_acc_step=0.389, val_loss_epoch=0.217, val_acc_epoch=0.417, train_loss_epoch=0.225, train_acc_epoch=0.377]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 18:  97%|█████████▋| 30/31 [00:02<00:00, 11.81it/s, v_num=494, train_loss_step=0.206, train_acc_step=0.436, val_loss_step=0.211, val_acc_step=0.421, val_loss_epoch=0.208, val_acc_epoch=0.451, train_loss_epoch=0.218, train_acc_epoch=0.400]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 19:  97%|█████████▋| 30/31 [00:02<00:00, 10.32it/s, v_num=494, train_loss_step=0.206, train_acc_step=0.436, val_loss_step=0.209, val_acc_step=0.428, val_loss_epoch=0.205, val_acc_epoch=0.450, train_loss_epoch=0.211, train_acc_epoch=0.425]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 20:  97%|█████████▋| 30/31 [00:02<00:00, 10.91it/s, v_num=494, train_loss_step=0.200, train_acc_step=0.455, val_loss_step=0.200, val_acc_step=0.476, val_loss_epoch=0.198, val_acc_epoch=0.488, train_loss_epoch=0.208, train_acc_epoch=0.432]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 21:  97%|█████████▋| 30/31 [00:02<00:00, 10.14it/s, v_num=494, train_loss_step=0.196, train_acc_step=0.461, val_loss_step=0.197, val_acc_step=0.479, val_loss_epoch=0.194, val_acc_epoch=0.496, train_loss_epoch=0.204, train_acc_epoch=0.449]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 22:  97%|█████████▋| 30/31 [00:02<00:00, 10.73it/s, v_num=494, train_loss_step=0.192, train_acc_step=0.512, val_loss_step=0.195, val_acc_step=0.478, val_loss_epoch=0.191, val_acc_epoch=0.499, train_loss_epoch=0.200, train_acc_epoch=0.463]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 23:  97%|█████████▋| 30/31 [00:02<00:00, 10.15it/s, v_num=494, train_loss_step=0.191, train_acc_step=0.504, val_loss_step=0.189, val_acc_step=0.483, val_loss_epoch=0.185, val_acc_epoch=0.517, train_loss_epoch=0.196, train_acc_epoch=0.480]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 24:  97%|█████████▋| 30/31 [00:02<00:00, 10.26it/s, v_num=494, train_loss_step=0.184, train_acc_step=0.526, val_loss_step=0.183, val_acc_step=0.512, val_loss_epoch=0.180, val_acc_epoch=0.539, train_loss_epoch=0.189, train_acc_epoch=0.501]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 25:  97%|█████████▋| 30/31 [00:02<00:00, 10.72it/s, v_num=494, train_loss_step=0.174, train_acc_step=0.561, val_loss_step=0.180, val_acc_step=0.530, val_loss_epoch=0.176, val_acc_epoch=0.562, train_loss_epoch=0.184, train_acc_epoch=0.524]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 26:  97%|█████████▋| 30/31 [00:02<00:00, 10.14it/s, v_num=494, train_loss_step=0.176, train_acc_step=0.550, val_loss_step=0.173, val_acc_step=0.567, val_loss_epoch=0.170, val_acc_epoch=0.590, train_loss_epoch=0.180, train_acc_epoch=0.537]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 27:  97%|█████████▋| 30/31 [00:02<00:00, 11.03it/s, v_num=494, train_loss_step=0.175, train_acc_step=0.557, val_loss_step=0.169, val_acc_step=0.581, val_loss_epoch=0.166, val_acc_epoch=0.602, train_loss_epoch=0.176, train_acc_epoch=0.552]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 28:  97%|█████████▋| 30/31 [00:02<00:00, 10.87it/s, v_num=494, train_loss_step=0.167, train_acc_step=0.597, val_loss_step=0.165, val_acc_step=0.593, val_loss_epoch=0.162, val_acc_epoch=0.617, train_loss_epoch=0.173, train_acc_epoch=0.565]Adjusting learning rate of group 0 to 1.3804e-03.\n",
      "Epoch 29:  97%|█████████▋| 30/31 [00:02<00:00, 10.57it/s, v_num=494, train_loss_step=0.165, train_acc_step=0.596, val_loss_step=0.160, val_acc_step=0.606, val_loss_epoch=0.157, val_acc_epoch=0.630, train_loss_epoch=0.168, train_acc_epoch=0.586]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 30:  97%|█████████▋| 30/31 [00:02<00:00, 10.64it/s, v_num=494, train_loss_step=0.161, train_acc_step=0.614, val_loss_step=0.157, val_acc_step=0.621, val_loss_epoch=0.155, val_acc_epoch=0.641, train_loss_epoch=0.165, train_acc_epoch=0.593]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 31:  97%|█████████▋| 30/31 [00:03<00:00,  9.41it/s, v_num=494, train_loss_step=0.166, train_acc_step=0.597, val_loss_step=0.156, val_acc_step=0.624, val_loss_epoch=0.153, val_acc_epoch=0.646, train_loss_epoch=0.162, train_acc_epoch=0.609]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 32:  97%|█████████▋| 30/31 [00:02<00:00, 10.70it/s, v_num=494, train_loss_step=0.159, train_acc_step=0.600, val_loss_step=0.156, val_acc_step=0.624, val_loss_epoch=0.154, val_acc_epoch=0.644, train_loss_epoch=0.160, train_acc_epoch=0.614]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 33:  97%|█████████▋| 30/31 [00:02<00:00, 10.37it/s, v_num=494, train_loss_step=0.159, train_acc_step=0.619, val_loss_step=0.153, val_acc_step=0.633, val_loss_epoch=0.151, val_acc_epoch=0.656, train_loss_epoch=0.158, train_acc_epoch=0.623]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 34:  97%|█████████▋| 30/31 [00:02<00:00, 10.49it/s, v_num=494, train_loss_step=0.153, train_acc_step=0.616, val_loss_step=0.151, val_acc_step=0.646, val_loss_epoch=0.149, val_acc_epoch=0.664, train_loss_epoch=0.158, train_acc_epoch=0.623]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 35:  97%|█████████▋| 30/31 [00:02<00:00, 10.00it/s, v_num=494, train_loss_step=0.155, train_acc_step=0.617, val_loss_step=0.150, val_acc_step=0.649, val_loss_epoch=0.148, val_acc_epoch=0.665, train_loss_epoch=0.156, train_acc_epoch=0.628]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 36:  97%|█████████▋| 30/31 [00:03<00:00,  9.95it/s, v_num=494, train_loss_step=0.158, train_acc_step=0.620, val_loss_step=0.149, val_acc_step=0.655, val_loss_epoch=0.147, val_acc_epoch=0.666, train_loss_epoch=0.154, train_acc_epoch=0.636]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 37:  97%|█████████▋| 30/31 [00:02<00:00, 10.44it/s, v_num=494, train_loss_step=0.153, train_acc_step=0.647, val_loss_step=0.148, val_acc_step=0.651, val_loss_epoch=0.147, val_acc_epoch=0.663, train_loss_epoch=0.154, train_acc_epoch=0.638]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 38:  97%|█████████▋| 30/31 [00:02<00:00, 10.77it/s, v_num=494, train_loss_step=0.151, train_acc_step=0.633, val_loss_step=0.147, val_acc_step=0.653, val_loss_epoch=0.145, val_acc_epoch=0.671, train_loss_epoch=0.152, train_acc_epoch=0.642]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 39:  97%|█████████▋| 30/31 [00:02<00:00, 10.52it/s, v_num=494, train_loss_step=0.150, train_acc_step=0.654, val_loss_step=0.145, val_acc_step=0.667, val_loss_epoch=0.143, val_acc_epoch=0.678, train_loss_epoch=0.151, train_acc_epoch=0.647]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 40:  97%|█████████▋| 30/31 [00:02<00:00, 10.18it/s, v_num=494, train_loss_step=0.150, train_acc_step=0.642, val_loss_step=0.143, val_acc_step=0.668, val_loss_epoch=0.142, val_acc_epoch=0.682, train_loss_epoch=0.150, train_acc_epoch=0.651]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 41:  97%|█████████▋| 30/31 [00:03<00:00,  9.19it/s, v_num=494, train_loss_step=0.149, train_acc_step=0.659, val_loss_step=0.143, val_acc_step=0.662, val_loss_epoch=0.142, val_acc_epoch=0.675, train_loss_epoch=0.148, train_acc_epoch=0.656]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 42:  97%|█████████▋| 30/31 [00:02<00:00, 10.95it/s, v_num=494, train_loss_step=0.149, train_acc_step=0.650, val_loss_step=0.141, val_acc_step=0.674, val_loss_epoch=0.140, val_acc_epoch=0.687, train_loss_epoch=0.147, train_acc_epoch=0.657]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 43:  97%|█████████▋| 30/31 [00:02<00:00, 10.34it/s, v_num=494, train_loss_step=0.144, train_acc_step=0.665, val_loss_step=0.141, val_acc_step=0.673, val_loss_epoch=0.139, val_acc_epoch=0.689, train_loss_epoch=0.147, train_acc_epoch=0.656]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 44:  97%|█████████▋| 30/31 [00:02<00:00, 10.52it/s, v_num=494, train_loss_step=0.144, train_acc_step=0.671, val_loss_step=0.141, val_acc_step=0.678, val_loss_epoch=0.138, val_acc_epoch=0.688, train_loss_epoch=0.145, train_acc_epoch=0.666]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 45:  97%|█████████▋| 30/31 [00:02<00:00, 10.87it/s, v_num=494, train_loss_step=0.148, train_acc_step=0.656, val_loss_step=0.139, val_acc_step=0.682, val_loss_epoch=0.137, val_acc_epoch=0.696, train_loss_epoch=0.144, train_acc_epoch=0.669]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 46:  97%|█████████▋| 30/31 [00:02<00:00, 10.60it/s, v_num=494, train_loss_step=0.142, train_acc_step=0.674, val_loss_step=0.140, val_acc_step=0.679, val_loss_epoch=0.138, val_acc_epoch=0.689, train_loss_epoch=0.142, train_acc_epoch=0.673]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 47:  97%|█████████▋| 30/31 [00:02<00:00, 10.54it/s, v_num=494, train_loss_step=0.144, train_acc_step=0.667, val_loss_step=0.137, val_acc_step=0.680, val_loss_epoch=0.135, val_acc_epoch=0.693, train_loss_epoch=0.143, train_acc_epoch=0.674]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 48:  97%|█████████▋| 30/31 [00:02<00:00, 10.59it/s, v_num=494, train_loss_step=0.141, train_acc_step=0.686, val_loss_step=0.136, val_acc_step=0.690, val_loss_epoch=0.133, val_acc_epoch=0.704, train_loss_epoch=0.141, train_acc_epoch=0.676]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 49:  97%|█████████▋| 30/31 [00:02<00:00, 10.52it/s, v_num=494, train_loss_step=0.136, train_acc_step=0.699, val_loss_step=0.135, val_acc_step=0.692, val_loss_epoch=0.132, val_acc_epoch=0.704, train_loss_epoch=0.138, train_acc_epoch=0.688]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 50:  97%|█████████▋| 30/31 [00:02<00:00, 10.45it/s, v_num=494, train_loss_step=0.136, train_acc_step=0.687, val_loss_step=0.133, val_acc_step=0.695, val_loss_epoch=0.131, val_acc_epoch=0.707, train_loss_epoch=0.138, train_acc_epoch=0.689]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 51:  97%|█████████▋| 30/31 [00:03<00:00,  9.17it/s, v_num=494, train_loss_step=0.139, train_acc_step=0.682, val_loss_step=0.134, val_acc_step=0.703, val_loss_epoch=0.131, val_acc_epoch=0.710, train_loss_epoch=0.137, train_acc_epoch=0.693]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 52:  97%|█████████▋| 30/31 [00:02<00:00, 10.36it/s, v_num=494, train_loss_step=0.138, train_acc_step=0.685, val_loss_step=0.132, val_acc_step=0.702, val_loss_epoch=0.130, val_acc_epoch=0.713, train_loss_epoch=0.136, train_acc_epoch=0.694]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 53:  97%|█████████▋| 30/31 [00:03<00:00,  9.87it/s, v_num=494, train_loss_step=0.131, train_acc_step=0.714, val_loss_step=0.131, val_acc_step=0.701, val_loss_epoch=0.128, val_acc_epoch=0.710, train_loss_epoch=0.136, train_acc_epoch=0.698]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 54:  97%|█████████▋| 30/31 [00:03<00:00,  9.66it/s, v_num=494, train_loss_step=0.133, train_acc_step=0.695, val_loss_step=0.130, val_acc_step=0.712, val_loss_epoch=0.127, val_acc_epoch=0.719, train_loss_epoch=0.133, train_acc_epoch=0.702]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 55:  97%|█████████▋| 30/31 [00:03<00:00,  9.51it/s, v_num=494, train_loss_step=0.132, train_acc_step=0.711, val_loss_step=0.129, val_acc_step=0.708, val_loss_epoch=0.127, val_acc_epoch=0.720, train_loss_epoch=0.132, train_acc_epoch=0.708]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 56:  97%|█████████▋| 30/31 [00:03<00:00,  8.24it/s, v_num=494, train_loss_step=0.130, train_acc_step=0.726, val_loss_step=0.128, val_acc_step=0.710, val_loss_epoch=0.126, val_acc_epoch=0.722, train_loss_epoch=0.131, train_acc_epoch=0.712]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 57:  97%|█████████▋| 30/31 [00:02<00:00, 10.29it/s, v_num=494, train_loss_step=0.131, train_acc_step=0.711, val_loss_step=0.127, val_acc_step=0.710, val_loss_epoch=0.125, val_acc_epoch=0.718, train_loss_epoch=0.130, train_acc_epoch=0.715]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 58:  97%|█████████▋| 30/31 [00:03<00:00,  8.82it/s, v_num=494, train_loss_step=0.129, train_acc_step=0.716, val_loss_step=0.127, val_acc_step=0.714, val_loss_epoch=0.125, val_acc_epoch=0.723, train_loss_epoch=0.128, train_acc_epoch=0.716]Adjusting learning rate of group 0 to 6.9019e-04.\n",
      "Epoch 59:  97%|█████████▋| 30/31 [00:02<00:00, 10.30it/s, v_num=494, train_loss_step=0.129, train_acc_step=0.709, val_loss_step=0.126, val_acc_step=0.721, val_loss_epoch=0.124, val_acc_epoch=0.727, train_loss_epoch=0.127, train_acc_epoch=0.719]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 60:  97%|█████████▋| 30/31 [00:03<00:00,  9.40it/s, v_num=494, train_loss_step=0.129, train_acc_step=0.703, val_loss_step=0.126, val_acc_step=0.720, val_loss_epoch=0.124, val_acc_epoch=0.728, train_loss_epoch=0.127, train_acc_epoch=0.719]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 61:  97%|█████████▋| 30/31 [00:03<00:00,  8.97it/s, v_num=494, train_loss_step=0.124, train_acc_step=0.727, val_loss_step=0.126, val_acc_step=0.728, val_loss_epoch=0.123, val_acc_epoch=0.729, train_loss_epoch=0.126, train_acc_epoch=0.725]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 62:  97%|█████████▋| 30/31 [00:03<00:00,  9.59it/s, v_num=494, train_loss_step=0.128, train_acc_step=0.723, val_loss_step=0.125, val_acc_step=0.731, val_loss_epoch=0.123, val_acc_epoch=0.730, train_loss_epoch=0.125, train_acc_epoch=0.726]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 63:  97%|█████████▋| 30/31 [00:02<00:00, 10.05it/s, v_num=494, train_loss_step=0.122, train_acc_step=0.743, val_loss_step=0.124, val_acc_step=0.729, val_loss_epoch=0.122, val_acc_epoch=0.732, train_loss_epoch=0.125, train_acc_epoch=0.728]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 64:  97%|█████████▋| 30/31 [00:02<00:00, 11.34it/s, v_num=494, train_loss_step=0.125, train_acc_step=0.720, val_loss_step=0.123, val_acc_step=0.726, val_loss_epoch=0.121, val_acc_epoch=0.733, train_loss_epoch=0.124, train_acc_epoch=0.729]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 65:  97%|█████████▋| 30/31 [00:02<00:00, 10.66it/s, v_num=494, train_loss_step=0.125, train_acc_step=0.729, val_loss_step=0.124, val_acc_step=0.731, val_loss_epoch=0.122, val_acc_epoch=0.732, train_loss_epoch=0.124, train_acc_epoch=0.733]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 66:  97%|█████████▋| 30/31 [00:02<00:00, 10.25it/s, v_num=494, train_loss_step=0.124, train_acc_step=0.722, val_loss_step=0.123, val_acc_step=0.729, val_loss_epoch=0.121, val_acc_epoch=0.733, train_loss_epoch=0.123, train_acc_epoch=0.734]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 67:  97%|█████████▋| 30/31 [00:02<00:00, 10.42it/s, v_num=494, train_loss_step=0.124, train_acc_step=0.729, val_loss_step=0.123, val_acc_step=0.726, val_loss_epoch=0.121, val_acc_epoch=0.731, train_loss_epoch=0.123, train_acc_epoch=0.734]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 68:  97%|█████████▋| 30/31 [00:03<00:00,  9.86it/s, v_num=494, train_loss_step=0.123, train_acc_step=0.731, val_loss_step=0.122, val_acc_step=0.732, val_loss_epoch=0.120, val_acc_epoch=0.737, train_loss_epoch=0.122, train_acc_epoch=0.738]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 69:  97%|█████████▋| 30/31 [00:02<00:00, 10.23it/s, v_num=494, train_loss_step=0.122, train_acc_step=0.742, val_loss_step=0.122, val_acc_step=0.729, val_loss_epoch=0.120, val_acc_epoch=0.737, train_loss_epoch=0.121, train_acc_epoch=0.739]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 70:  97%|█████████▋| 30/31 [00:02<00:00, 10.45it/s, v_num=494, train_loss_step=0.122, train_acc_step=0.749, val_loss_step=0.122, val_acc_step=0.736, val_loss_epoch=0.120, val_acc_epoch=0.738, train_loss_epoch=0.121, train_acc_epoch=0.739]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 71:  97%|█████████▋| 30/31 [00:03<00:00,  9.43it/s, v_num=494, train_loss_step=0.120, train_acc_step=0.741, val_loss_step=0.122, val_acc_step=0.730, val_loss_epoch=0.120, val_acc_epoch=0.737, train_loss_epoch=0.122, train_acc_epoch=0.738]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 72:  97%|█████████▋| 30/31 [00:02<00:00, 10.63it/s, v_num=494, train_loss_step=0.118, train_acc_step=0.741, val_loss_step=0.123, val_acc_step=0.729, val_loss_epoch=0.120, val_acc_epoch=0.731, train_loss_epoch=0.120, train_acc_epoch=0.740]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 73:  97%|█████████▋| 30/31 [00:03<00:00,  9.58it/s, v_num=494, train_loss_step=0.122, train_acc_step=0.741, val_loss_step=0.122, val_acc_step=0.730, val_loss_epoch=0.120, val_acc_epoch=0.733, train_loss_epoch=0.120, train_acc_epoch=0.742]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 74:  97%|█████████▋| 30/31 [00:02<00:00, 10.47it/s, v_num=494, train_loss_step=0.119, train_acc_step=0.735, val_loss_step=0.122, val_acc_step=0.727, val_loss_epoch=0.119, val_acc_epoch=0.733, train_loss_epoch=0.120, train_acc_epoch=0.740]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 75:  97%|█████████▋| 30/31 [00:02<00:00, 10.35it/s, v_num=494, train_loss_step=0.119, train_acc_step=0.738, val_loss_step=0.121, val_acc_step=0.728, val_loss_epoch=0.119, val_acc_epoch=0.736, train_loss_epoch=0.119, train_acc_epoch=0.747]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 76:  97%|█████████▋| 30/31 [00:03<00:00,  9.61it/s, v_num=494, train_loss_step=0.119, train_acc_step=0.742, val_loss_step=0.123, val_acc_step=0.722, val_loss_epoch=0.120, val_acc_epoch=0.728, train_loss_epoch=0.119, train_acc_epoch=0.747]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 77:  97%|█████████▋| 30/31 [00:02<00:00, 10.96it/s, v_num=494, train_loss_step=0.117, train_acc_step=0.747, val_loss_step=0.122, val_acc_step=0.725, val_loss_epoch=0.119, val_acc_epoch=0.732, train_loss_epoch=0.118, train_acc_epoch=0.747]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 78:  97%|█████████▋| 30/31 [00:03<00:00,  9.24it/s, v_num=494, train_loss_step=0.117, train_acc_step=0.744, val_loss_step=0.121, val_acc_step=0.726, val_loss_epoch=0.119, val_acc_epoch=0.735, train_loss_epoch=0.117, train_acc_epoch=0.751]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 79:  97%|█████████▋| 30/31 [00:03<00:00,  9.82it/s, v_num=494, train_loss_step=0.117, train_acc_step=0.734, val_loss_step=0.121, val_acc_step=0.722, val_loss_epoch=0.119, val_acc_epoch=0.736, train_loss_epoch=0.117, train_acc_epoch=0.748]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 80:  97%|█████████▋| 30/31 [00:02<00:00, 10.43it/s, v_num=494, train_loss_step=0.118, train_acc_step=0.745, val_loss_step=0.121, val_acc_step=0.728, val_loss_epoch=0.118, val_acc_epoch=0.737, train_loss_epoch=0.116, train_acc_epoch=0.753]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 81:  97%|█████████▋| 30/31 [00:03<00:00,  9.94it/s, v_num=494, train_loss_step=0.115, train_acc_step=0.761, val_loss_step=0.121, val_acc_step=0.729, val_loss_epoch=0.118, val_acc_epoch=0.736, train_loss_epoch=0.116, train_acc_epoch=0.753]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 82:  97%|█████████▋| 30/31 [00:02<00:00, 10.26it/s, v_num=494, train_loss_step=0.116, train_acc_step=0.756, val_loss_step=0.119, val_acc_step=0.734, val_loss_epoch=0.117, val_acc_epoch=0.743, train_loss_epoch=0.116, train_acc_epoch=0.757]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 83:  97%|█████████▋| 30/31 [00:03<00:00,  9.98it/s, v_num=494, train_loss_step=0.117, train_acc_step=0.748, val_loss_step=0.119, val_acc_step=0.731, val_loss_epoch=0.117, val_acc_epoch=0.740, train_loss_epoch=0.115, train_acc_epoch=0.761]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 84:  97%|█████████▋| 30/31 [00:02<00:00, 10.61it/s, v_num=494, train_loss_step=0.113, train_acc_step=0.764, val_loss_step=0.119, val_acc_step=0.736, val_loss_epoch=0.117, val_acc_epoch=0.739, train_loss_epoch=0.114, train_acc_epoch=0.760]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 85:  97%|█████████▋| 30/31 [00:02<00:00, 10.81it/s, v_num=494, train_loss_step=0.115, train_acc_step=0.750, val_loss_step=0.119, val_acc_step=0.738, val_loss_epoch=0.117, val_acc_epoch=0.744, train_loss_epoch=0.115, train_acc_epoch=0.759]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 86:  97%|█████████▋| 30/31 [00:02<00:00, 10.12it/s, v_num=494, train_loss_step=0.117, train_acc_step=0.742, val_loss_step=0.119, val_acc_step=0.732, val_loss_epoch=0.117, val_acc_epoch=0.740, train_loss_epoch=0.114, train_acc_epoch=0.758]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 87:  97%|█████████▋| 30/31 [00:03<00:00,  9.92it/s, v_num=494, train_loss_step=0.116, train_acc_step=0.753, val_loss_step=0.119, val_acc_step=0.735, val_loss_epoch=0.116, val_acc_epoch=0.742, train_loss_epoch=0.113, train_acc_epoch=0.760]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 88:  97%|█████████▋| 30/31 [00:03<00:00,  9.84it/s, v_num=494, train_loss_step=0.116, train_acc_step=0.751, val_loss_step=0.118, val_acc_step=0.739, val_loss_epoch=0.116, val_acc_epoch=0.744, train_loss_epoch=0.112, train_acc_epoch=0.766]Adjusting learning rate of group 0 to 3.4510e-04.\n",
      "Epoch 89:  97%|█████████▋| 30/31 [00:02<00:00, 10.75it/s, v_num=494, train_loss_step=0.112, train_acc_step=0.763, val_loss_step=0.119, val_acc_step=0.725, val_loss_epoch=0.117, val_acc_epoch=0.738, train_loss_epoch=0.113, train_acc_epoch=0.762]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 90:  97%|█████████▋| 30/31 [00:02<00:00, 10.64it/s, v_num=494, train_loss_step=0.112, train_acc_step=0.757, val_loss_step=0.118, val_acc_step=0.735, val_loss_epoch=0.116, val_acc_epoch=0.744, train_loss_epoch=0.112, train_acc_epoch=0.765] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 91:  97%|█████████▋| 30/31 [00:02<00:00, 10.30it/s, v_num=494, train_loss_step=0.113, train_acc_step=0.746, val_loss_step=0.118, val_acc_step=0.736, val_loss_epoch=0.117, val_acc_epoch=0.743, train_loss_epoch=0.111, train_acc_epoch=0.767]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 92:  97%|█████████▋| 30/31 [00:02<00:00, 11.23it/s, v_num=494, train_loss_step=0.115, train_acc_step=0.758, val_loss_step=0.117, val_acc_step=0.740, val_loss_epoch=0.116, val_acc_epoch=0.743, train_loss_epoch=0.112, train_acc_epoch=0.764]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 93:  97%|█████████▋| 30/31 [00:03<00:00,  9.58it/s, v_num=494, train_loss_step=0.110, train_acc_step=0.770, val_loss_step=0.117, val_acc_step=0.746, val_loss_epoch=0.116, val_acc_epoch=0.745, train_loss_epoch=0.111, train_acc_epoch=0.767]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 94:  97%|█████████▋| 30/31 [00:02<00:00, 10.33it/s, v_num=494, train_loss_step=0.114, train_acc_step=0.762, val_loss_step=0.117, val_acc_step=0.747, val_loss_epoch=0.116, val_acc_epoch=0.743, train_loss_epoch=0.110, train_acc_epoch=0.768]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 95:  97%|█████████▋| 30/31 [00:03<00:00,  9.30it/s, v_num=494, train_loss_step=0.112, train_acc_step=0.764, val_loss_step=0.117, val_acc_step=0.741, val_loss_epoch=0.115, val_acc_epoch=0.745, train_loss_epoch=0.110, train_acc_epoch=0.772]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 96:  97%|█████████▋| 30/31 [00:02<00:00, 10.00it/s, v_num=494, train_loss_step=0.111, train_acc_step=0.757, val_loss_step=0.117, val_acc_step=0.747, val_loss_epoch=0.115, val_acc_epoch=0.747, train_loss_epoch=0.109, train_acc_epoch=0.773]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 97:  97%|█████████▋| 30/31 [00:03<00:00,  9.80it/s, v_num=494, train_loss_step=0.107, train_acc_step=0.785, val_loss_step=0.117, val_acc_step=0.748, val_loss_epoch=0.115, val_acc_epoch=0.748, train_loss_epoch=0.111, train_acc_epoch=0.770]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 98:  97%|█████████▋| 30/31 [00:03<00:00,  9.86it/s, v_num=494, train_loss_step=0.110, train_acc_step=0.765, val_loss_step=0.117, val_acc_step=0.749, val_loss_epoch=0.115, val_acc_epoch=0.748, train_loss_epoch=0.110, train_acc_epoch=0.770]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 99:  97%|█████████▋| 30/31 [00:02<00:00, 10.87it/s, v_num=494, train_loss_step=0.109, train_acc_step=0.777, val_loss_step=0.117, val_acc_step=0.743, val_loss_epoch=0.115, val_acc_epoch=0.745, train_loss_epoch=0.110, train_acc_epoch=0.773]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 100:  97%|█████████▋| 30/31 [00:03<00:00,  9.31it/s, v_num=494, train_loss_step=0.110, train_acc_step=0.771, val_loss_step=0.116, val_acc_step=0.748, val_loss_epoch=0.115, val_acc_epoch=0.749, train_loss_epoch=0.109, train_acc_epoch=0.772]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 101:  97%|█████████▋| 30/31 [00:02<00:00, 10.11it/s, v_num=494, train_loss_step=0.111, train_acc_step=0.771, val_loss_step=0.117, val_acc_step=0.748, val_loss_epoch=0.115, val_acc_epoch=0.747, train_loss_epoch=0.110, train_acc_epoch=0.772]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 102:  97%|█████████▋| 30/31 [00:02<00:00, 10.72it/s, v_num=494, train_loss_step=0.108, train_acc_step=0.789, val_loss_step=0.117, val_acc_step=0.745, val_loss_epoch=0.115, val_acc_epoch=0.745, train_loss_epoch=0.109, train_acc_epoch=0.775] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 103:  97%|█████████▋| 30/31 [00:03<00:00,  9.86it/s, v_num=494, train_loss_step=0.111, train_acc_step=0.766, val_loss_step=0.116, val_acc_step=0.749, val_loss_epoch=0.115, val_acc_epoch=0.747, train_loss_epoch=0.109, train_acc_epoch=0.775]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 104:  97%|█████████▋| 30/31 [00:03<00:00,  8.63it/s, v_num=494, train_loss_step=0.109, train_acc_step=0.771, val_loss_step=0.116, val_acc_step=0.747, val_loss_epoch=0.115, val_acc_epoch=0.747, train_loss_epoch=0.108, train_acc_epoch=0.777] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 105:  97%|█████████▋| 30/31 [00:03<00:00,  9.13it/s, v_num=494, train_loss_step=0.110, train_acc_step=0.770, val_loss_step=0.117, val_acc_step=0.746, val_loss_epoch=0.115, val_acc_epoch=0.746, train_loss_epoch=0.108, train_acc_epoch=0.778]Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 106:  97%|█████████▋| 30/31 [00:03<00:00,  9.75it/s, v_num=494, train_loss_step=0.109, train_acc_step=0.777, val_loss_step=0.116, val_acc_step=0.749, val_loss_epoch=0.114, val_acc_epoch=0.746, train_loss_epoch=0.108, train_acc_epoch=0.779] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 107:  97%|█████████▋| 30/31 [00:03<00:00,  9.84it/s, v_num=494, train_loss_step=0.107, train_acc_step=0.769, val_loss_step=0.116, val_acc_step=0.748, val_loss_epoch=0.114, val_acc_epoch=0.748, train_loss_epoch=0.107, train_acc_epoch=0.779] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 108:  97%|█████████▋| 30/31 [00:03<00:00,  9.19it/s, v_num=494, train_loss_step=0.110, train_acc_step=0.760, val_loss_step=0.116, val_acc_step=0.749, val_loss_epoch=0.114, val_acc_epoch=0.749, train_loss_epoch=0.107, train_acc_epoch=0.778] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 109:  97%|█████████▋| 30/31 [00:03<00:00,  9.44it/s, v_num=494, train_loss_step=0.109, train_acc_step=0.772, val_loss_step=0.116, val_acc_step=0.749, val_loss_epoch=0.114, val_acc_epoch=0.748, train_loss_epoch=0.107, train_acc_epoch=0.778] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 110:  97%|█████████▋| 30/31 [00:03<00:00,  8.47it/s, v_num=494, train_loss_step=0.109, train_acc_step=0.768, val_loss_step=0.116, val_acc_step=0.747, val_loss_epoch=0.114, val_acc_epoch=0.748, train_loss_epoch=0.106, train_acc_epoch=0.783] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 111:  97%|█████████▋| 30/31 [00:02<00:00, 10.70it/s, v_num=494, train_loss_step=0.108, train_acc_step=0.772, val_loss_step=0.116, val_acc_step=0.746, val_loss_epoch=0.114, val_acc_epoch=0.747, train_loss_epoch=0.107, train_acc_epoch=0.782] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 112:  97%|█████████▋| 30/31 [00:03<00:00,  9.87it/s, v_num=494, train_loss_step=0.111, train_acc_step=0.759, val_loss_step=0.115, val_acc_step=0.747, val_loss_epoch=0.114, val_acc_epoch=0.748, train_loss_epoch=0.107, train_acc_epoch=0.780] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 113:  97%|█████████▋| 30/31 [00:03<00:00,  9.36it/s, v_num=494, train_loss_step=0.108, train_acc_step=0.772, val_loss_step=0.115, val_acc_step=0.749, val_loss_epoch=0.114, val_acc_epoch=0.751, train_loss_epoch=0.107, train_acc_epoch=0.780] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 114:  97%|█████████▋| 30/31 [00:03<00:00,  9.54it/s, v_num=494, train_loss_step=0.108, train_acc_step=0.774, val_loss_step=0.115, val_acc_step=0.746, val_loss_epoch=0.114, val_acc_epoch=0.748, train_loss_epoch=0.106, train_acc_epoch=0.780] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 115:  97%|█████████▋| 30/31 [00:03<00:00,  9.72it/s, v_num=494, train_loss_step=0.108, train_acc_step=0.771, val_loss_step=0.115, val_acc_step=0.749, val_loss_epoch=0.114, val_acc_epoch=0.749, train_loss_epoch=0.106, train_acc_epoch=0.783] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 116:  97%|█████████▋| 30/31 [00:02<00:00, 10.03it/s, v_num=494, train_loss_step=0.106, train_acc_step=0.772, val_loss_step=0.115, val_acc_step=0.747, val_loss_epoch=0.114, val_acc_epoch=0.749, train_loss_epoch=0.106, train_acc_epoch=0.783] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 117:  97%|█████████▋| 30/31 [00:02<00:00, 10.11it/s, v_num=494, train_loss_step=0.107, train_acc_step=0.777, val_loss_step=0.115, val_acc_step=0.746, val_loss_epoch=0.113, val_acc_epoch=0.750, train_loss_epoch=0.105, train_acc_epoch=0.787] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 118:  97%|█████████▋| 30/31 [00:03<00:00,  9.37it/s, v_num=494, train_loss_step=0.106, train_acc_step=0.771, val_loss_step=0.115, val_acc_step=0.748, val_loss_epoch=0.113, val_acc_epoch=0.751, train_loss_epoch=0.105, train_acc_epoch=0.784] Adjusting learning rate of group 0 to 1.7255e-04.\n",
      "Epoch 119:  97%|█████████▋| 30/31 [00:03<00:00,  9.99it/s, v_num=494, train_loss_step=0.109, train_acc_step=0.769, val_loss_step=0.115, val_acc_step=0.751, val_loss_epoch=0.114, val_acc_epoch=0.751, train_loss_epoch=0.105, train_acc_epoch=0.786] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 120:  97%|█████████▋| 30/31 [00:03<00:00,  9.29it/s, v_num=494, train_loss_step=0.107, train_acc_step=0.777, val_loss_step=0.115, val_acc_step=0.749, val_loss_epoch=0.113, val_acc_epoch=0.751, train_loss_epoch=0.105, train_acc_epoch=0.786] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 121:  97%|█████████▋| 30/31 [00:02<00:00, 11.01it/s, v_num=494, train_loss_step=0.107, train_acc_step=0.774, val_loss_step=0.115, val_acc_step=0.748, val_loss_epoch=0.113, val_acc_epoch=0.752, train_loss_epoch=0.104, train_acc_epoch=0.787] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 122:  97%|█████████▋| 30/31 [00:02<00:00, 11.56it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.783, val_loss_step=0.115, val_acc_step=0.751, val_loss_epoch=0.113, val_acc_epoch=0.755, train_loss_epoch=0.105, train_acc_epoch=0.787] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 123:  97%|█████████▋| 30/31 [00:03<00:00,  9.98it/s, v_num=494, train_loss_step=0.104, train_acc_step=0.774, val_loss_step=0.114, val_acc_step=0.748, val_loss_epoch=0.112, val_acc_epoch=0.752, train_loss_epoch=0.103, train_acc_epoch=0.791] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 124:  97%|█████████▋| 30/31 [00:02<00:00, 10.78it/s, v_num=494, train_loss_step=0.106, train_acc_step=0.771, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.753, train_loss_epoch=0.104, train_acc_epoch=0.790] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 125:  97%|█████████▋| 30/31 [00:03<00:00,  9.79it/s, v_num=494, train_loss_step=0.110, train_acc_step=0.763, val_loss_step=0.115, val_acc_step=0.754, val_loss_epoch=0.113, val_acc_epoch=0.757, train_loss_epoch=0.104, train_acc_epoch=0.793] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 126:  97%|█████████▋| 30/31 [00:02<00:00, 11.57it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.774, val_loss_step=0.114, val_acc_step=0.751, val_loss_epoch=0.112, val_acc_epoch=0.753, train_loss_epoch=0.104, train_acc_epoch=0.790] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 127:  97%|█████████▋| 30/31 [00:02<00:00, 10.64it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.779, val_loss_step=0.115, val_acc_step=0.752, val_loss_epoch=0.113, val_acc_epoch=0.756, train_loss_epoch=0.103, train_acc_epoch=0.790] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 128:  97%|█████████▋| 30/31 [00:02<00:00, 11.00it/s, v_num=494, train_loss_step=0.104, train_acc_step=0.784, val_loss_step=0.114, val_acc_step=0.750, val_loss_epoch=0.112, val_acc_epoch=0.752, train_loss_epoch=0.103, train_acc_epoch=0.790] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 129:  97%|█████████▋| 30/31 [00:02<00:00, 11.44it/s, v_num=494, train_loss_step=0.108, train_acc_step=0.784, val_loss_step=0.114, val_acc_step=0.748, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.103, train_acc_epoch=0.789] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 130:  97%|█████████▋| 30/31 [00:03<00:00,  9.35it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.782, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.103, train_acc_epoch=0.791] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 131:  97%|█████████▋| 30/31 [00:02<00:00, 10.19it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.789, val_loss_step=0.114, val_acc_step=0.753, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.103, train_acc_epoch=0.791] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 132:  97%|█████████▋| 30/31 [00:02<00:00, 11.02it/s, v_num=494, train_loss_step=0.102, train_acc_step=0.793, val_loss_step=0.114, val_acc_step=0.750, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.103, train_acc_epoch=0.791] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 133:  97%|█████████▋| 30/31 [00:02<00:00, 10.34it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.786, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.103, train_acc_epoch=0.793] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 134:  97%|█████████▋| 30/31 [00:02<00:00, 10.29it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.777, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.102, train_acc_epoch=0.792] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 135:  97%|█████████▋| 30/31 [00:03<00:00,  9.07it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.790, val_loss_step=0.114, val_acc_step=0.752, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.102, train_acc_epoch=0.793] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 136:  97%|█████████▋| 30/31 [00:02<00:00, 10.69it/s, v_num=494, train_loss_step=0.105, train_acc_step=0.795, val_loss_step=0.114, val_acc_step=0.748, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.103, train_acc_epoch=0.793] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 137:  97%|█████████▋| 30/31 [00:03<00:00,  9.12it/s, v_num=494, train_loss_step=0.106, train_acc_step=0.776, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.102, train_acc_epoch=0.795] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 138:  97%|█████████▋| 30/31 [00:02<00:00, 10.06it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.784, val_loss_step=0.114, val_acc_step=0.750, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.102, train_acc_epoch=0.793] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 139:  97%|█████████▋| 30/31 [00:02<00:00, 10.21it/s, v_num=494, train_loss_step=0.102, train_acc_step=0.800, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.102, train_acc_epoch=0.795] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 140:  97%|█████████▋| 30/31 [00:03<00:00,  9.38it/s, v_num=494, train_loss_step=0.104, train_acc_step=0.779, val_loss_step=0.114, val_acc_step=0.752, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.102, train_acc_epoch=0.793] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 141:  97%|█████████▋| 30/31 [00:03<00:00,  9.48it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.786, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.102, train_acc_epoch=0.794] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 142:  97%|█████████▋| 30/31 [00:03<00:00,  7.81it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.788, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.753, train_loss_epoch=0.102, train_acc_epoch=0.796] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 143:  97%|█████████▋| 30/31 [00:02<00:00, 10.76it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.780, val_loss_step=0.114, val_acc_step=0.751, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.102, train_acc_epoch=0.794] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 144:  97%|█████████▋| 30/31 [00:03<00:00,  9.63it/s, v_num=494, train_loss_step=0.104, train_acc_step=0.787, val_loss_step=0.114, val_acc_step=0.751, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.101, train_acc_epoch=0.797] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 145:  97%|█████████▋| 30/31 [00:03<00:00,  7.80it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.794, val_loss_step=0.114, val_acc_step=0.753, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.101, train_acc_epoch=0.796] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 146:  97%|█████████▋| 30/31 [00:03<00:00,  9.74it/s, v_num=494, train_loss_step=0.104, train_acc_step=0.784, val_loss_step=0.114, val_acc_step=0.753, val_loss_epoch=0.112, val_acc_epoch=0.753, train_loss_epoch=0.102, train_acc_epoch=0.796] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 147:  97%|█████████▋| 30/31 [00:03<00:00,  8.39it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.792, val_loss_step=0.114, val_acc_step=0.753, val_loss_epoch=0.112, val_acc_epoch=0.755, train_loss_epoch=0.100, train_acc_epoch=0.800] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 148:  97%|█████████▋| 30/31 [00:03<00:00,  8.54it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.799, val_loss_step=0.114, val_acc_step=0.753, val_loss_epoch=0.111, val_acc_epoch=0.755, train_loss_epoch=0.101, train_acc_epoch=0.798] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 149:  97%|█████████▋| 30/31 [00:02<00:00, 10.04it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.782, val_loss_step=0.113, val_acc_step=0.751, val_loss_epoch=0.111, val_acc_epoch=0.755, train_loss_epoch=0.101, train_acc_epoch=0.798] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 150:  97%|█████████▋| 30/31 [00:03<00:00,  9.91it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.793, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.112, val_acc_epoch=0.754, train_loss_epoch=0.100, train_acc_epoch=0.802] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 151:  97%|█████████▋| 30/31 [00:03<00:00,  9.83it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.792, val_loss_step=0.114, val_acc_step=0.752, val_loss_epoch=0.111, val_acc_epoch=0.755, train_loss_epoch=0.100, train_acc_epoch=0.800] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 152:  97%|█████████▋| 30/31 [00:03<00:00,  8.22it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.787, val_loss_step=0.113, val_acc_step=0.755, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.101, train_acc_epoch=0.799] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 153:  97%|█████████▋| 30/31 [00:03<00:00,  9.20it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.786, val_loss_step=0.114, val_acc_step=0.750, val_loss_epoch=0.112, val_acc_epoch=0.756, train_loss_epoch=0.100, train_acc_epoch=0.799] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 154:  97%|█████████▋| 30/31 [00:03<00:00,  9.67it/s, v_num=494, train_loss_step=0.104, train_acc_step=0.790, val_loss_step=0.113, val_acc_step=0.755, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.100, train_acc_epoch=0.799] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 155:  97%|█████████▋| 30/31 [00:02<00:00, 10.08it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.786, val_loss_step=0.113, val_acc_step=0.751, val_loss_epoch=0.111, val_acc_epoch=0.755, train_loss_epoch=0.0997, train_acc_epoch=0.802] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 156:  97%|█████████▋| 30/31 [00:02<00:00, 10.16it/s, v_num=494, train_loss_step=0.0993, train_acc_step=0.791, val_loss_step=0.113, val_acc_step=0.753, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.100, train_acc_epoch=0.799] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 157:  97%|█████████▋| 30/31 [00:03<00:00,  8.84it/s, v_num=494, train_loss_step=0.102, train_acc_step=0.800, val_loss_step=0.113, val_acc_step=0.752, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.100, train_acc_epoch=0.800] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 158:  97%|█████████▋| 30/31 [00:02<00:00, 10.25it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.800, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.758, train_loss_epoch=0.0995, train_acc_epoch=0.802] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 159:  97%|█████████▋| 30/31 [00:02<00:00, 10.47it/s, v_num=494, train_loss_step=0.100, train_acc_step=0.780, val_loss_step=0.114, val_acc_step=0.749, val_loss_epoch=0.111, val_acc_epoch=0.753, train_loss_epoch=0.0992, train_acc_epoch=0.800] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 160:  97%|█████████▋| 30/31 [00:03<00:00,  9.35it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.794, val_loss_step=0.113, val_acc_step=0.752, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.0993, train_acc_epoch=0.803] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 161:  97%|█████████▋| 30/31 [00:03<00:00, 10.00it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.780, val_loss_step=0.113, val_acc_step=0.750, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.0989, train_acc_epoch=0.802] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 162:  97%|█████████▋| 30/31 [00:03<00:00,  9.76it/s, v_num=494, train_loss_step=0.100, train_acc_step=0.796, val_loss_step=0.113, val_acc_step=0.751, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.0987, train_acc_epoch=0.803] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 163:  97%|█████████▋| 30/31 [00:02<00:00, 10.54it/s, v_num=494, train_loss_step=0.103, train_acc_step=0.786, val_loss_step=0.113, val_acc_step=0.755, val_loss_epoch=0.111, val_acc_epoch=0.759, train_loss_epoch=0.0989, train_acc_epoch=0.802] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 164:  97%|█████████▋| 30/31 [00:03<00:00,  9.95it/s, v_num=494, train_loss_step=0.0991, train_acc_step=0.793, val_loss_step=0.113, val_acc_step=0.753, val_loss_epoch=0.111, val_acc_epoch=0.755, train_loss_epoch=0.0989, train_acc_epoch=0.803]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 165:  97%|█████████▋| 30/31 [00:03<00:00,  9.04it/s, v_num=494, train_loss_step=0.102, train_acc_step=0.787, val_loss_step=0.113, val_acc_step=0.751, val_loss_epoch=0.111, val_acc_epoch=0.758, train_loss_epoch=0.0987, train_acc_epoch=0.805] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 166:  97%|█████████▋| 30/31 [00:02<00:00, 10.22it/s, v_num=494, train_loss_step=0.102, train_acc_step=0.799, val_loss_step=0.113, val_acc_step=0.753, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.0985, train_acc_epoch=0.805] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 167:  97%|█████████▋| 30/31 [00:03<00:00,  9.59it/s, v_num=494, train_loss_step=0.100, train_acc_step=0.795, val_loss_step=0.113, val_acc_step=0.752, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.0983, train_acc_epoch=0.804] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 168:  97%|█████████▋| 30/31 [00:02<00:00, 10.05it/s, v_num=494, train_loss_step=0.0987, train_acc_step=0.793, val_loss_step=0.113, val_acc_step=0.750, val_loss_epoch=0.111, val_acc_epoch=0.758, train_loss_epoch=0.0981, train_acc_epoch=0.805]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 169:  97%|█████████▋| 30/31 [00:02<00:00, 10.76it/s, v_num=494, train_loss_step=0.0959, train_acc_step=0.799, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.758, train_loss_epoch=0.0979, train_acc_epoch=0.805]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 170:  97%|█████████▋| 30/31 [00:02<00:00, 10.04it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.796, val_loss_step=0.113, val_acc_step=0.753, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.0981, train_acc_epoch=0.802] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 171:  97%|█████████▋| 30/31 [00:02<00:00, 10.27it/s, v_num=494, train_loss_step=0.099, train_acc_step=0.803, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.0978, train_acc_epoch=0.806] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 172:  97%|█████████▋| 30/31 [00:03<00:00,  9.78it/s, v_num=494, train_loss_step=0.0975, train_acc_step=0.800, val_loss_step=0.113, val_acc_step=0.755, val_loss_epoch=0.111, val_acc_epoch=0.759, train_loss_epoch=0.0985, train_acc_epoch=0.804]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 173:  97%|█████████▋| 30/31 [00:02<00:00, 10.19it/s, v_num=494, train_loss_step=0.101, train_acc_step=0.789, val_loss_step=0.113, val_acc_step=0.753, val_loss_epoch=0.110, val_acc_epoch=0.756, train_loss_epoch=0.0972, train_acc_epoch=0.806] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 174:  97%|█████████▋| 30/31 [00:02<00:00, 10.07it/s, v_num=494, train_loss_step=0.099, train_acc_step=0.807, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.760, train_loss_epoch=0.0979, train_acc_epoch=0.806] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 175:  97%|█████████▋| 30/31 [00:03<00:00,  9.45it/s, v_num=494, train_loss_step=0.0995, train_acc_step=0.790, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.0973, train_acc_epoch=0.807]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 176:  97%|█████████▋| 30/31 [00:02<00:00, 10.15it/s, v_num=494, train_loss_step=0.0994, train_acc_step=0.800, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.757, train_loss_epoch=0.0972, train_acc_epoch=0.806]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 177:  97%|█████████▋| 30/31 [00:03<00:00,  9.38it/s, v_num=494, train_loss_step=0.0985, train_acc_step=0.810, val_loss_step=0.113, val_acc_step=0.750, val_loss_epoch=0.111, val_acc_epoch=0.756, train_loss_epoch=0.0973, train_acc_epoch=0.806]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 178:  97%|█████████▋| 30/31 [00:02<00:00, 10.32it/s, v_num=494, train_loss_step=0.102, train_acc_step=0.795, val_loss_step=0.113, val_acc_step=0.747, val_loss_epoch=0.111, val_acc_epoch=0.754, train_loss_epoch=0.0977, train_acc_epoch=0.806] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 179:  97%|█████████▋| 30/31 [00:03<00:00,  9.38it/s, v_num=494, train_loss_step=0.097, train_acc_step=0.799, val_loss_step=0.113, val_acc_step=0.753, val_loss_epoch=0.110, val_acc_epoch=0.758, train_loss_epoch=0.0975, train_acc_epoch=0.807] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 180:  97%|█████████▋| 30/31 [00:02<00:00, 10.43it/s, v_num=494, train_loss_step=0.0985, train_acc_step=0.789, val_loss_step=0.113, val_acc_step=0.757, val_loss_epoch=0.111, val_acc_epoch=0.760, train_loss_epoch=0.0966, train_acc_epoch=0.809]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 181:  97%|█████████▋| 30/31 [00:03<00:00,  8.33it/s, v_num=494, train_loss_step=0.0982, train_acc_step=0.791, val_loss_step=0.113, val_acc_step=0.751, val_loss_epoch=0.111, val_acc_epoch=0.758, train_loss_epoch=0.0963, train_acc_epoch=0.810]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 182:  97%|█████████▋| 30/31 [00:03<00:00,  8.06it/s, v_num=494, train_loss_step=0.0943, train_acc_step=0.817, val_loss_step=0.112, val_acc_step=0.754, val_loss_epoch=0.110, val_acc_epoch=0.757, train_loss_epoch=0.0966, train_acc_epoch=0.809]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 183:  97%|█████████▋| 30/31 [00:03<00:00,  9.20it/s, v_num=494, train_loss_step=0.0976, train_acc_step=0.800, val_loss_step=0.113, val_acc_step=0.756, val_loss_epoch=0.111, val_acc_epoch=0.759, train_loss_epoch=0.0966, train_acc_epoch=0.810]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 184:  97%|█████████▋| 30/31 [00:03<00:00,  9.83it/s, v_num=494, train_loss_step=0.0968, train_acc_step=0.806, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.110, val_acc_epoch=0.757, train_loss_epoch=0.0961, train_acc_epoch=0.810]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 185:  97%|█████████▋| 30/31 [00:03<00:00,  8.67it/s, v_num=494, train_loss_step=0.097, train_acc_step=0.817, val_loss_step=0.112, val_acc_step=0.755, val_loss_epoch=0.110, val_acc_epoch=0.757, train_loss_epoch=0.0962, train_acc_epoch=0.810] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 186:  97%|█████████▋| 30/31 [00:03<00:00,  8.69it/s, v_num=494, train_loss_step=0.0971, train_acc_step=0.805, val_loss_step=0.112, val_acc_step=0.752, val_loss_epoch=0.110, val_acc_epoch=0.756, train_loss_epoch=0.0956, train_acc_epoch=0.813]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 187:  97%|█████████▋| 30/31 [00:03<00:00,  8.55it/s, v_num=494, train_loss_step=0.0992, train_acc_step=0.801, val_loss_step=0.113, val_acc_step=0.754, val_loss_epoch=0.111, val_acc_epoch=0.759, train_loss_epoch=0.0954, train_acc_epoch=0.813]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 188:  97%|█████████▋| 30/31 [00:03<00:00,  9.00it/s, v_num=494, train_loss_step=0.0975, train_acc_step=0.803, val_loss_step=0.112, val_acc_step=0.755, val_loss_epoch=0.110, val_acc_epoch=0.758, train_loss_epoch=0.0956, train_acc_epoch=0.813]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 189:  97%|█████████▋| 30/31 [00:03<00:00,  8.37it/s, v_num=494, train_loss_step=0.100, train_acc_step=0.785, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0953, train_acc_epoch=0.813] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 190:  97%|█████████▋| 30/31 [00:03<00:00,  9.45it/s, v_num=494, train_loss_step=0.0967, train_acc_step=0.812, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0953, train_acc_epoch=0.811]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 191:  97%|█████████▋| 30/31 [00:03<00:00,  8.26it/s, v_num=494, train_loss_step=0.0998, train_acc_step=0.793, val_loss_step=0.112, val_acc_step=0.752, val_loss_epoch=0.111, val_acc_epoch=0.758, train_loss_epoch=0.0956, train_acc_epoch=0.812]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 192:  97%|█████████▋| 30/31 [00:03<00:00,  8.07it/s, v_num=494, train_loss_step=0.0953, train_acc_step=0.812, val_loss_step=0.113, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0952, train_acc_epoch=0.810]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 193:  97%|█████████▋| 30/31 [00:03<00:00,  8.49it/s, v_num=494, train_loss_step=0.0934, train_acc_step=0.820, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.110, val_acc_epoch=0.758, train_loss_epoch=0.0951, train_acc_epoch=0.812]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 194:  97%|█████████▋| 30/31 [00:03<00:00,  7.62it/s, v_num=494, train_loss_step=0.0984, train_acc_step=0.791, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0947, train_acc_epoch=0.815]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 195:  97%|█████████▋| 30/31 [00:03<00:00,  9.76it/s, v_num=494, train_loss_step=0.0967, train_acc_step=0.805, val_loss_step=0.112, val_acc_step=0.754, val_loss_epoch=0.110, val_acc_epoch=0.761, train_loss_epoch=0.0945, train_acc_epoch=0.814]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 196:  97%|█████████▋| 30/31 [00:03<00:00,  9.07it/s, v_num=494, train_loss_step=0.0956, train_acc_step=0.812, val_loss_step=0.112, val_acc_step=0.755, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0944, train_acc_epoch=0.812]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 197:  97%|█████████▋| 30/31 [00:03<00:00,  8.31it/s, v_num=494, train_loss_step=0.0965, train_acc_step=0.797, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0943, train_acc_epoch=0.819]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 198:  97%|█████████▋| 30/31 [00:03<00:00,  8.54it/s, v_num=494, train_loss_step=0.0956, train_acc_step=0.808, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.758, train_loss_epoch=0.0938, train_acc_epoch=0.818]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 199:  97%|█████████▋| 30/31 [00:03<00:00,  8.69it/s, v_num=494, train_loss_step=0.0936, train_acc_step=0.808, val_loss_step=0.112, val_acc_step=0.751, val_loss_epoch=0.110, val_acc_epoch=0.757, train_loss_epoch=0.0936, train_acc_epoch=0.816]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 200:  97%|█████████▋| 30/31 [00:03<00:00,  8.29it/s, v_num=494, train_loss_step=0.0917, train_acc_step=0.809, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.110, val_acc_epoch=0.761, train_loss_epoch=0.0936, train_acc_epoch=0.815]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 201:  97%|█████████▋| 30/31 [00:02<00:00, 10.73it/s, v_num=494, train_loss_step=0.099, train_acc_step=0.804, val_loss_step=0.112, val_acc_step=0.756, val_loss_epoch=0.110, val_acc_epoch=0.758, train_loss_epoch=0.0938, train_acc_epoch=0.816] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 202:  97%|█████████▋| 30/31 [00:04<00:00,  7.32it/s, v_num=494, train_loss_step=0.0942, train_acc_step=0.812, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0938, train_acc_epoch=0.814]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 203:  97%|█████████▋| 30/31 [00:02<00:00, 10.12it/s, v_num=494, train_loss_step=0.0942, train_acc_step=0.814, val_loss_step=0.112, val_acc_step=0.755, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0935, train_acc_epoch=0.817]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 204:  97%|█████████▋| 30/31 [00:03<00:00,  9.08it/s, v_num=494, train_loss_step=0.0943, train_acc_step=0.816, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0932, train_acc_epoch=0.820]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 205:  97%|█████████▋| 30/31 [00:02<00:00, 10.11it/s, v_num=494, train_loss_step=0.0913, train_acc_step=0.824, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0936, train_acc_epoch=0.816]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 206:  97%|█████████▋| 30/31 [00:03<00:00,  9.19it/s, v_num=494, train_loss_step=0.0933, train_acc_step=0.818, val_loss_step=0.112, val_acc_step=0.756, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0933, train_acc_epoch=0.816]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 207:  97%|█████████▋| 30/31 [00:03<00:00,  7.95it/s, v_num=494, train_loss_step=0.0952, train_acc_step=0.810, val_loss_step=0.112, val_acc_step=0.755, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0931, train_acc_epoch=0.818]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 208:  97%|█████████▋| 30/31 [00:03<00:00,  8.13it/s, v_num=494, train_loss_step=0.0931, train_acc_step=0.801, val_loss_step=0.112, val_acc_step=0.754, val_loss_epoch=0.110, val_acc_epoch=0.758, train_loss_epoch=0.0936, train_acc_epoch=0.814]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 209:  97%|█████████▋| 30/31 [00:03<00:00,  8.96it/s, v_num=494, train_loss_step=0.0945, train_acc_step=0.817, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0934, train_acc_epoch=0.816]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 210:  97%|█████████▋| 30/31 [00:03<00:00,  8.05it/s, v_num=494, train_loss_step=0.0953, train_acc_step=0.809, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0924, train_acc_epoch=0.821]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 211:  97%|█████████▋| 30/31 [00:03<00:00,  9.47it/s, v_num=494, train_loss_step=0.0934, train_acc_step=0.812, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0924, train_acc_epoch=0.820]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 212:  97%|█████████▋| 30/31 [00:03<00:00,  7.60it/s, v_num=494, train_loss_step=0.0904, train_acc_step=0.811, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.110, val_acc_epoch=0.761, train_loss_epoch=0.0922, train_acc_epoch=0.822]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 213:  97%|█████████▋| 30/31 [00:03<00:00,  9.76it/s, v_num=494, train_loss_step=0.0963, train_acc_step=0.807, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.110, val_acc_epoch=0.763, train_loss_epoch=0.0922, train_acc_epoch=0.822]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 214:  97%|█████████▋| 30/31 [00:03<00:00,  9.24it/s, v_num=494, train_loss_step=0.0923, train_acc_step=0.818, val_loss_step=0.112, val_acc_step=0.754, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0923, train_acc_epoch=0.819]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 215:  97%|█████████▋| 30/31 [00:03<00:00,  8.29it/s, v_num=494, train_loss_step=0.0919, train_acc_step=0.808, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0922, train_acc_epoch=0.819]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 216:  97%|█████████▋| 30/31 [00:03<00:00,  9.13it/s, v_num=494, train_loss_step=0.0923, train_acc_step=0.825, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0922, train_acc_epoch=0.819]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 217:  97%|█████████▋| 30/31 [00:02<00:00, 10.06it/s, v_num=494, train_loss_step=0.0898, train_acc_step=0.837, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.092, train_acc_epoch=0.821] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 218:  97%|█████████▋| 30/31 [00:03<00:00,  9.88it/s, v_num=494, train_loss_step=0.0888, train_acc_step=0.824, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0914, train_acc_epoch=0.823]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 219:  97%|█████████▋| 30/31 [00:03<00:00,  9.29it/s, v_num=494, train_loss_step=0.0928, train_acc_step=0.820, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0914, train_acc_epoch=0.821]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 220:  97%|█████████▋| 30/31 [00:02<00:00, 10.31it/s, v_num=494, train_loss_step=0.0944, train_acc_step=0.805, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.761, train_loss_epoch=0.0915, train_acc_epoch=0.823]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 221:  97%|█████████▋| 30/31 [00:03<00:00,  8.96it/s, v_num=494, train_loss_step=0.0897, train_acc_step=0.823, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.091, train_acc_epoch=0.824] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 222:  97%|█████████▋| 30/31 [00:03<00:00,  9.83it/s, v_num=494, train_loss_step=0.0935, train_acc_step=0.818, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.760, train_loss_epoch=0.0911, train_acc_epoch=0.825]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 223:  97%|█████████▋| 30/31 [00:03<00:00,  9.56it/s, v_num=494, train_loss_step=0.0943, train_acc_step=0.815, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0904, train_acc_epoch=0.827]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 224:  97%|█████████▋| 30/31 [00:03<00:00,  9.35it/s, v_num=494, train_loss_step=0.0924, train_acc_step=0.825, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0914, train_acc_epoch=0.823]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 225:  97%|█████████▋| 30/31 [00:03<00:00,  8.81it/s, v_num=494, train_loss_step=0.0946, train_acc_step=0.806, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0911, train_acc_epoch=0.823]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 226:  97%|█████████▋| 30/31 [00:03<00:00,  9.54it/s, v_num=494, train_loss_step=0.0938, train_acc_step=0.825, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.759, train_loss_epoch=0.0905, train_acc_epoch=0.824]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 227:  97%|█████████▋| 30/31 [00:03<00:00,  9.85it/s, v_num=494, train_loss_step=0.0923, train_acc_step=0.819, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0903, train_acc_epoch=0.825]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 228:  97%|█████████▋| 30/31 [00:02<00:00, 10.59it/s, v_num=494, train_loss_step=0.0908, train_acc_step=0.814, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0902, train_acc_epoch=0.826]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 229:  97%|█████████▋| 30/31 [00:03<00:00,  9.86it/s, v_num=494, train_loss_step=0.0929, train_acc_step=0.809, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0907, train_acc_epoch=0.826]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 230:  97%|█████████▋| 30/31 [00:03<00:00,  9.76it/s, v_num=494, train_loss_step=0.0915, train_acc_step=0.824, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0905, train_acc_epoch=0.825]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 231:  97%|█████████▋| 30/31 [00:03<00:00,  8.17it/s, v_num=494, train_loss_step=0.0914, train_acc_step=0.815, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.110, val_acc_epoch=0.760, train_loss_epoch=0.0902, train_acc_epoch=0.827]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 232:  97%|█████████▋| 30/31 [00:03<00:00,  9.47it/s, v_num=494, train_loss_step=0.0914, train_acc_step=0.822, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0898, train_acc_epoch=0.826]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 233:  97%|█████████▋| 30/31 [00:03<00:00,  8.97it/s, v_num=494, train_loss_step=0.0919, train_acc_step=0.817, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0902, train_acc_epoch=0.828]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 234:  97%|█████████▋| 30/31 [00:03<00:00,  8.74it/s, v_num=494, train_loss_step=0.0874, train_acc_step=0.828, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0894, train_acc_epoch=0.829]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 235:  97%|█████████▋| 30/31 [00:03<00:00,  9.32it/s, v_num=494, train_loss_step=0.0922, train_acc_step=0.811, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0899, train_acc_epoch=0.823]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 236:  97%|█████████▋| 30/31 [00:03<00:00,  8.79it/s, v_num=494, train_loss_step=0.095, train_acc_step=0.811, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0901, train_acc_epoch=0.828] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 237:  97%|█████████▋| 30/31 [00:03<00:00,  9.25it/s, v_num=494, train_loss_step=0.0914, train_acc_step=0.814, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.760, train_loss_epoch=0.0895, train_acc_epoch=0.827]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 238:  97%|█████████▋| 30/31 [00:04<00:00,  6.88it/s, v_num=494, train_loss_step=0.0922, train_acc_step=0.822, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0891, train_acc_epoch=0.829]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 239:  97%|█████████▋| 30/31 [00:03<00:00,  7.58it/s, v_num=494, train_loss_step=0.0939, train_acc_step=0.809, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0891, train_acc_epoch=0.827]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 240:  97%|█████████▋| 30/31 [00:04<00:00,  7.27it/s, v_num=494, train_loss_step=0.0911, train_acc_step=0.819, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0887, train_acc_epoch=0.830]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 241:  97%|█████████▋| 30/31 [00:03<00:00,  7.56it/s, v_num=494, train_loss_step=0.0897, train_acc_step=0.825, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0893, train_acc_epoch=0.826]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 242:  97%|█████████▋| 30/31 [00:03<00:00,  8.34it/s, v_num=494, train_loss_step=0.0915, train_acc_step=0.812, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0884, train_acc_epoch=0.832]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 243:  97%|█████████▋| 30/31 [00:03<00:00,  9.13it/s, v_num=494, train_loss_step=0.0882, train_acc_step=0.827, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0881, train_acc_epoch=0.831]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 244:  97%|█████████▋| 30/31 [00:03<00:00,  8.75it/s, v_num=494, train_loss_step=0.0919, train_acc_step=0.813, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.110, val_acc_epoch=0.759, train_loss_epoch=0.0881, train_acc_epoch=0.830]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 245:  97%|█████████▋| 30/31 [00:03<00:00,  8.90it/s, v_num=494, train_loss_step=0.0892, train_acc_step=0.820, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0878, train_acc_epoch=0.833]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 246:  97%|█████████▋| 30/31 [00:04<00:00,  6.94it/s, v_num=494, train_loss_step=0.0891, train_acc_step=0.832, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.110, val_acc_epoch=0.763, train_loss_epoch=0.0884, train_acc_epoch=0.831]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 247:  97%|█████████▋| 30/31 [00:02<00:00, 10.60it/s, v_num=494, train_loss_step=0.0902, train_acc_step=0.821, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0882, train_acc_epoch=0.833]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 248:  97%|█████████▋| 30/31 [00:04<00:00,  7.19it/s, v_num=494, train_loss_step=0.0877, train_acc_step=0.836, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0879, train_acc_epoch=0.832]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 249:  97%|█████████▋| 30/31 [00:03<00:00,  8.99it/s, v_num=494, train_loss_step=0.0868, train_acc_step=0.815, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0881, train_acc_epoch=0.831]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 250:  97%|█████████▋| 30/31 [00:03<00:00,  8.76it/s, v_num=494, train_loss_step=0.0876, train_acc_step=0.829, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.110, val_acc_epoch=0.764, train_loss_epoch=0.0879, train_acc_epoch=0.832]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 251:  97%|█████████▋| 30/31 [00:04<00:00,  7.37it/s, v_num=494, train_loss_step=0.0873, train_acc_step=0.830, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0875, train_acc_epoch=0.834]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 252:  97%|█████████▋| 30/31 [00:03<00:00,  9.03it/s, v_num=494, train_loss_step=0.0867, train_acc_step=0.833, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.760, train_loss_epoch=0.0879, train_acc_epoch=0.831]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 253:  97%|█████████▋| 30/31 [00:03<00:00,  8.16it/s, v_num=494, train_loss_step=0.0927, train_acc_step=0.811, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.110, val_acc_epoch=0.761, train_loss_epoch=0.0876, train_acc_epoch=0.834]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 254:  97%|█████████▋| 30/31 [00:03<00:00,  9.49it/s, v_num=494, train_loss_step=0.0852, train_acc_step=0.824, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.109, val_acc_epoch=0.760, train_loss_epoch=0.0873, train_acc_epoch=0.835]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 255:  97%|█████████▋| 30/31 [00:03<00:00,  9.73it/s, v_num=494, train_loss_step=0.0896, train_acc_step=0.824, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0871, train_acc_epoch=0.836]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 256:  97%|█████████▋| 30/31 [00:03<00:00,  8.89it/s, v_num=494, train_loss_step=0.0888, train_acc_step=0.820, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.087, train_acc_epoch=0.833] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 257:  97%|█████████▋| 30/31 [00:03<00:00,  9.15it/s, v_num=494, train_loss_step=0.0911, train_acc_step=0.821, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.087, train_acc_epoch=0.833]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 258:  97%|█████████▋| 30/31 [00:03<00:00,  9.36it/s, v_num=494, train_loss_step=0.0891, train_acc_step=0.823, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0868, train_acc_epoch=0.834]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 259:  97%|█████████▋| 30/31 [00:03<00:00,  9.87it/s, v_num=494, train_loss_step=0.0864, train_acc_step=0.834, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0873, train_acc_epoch=0.835]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 260:  97%|█████████▋| 30/31 [00:02<00:00, 10.55it/s, v_num=494, train_loss_step=0.0879, train_acc_step=0.823, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0862, train_acc_epoch=0.839]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 261:  97%|█████████▋| 30/31 [00:03<00:00,  9.20it/s, v_num=494, train_loss_step=0.0862, train_acc_step=0.830, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0861, train_acc_epoch=0.835]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 262:  97%|█████████▋| 30/31 [00:02<00:00, 10.37it/s, v_num=494, train_loss_step=0.085, train_acc_step=0.840, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0862, train_acc_epoch=0.837] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 263:  97%|█████████▋| 30/31 [00:03<00:00,  9.65it/s, v_num=494, train_loss_step=0.0883, train_acc_step=0.826, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0855, train_acc_epoch=0.836]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 264:  97%|█████████▋| 30/31 [00:03<00:00,  9.44it/s, v_num=494, train_loss_step=0.0837, train_acc_step=0.836, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0858, train_acc_epoch=0.839]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 265:  97%|█████████▋| 30/31 [00:02<00:00, 10.11it/s, v_num=494, train_loss_step=0.0861, train_acc_step=0.836, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0862, train_acc_epoch=0.836]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 266:  97%|█████████▋| 30/31 [00:03<00:00,  9.22it/s, v_num=494, train_loss_step=0.0877, train_acc_step=0.825, val_loss_step=0.112, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0856, train_acc_epoch=0.840]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 267:  97%|█████████▋| 30/31 [00:02<00:00, 10.73it/s, v_num=494, train_loss_step=0.0859, train_acc_step=0.833, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0859, train_acc_epoch=0.837]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 268:  97%|█████████▋| 30/31 [00:03<00:00,  9.67it/s, v_num=494, train_loss_step=0.0872, train_acc_step=0.836, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0854, train_acc_epoch=0.838]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 269:  97%|█████████▋| 30/31 [00:03<00:00,  9.55it/s, v_num=494, train_loss_step=0.0855, train_acc_step=0.826, val_loss_step=0.112, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0849, train_acc_epoch=0.842]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 270:  97%|█████████▋| 30/31 [00:02<00:00, 10.06it/s, v_num=494, train_loss_step=0.0849, train_acc_step=0.840, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0851, train_acc_epoch=0.838]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 271:  97%|█████████▋| 30/31 [00:03<00:00,  9.56it/s, v_num=494, train_loss_step=0.0872, train_acc_step=0.832, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0847, train_acc_epoch=0.839]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 272:  97%|█████████▋| 30/31 [00:03<00:00,  9.93it/s, v_num=494, train_loss_step=0.0878, train_acc_step=0.830, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.085, train_acc_epoch=0.840] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 273:  97%|█████████▋| 30/31 [00:03<00:00,  9.63it/s, v_num=494, train_loss_step=0.0825, train_acc_step=0.852, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0848, train_acc_epoch=0.839]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 274:  97%|█████████▋| 30/31 [00:02<00:00, 10.73it/s, v_num=494, train_loss_step=0.0844, train_acc_step=0.834, val_loss_step=0.111, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0846, train_acc_epoch=0.841]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 275:  97%|█████████▋| 30/31 [00:03<00:00,  9.97it/s, v_num=494, train_loss_step=0.0863, train_acc_step=0.840, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0843, train_acc_epoch=0.842]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 276:  97%|█████████▋| 30/31 [00:03<00:00,  9.64it/s, v_num=494, train_loss_step=0.0826, train_acc_step=0.846, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0838, train_acc_epoch=0.841]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 277:  97%|█████████▋| 30/31 [00:03<00:00,  9.90it/s, v_num=494, train_loss_step=0.084, train_acc_step=0.839, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0839, train_acc_epoch=0.840] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 278:  97%|█████████▋| 30/31 [00:03<00:00,  9.85it/s, v_num=494, train_loss_step=0.0827, train_acc_step=0.835, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0847, train_acc_epoch=0.842]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 279:  97%|█████████▋| 30/31 [00:03<00:00,  9.93it/s, v_num=494, train_loss_step=0.088, train_acc_step=0.822, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.110, val_acc_epoch=0.761, train_loss_epoch=0.0845, train_acc_epoch=0.840] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 280:  97%|█████████▋| 30/31 [00:02<00:00, 10.14it/s, v_num=494, train_loss_step=0.0862, train_acc_step=0.838, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0846, train_acc_epoch=0.839]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 281:  97%|█████████▋| 30/31 [00:03<00:00,  9.21it/s, v_num=494, train_loss_step=0.0876, train_acc_step=0.829, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0843, train_acc_epoch=0.838]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 282:  97%|█████████▋| 30/31 [00:02<00:00, 10.53it/s, v_num=494, train_loss_step=0.0832, train_acc_step=0.846, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0842, train_acc_epoch=0.843]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 283:  97%|█████████▋| 30/31 [00:03<00:00,  9.02it/s, v_num=494, train_loss_step=0.0856, train_acc_step=0.834, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0838, train_acc_epoch=0.840]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 284:  97%|█████████▋| 30/31 [00:02<00:00, 10.23it/s, v_num=494, train_loss_step=0.0851, train_acc_step=0.847, val_loss_step=0.111, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0834, train_acc_epoch=0.843]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 285:  97%|█████████▋| 30/31 [00:03<00:00,  9.75it/s, v_num=494, train_loss_step=0.0872, train_acc_step=0.826, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.110, val_acc_epoch=0.762, train_loss_epoch=0.0834, train_acc_epoch=0.844]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 286:  97%|█████████▋| 30/31 [00:03<00:00,  9.35it/s, v_num=494, train_loss_step=0.084, train_acc_step=0.835, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.761, train_loss_epoch=0.0836, train_acc_epoch=0.843] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 287:  97%|█████████▋| 30/31 [00:03<00:00,  9.47it/s, v_num=494, train_loss_step=0.0822, train_acc_step=0.848, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0832, train_acc_epoch=0.844]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 288:  97%|█████████▋| 30/31 [00:03<00:00,  9.15it/s, v_num=494, train_loss_step=0.084, train_acc_step=0.840, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0836, train_acc_epoch=0.844] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 289:  97%|█████████▋| 30/31 [00:02<00:00, 10.61it/s, v_num=494, train_loss_step=0.0845, train_acc_step=0.829, val_loss_step=0.111, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0835, train_acc_epoch=0.845]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 290:  97%|█████████▋| 30/31 [00:03<00:00,  9.48it/s, v_num=494, train_loss_step=0.0839, train_acc_step=0.850, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0827, train_acc_epoch=0.844]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 291:  97%|█████████▋| 30/31 [00:03<00:00,  9.35it/s, v_num=494, train_loss_step=0.0855, train_acc_step=0.827, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0829, train_acc_epoch=0.845]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 292:  97%|█████████▋| 30/31 [00:02<00:00, 10.46it/s, v_num=494, train_loss_step=0.0813, train_acc_step=0.855, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0824, train_acc_epoch=0.845]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 293:  97%|█████████▋| 30/31 [00:03<00:00,  9.35it/s, v_num=494, train_loss_step=0.0844, train_acc_step=0.844, val_loss_step=0.112, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0828, train_acc_epoch=0.846]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 294:  97%|█████████▋| 30/31 [00:02<00:00, 10.26it/s, v_num=494, train_loss_step=0.0816, train_acc_step=0.844, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0826, train_acc_epoch=0.848]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 295:  97%|█████████▋| 30/31 [00:02<00:00, 11.04it/s, v_num=494, train_loss_step=0.0843, train_acc_step=0.830, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0823, train_acc_epoch=0.844]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 296:  97%|█████████▋| 30/31 [00:03<00:00,  9.10it/s, v_num=494, train_loss_step=0.082, train_acc_step=0.845, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0821, train_acc_epoch=0.848] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 297:  97%|█████████▋| 30/31 [00:02<00:00, 10.43it/s, v_num=494, train_loss_step=0.0821, train_acc_step=0.837, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0819, train_acc_epoch=0.848]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 298:  97%|█████████▋| 30/31 [00:03<00:00,  9.00it/s, v_num=494, train_loss_step=0.0816, train_acc_step=0.851, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0826, train_acc_epoch=0.844]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 299:  97%|█████████▋| 30/31 [00:03<00:00,  9.93it/s, v_num=494, train_loss_step=0.0833, train_acc_step=0.841, val_loss_step=0.111, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0821, train_acc_epoch=0.847]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 300:  97%|█████████▋| 30/31 [00:03<00:00,  9.66it/s, v_num=494, train_loss_step=0.0831, train_acc_step=0.851, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0819, train_acc_epoch=0.849]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 301:  97%|█████████▋| 30/31 [00:03<00:00,  9.12it/s, v_num=494, train_loss_step=0.0809, train_acc_step=0.850, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.762, train_loss_epoch=0.0817, train_acc_epoch=0.850]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 302:  97%|█████████▋| 30/31 [00:03<00:00,  9.57it/s, v_num=494, train_loss_step=0.0806, train_acc_step=0.853, val_loss_step=0.111, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0818, train_acc_epoch=0.848]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 303:  97%|█████████▋| 30/31 [00:03<00:00,  8.49it/s, v_num=494, train_loss_step=0.0793, train_acc_step=0.854, val_loss_step=0.111, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0808, train_acc_epoch=0.850]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 304:  97%|█████████▋| 30/31 [00:03<00:00,  7.61it/s, v_num=494, train_loss_step=0.0819, train_acc_step=0.853, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0814, train_acc_epoch=0.847]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 305:  97%|█████████▋| 30/31 [00:03<00:00,  8.02it/s, v_num=494, train_loss_step=0.0834, train_acc_step=0.842, val_loss_step=0.111, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0818, train_acc_epoch=0.849]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 306:  97%|█████████▋| 30/31 [00:04<00:00,  7.11it/s, v_num=494, train_loss_step=0.0834, train_acc_step=0.838, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0811, train_acc_epoch=0.850]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 307:  97%|█████████▋| 30/31 [00:03<00:00,  8.83it/s, v_num=494, train_loss_step=0.0811, train_acc_step=0.851, val_loss_step=0.111, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0813, train_acc_epoch=0.850]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 308:  97%|█████████▋| 30/31 [00:03<00:00,  9.06it/s, v_num=494, train_loss_step=0.0815, train_acc_step=0.857, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.081, train_acc_epoch=0.852] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 309:  97%|█████████▋| 30/31 [00:03<00:00,  8.87it/s, v_num=494, train_loss_step=0.080, train_acc_step=0.850, val_loss_step=0.111, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0808, train_acc_epoch=0.852] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 310:  97%|█████████▋| 30/31 [00:03<00:00,  9.49it/s, v_num=494, train_loss_step=0.0785, train_acc_step=0.854, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.110, val_acc_epoch=0.763, train_loss_epoch=0.0812, train_acc_epoch=0.849]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 311:  97%|█████████▋| 30/31 [00:03<00:00,  9.82it/s, v_num=494, train_loss_step=0.0809, train_acc_step=0.849, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0814, train_acc_epoch=0.850]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 312:  97%|█████████▋| 30/31 [00:04<00:00,  7.35it/s, v_num=494, train_loss_step=0.0859, train_acc_step=0.834, val_loss_step=0.111, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0802, train_acc_epoch=0.853]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 313:  97%|█████████▋| 30/31 [00:03<00:00,  9.38it/s, v_num=494, train_loss_step=0.0819, train_acc_step=0.840, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.763, train_loss_epoch=0.0812, train_acc_epoch=0.849]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 314:  97%|█████████▋| 30/31 [00:03<00:00,  9.48it/s, v_num=494, train_loss_step=0.0823, train_acc_step=0.857, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0801, train_acc_epoch=0.851]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 315:  97%|█████████▋| 30/31 [00:03<00:00,  9.95it/s, v_num=494, train_loss_step=0.0821, train_acc_step=0.839, val_loss_step=0.111, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0807, train_acc_epoch=0.850]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 316:  97%|█████████▋| 30/31 [00:03<00:00,  9.48it/s, v_num=494, train_loss_step=0.0781, train_acc_step=0.845, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.080, train_acc_epoch=0.852] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 317:  97%|█████████▋| 30/31 [00:03<00:00,  9.89it/s, v_num=494, train_loss_step=0.082, train_acc_step=0.836, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0797, train_acc_epoch=0.854] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 318:  97%|█████████▋| 30/31 [00:03<00:00,  9.44it/s, v_num=494, train_loss_step=0.0797, train_acc_step=0.853, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0799, train_acc_epoch=0.852]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 319:  97%|█████████▋| 30/31 [00:02<00:00, 10.12it/s, v_num=494, train_loss_step=0.0796, train_acc_step=0.853, val_loss_step=0.111, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0798, train_acc_epoch=0.853]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 320:  97%|█████████▋| 30/31 [00:03<00:00,  9.54it/s, v_num=494, train_loss_step=0.0814, train_acc_step=0.844, val_loss_step=0.111, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0797, train_acc_epoch=0.852]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 321:  97%|█████████▋| 30/31 [00:02<00:00, 10.49it/s, v_num=494, train_loss_step=0.078, train_acc_step=0.865, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.110, val_acc_epoch=0.763, train_loss_epoch=0.0791, train_acc_epoch=0.852] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 322:  97%|█████████▋| 30/31 [00:03<00:00,  9.87it/s, v_num=494, train_loss_step=0.0776, train_acc_step=0.857, val_loss_step=0.111, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0794, train_acc_epoch=0.854]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 323:  97%|█████████▋| 30/31 [00:03<00:00,  9.49it/s, v_num=494, train_loss_step=0.0784, train_acc_step=0.851, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0791, train_acc_epoch=0.854]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 324:  97%|█████████▋| 30/31 [00:03<00:00,  9.73it/s, v_num=494, train_loss_step=0.076, train_acc_step=0.872, val_loss_step=0.112, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0788, train_acc_epoch=0.856] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 325:  97%|█████████▋| 30/31 [00:03<00:00,  8.93it/s, v_num=494, train_loss_step=0.0803, train_acc_step=0.853, val_loss_step=0.112, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0782, train_acc_epoch=0.857]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 326:  97%|█████████▋| 30/31 [00:02<00:00, 10.24it/s, v_num=494, train_loss_step=0.081, train_acc_step=0.846, val_loss_step=0.112, val_acc_step=0.768, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0786, train_acc_epoch=0.856] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 327:  97%|█████████▋| 30/31 [00:02<00:00, 10.05it/s, v_num=494, train_loss_step=0.0778, train_acc_step=0.847, val_loss_step=0.111, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0791, train_acc_epoch=0.853]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 328:  97%|█████████▋| 30/31 [00:03<00:00,  9.13it/s, v_num=494, train_loss_step=0.0793, train_acc_step=0.859, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0782, train_acc_epoch=0.856]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 329:  97%|█████████▋| 30/31 [00:03<00:00,  9.61it/s, v_num=494, train_loss_step=0.0785, train_acc_step=0.844, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0782, train_acc_epoch=0.857]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 330:  97%|█████████▋| 30/31 [00:03<00:00,  9.19it/s, v_num=494, train_loss_step=0.0773, train_acc_step=0.858, val_loss_step=0.111, val_acc_step=0.769, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.0784, train_acc_epoch=0.854]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 331:  97%|█████████▋| 30/31 [00:02<00:00, 10.08it/s, v_num=494, train_loss_step=0.0794, train_acc_step=0.849, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0787, train_acc_epoch=0.856]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 332:  97%|█████████▋| 30/31 [00:02<00:00, 10.08it/s, v_num=494, train_loss_step=0.0808, train_acc_step=0.852, val_loss_step=0.111, val_acc_step=0.770, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.0777, train_acc_epoch=0.858]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 333:  97%|█████████▋| 30/31 [00:03<00:00,  9.17it/s, v_num=494, train_loss_step=0.0806, train_acc_step=0.841, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0776, train_acc_epoch=0.858]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 334:  97%|█████████▋| 30/31 [00:03<00:00,  9.99it/s, v_num=494, train_loss_step=0.0805, train_acc_step=0.853, val_loss_step=0.112, val_acc_step=0.754, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.078, train_acc_epoch=0.857] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 335:  97%|█████████▋| 30/31 [00:03<00:00,  9.19it/s, v_num=494, train_loss_step=0.0818, train_acc_step=0.846, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0782, train_acc_epoch=0.856]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 336:  97%|█████████▋| 30/31 [00:02<00:00, 12.03it/s, v_num=494, train_loss_step=0.0768, train_acc_step=0.864, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0782, train_acc_epoch=0.856]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 337:  97%|█████████▋| 30/31 [00:03<00:00,  9.83it/s, v_num=494, train_loss_step=0.0829, train_acc_step=0.840, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0777, train_acc_epoch=0.860]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 338:  97%|█████████▋| 30/31 [00:03<00:00,  9.06it/s, v_num=494, train_loss_step=0.0758, train_acc_step=0.861, val_loss_step=0.111, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0775, train_acc_epoch=0.858]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 339:  97%|█████████▋| 30/31 [00:03<00:00,  9.82it/s, v_num=494, train_loss_step=0.081, train_acc_step=0.845, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0773, train_acc_epoch=0.859] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 340:  97%|█████████▋| 30/31 [00:03<00:00,  9.55it/s, v_num=494, train_loss_step=0.0794, train_acc_step=0.849, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.077, train_acc_epoch=0.860] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 341:  97%|█████████▋| 30/31 [00:02<00:00, 10.99it/s, v_num=494, train_loss_step=0.0756, train_acc_step=0.855, val_loss_step=0.111, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0771, train_acc_epoch=0.861]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 342:  97%|█████████▋| 30/31 [00:03<00:00,  8.54it/s, v_num=494, train_loss_step=0.0772, train_acc_step=0.868, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0764, train_acc_epoch=0.862]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 343:  97%|█████████▋| 30/31 [00:03<00:00,  7.53it/s, v_num=494, train_loss_step=0.0801, train_acc_step=0.853, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0769, train_acc_epoch=0.861]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 344:  97%|█████████▋| 30/31 [00:03<00:00,  8.69it/s, v_num=494, train_loss_step=0.0783, train_acc_step=0.847, val_loss_step=0.111, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0768, train_acc_epoch=0.858]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 345:  97%|█████████▋| 30/31 [00:03<00:00,  9.00it/s, v_num=494, train_loss_step=0.0791, train_acc_step=0.841, val_loss_step=0.112, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.0772, train_acc_epoch=0.860]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 346:  97%|█████████▋| 30/31 [00:03<00:00,  8.93it/s, v_num=494, train_loss_step=0.0767, train_acc_step=0.855, val_loss_step=0.111, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0765, train_acc_epoch=0.860]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 347:  97%|█████████▋| 30/31 [00:03<00:00,  9.05it/s, v_num=494, train_loss_step=0.0747, train_acc_step=0.863, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0766, train_acc_epoch=0.860]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 348:  97%|█████████▋| 30/31 [00:04<00:00,  6.15it/s, v_num=494, train_loss_step=0.076, train_acc_step=0.860, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0763, train_acc_epoch=0.863] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 349:  97%|█████████▋| 30/31 [00:03<00:00,  8.76it/s, v_num=494, train_loss_step=0.0742, train_acc_step=0.874, val_loss_step=0.111, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.0758, train_acc_epoch=0.864]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 350:  97%|█████████▋| 30/31 [00:04<00:00,  6.27it/s, v_num=494, train_loss_step=0.0779, train_acc_step=0.854, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.076, train_acc_epoch=0.862] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 351:  97%|█████████▋| 30/31 [00:03<00:00,  7.58it/s, v_num=494, train_loss_step=0.0752, train_acc_step=0.857, val_loss_step=0.111, val_acc_step=0.771, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.0764, train_acc_epoch=0.861]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 352:  97%|█████████▋| 30/31 [00:03<00:00,  8.15it/s, v_num=494, train_loss_step=0.0751, train_acc_step=0.871, val_loss_step=0.112, val_acc_step=0.769, val_loss_epoch=0.109, val_acc_epoch=0.771, train_loss_epoch=0.0762, train_acc_epoch=0.861]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 353:  97%|█████████▋| 30/31 [00:03<00:00,  9.27it/s, v_num=494, train_loss_step=0.0748, train_acc_step=0.860, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.108, val_acc_epoch=0.769, train_loss_epoch=0.0754, train_acc_epoch=0.868]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 354:  97%|█████████▋| 30/31 [00:04<00:00,  6.29it/s, v_num=494, train_loss_step=0.076, train_acc_step=0.843, val_loss_step=0.111, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.075, train_acc_epoch=0.864]  Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 355:  97%|█████████▋| 30/31 [00:03<00:00,  7.78it/s, v_num=494, train_loss_step=0.0759, train_acc_step=0.863, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0757, train_acc_epoch=0.862]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 356:  97%|█████████▋| 30/31 [00:03<00:00,  8.15it/s, v_num=494, train_loss_step=0.0751, train_acc_step=0.866, val_loss_step=0.111, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0752, train_acc_epoch=0.867]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 357:  97%|█████████▋| 30/31 [00:02<00:00, 10.24it/s, v_num=494, train_loss_step=0.0754, train_acc_step=0.871, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0753, train_acc_epoch=0.863]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 358:  97%|█████████▋| 30/31 [00:03<00:00,  9.39it/s, v_num=494, train_loss_step=0.0765, train_acc_step=0.864, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0754, train_acc_epoch=0.864]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 359:  97%|█████████▋| 30/31 [00:03<00:00,  9.48it/s, v_num=494, train_loss_step=0.0737, train_acc_step=0.866, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.075, train_acc_epoch=0.866] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 360:  97%|█████████▋| 30/31 [00:03<00:00,  9.26it/s, v_num=494, train_loss_step=0.0745, train_acc_step=0.860, val_loss_step=0.111, val_acc_step=0.769, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0747, train_acc_epoch=0.866]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 361:  97%|█████████▋| 30/31 [00:03<00:00,  9.69it/s, v_num=494, train_loss_step=0.0791, train_acc_step=0.847, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0749, train_acc_epoch=0.864]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 362:  97%|█████████▋| 30/31 [00:03<00:00,  9.61it/s, v_num=494, train_loss_step=0.0762, train_acc_step=0.850, val_loss_step=0.112, val_acc_step=0.758, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0746, train_acc_epoch=0.865]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 363:  97%|█████████▋| 30/31 [00:03<00:00,  9.25it/s, v_num=494, train_loss_step=0.0742, train_acc_step=0.864, val_loss_step=0.111, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0742, train_acc_epoch=0.867]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 364:  97%|█████████▋| 30/31 [00:02<00:00, 10.41it/s, v_num=494, train_loss_step=0.0752, train_acc_step=0.866, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0744, train_acc_epoch=0.866]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 365:  97%|█████████▋| 30/31 [00:03<00:00,  9.07it/s, v_num=494, train_loss_step=0.0762, train_acc_step=0.866, val_loss_step=0.112, val_acc_step=0.768, val_loss_epoch=0.109, val_acc_epoch=0.771, train_loss_epoch=0.0745, train_acc_epoch=0.867]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 366:  97%|█████████▋| 30/31 [00:03<00:00,  9.94it/s, v_num=494, train_loss_step=0.074, train_acc_step=0.872, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0743, train_acc_epoch=0.868] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 367:  97%|█████████▋| 30/31 [00:03<00:00,  9.92it/s, v_num=494, train_loss_step=0.0727, train_acc_step=0.876, val_loss_step=0.111, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0745, train_acc_epoch=0.867]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 368:  97%|█████████▋| 30/31 [00:02<00:00, 10.13it/s, v_num=494, train_loss_step=0.0739, train_acc_step=0.861, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0736, train_acc_epoch=0.866]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 369:  97%|█████████▋| 30/31 [00:03<00:00,  9.49it/s, v_num=494, train_loss_step=0.0746, train_acc_step=0.860, val_loss_step=0.112, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0746, train_acc_epoch=0.864]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 370:  97%|█████████▋| 30/31 [00:04<00:00,  7.50it/s, v_num=494, train_loss_step=0.0713, train_acc_step=0.875, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0737, train_acc_epoch=0.868]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 371:  97%|█████████▋| 30/31 [00:03<00:00,  8.87it/s, v_num=494, train_loss_step=0.0736, train_acc_step=0.861, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0738, train_acc_epoch=0.869]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 372:  97%|█████████▋| 30/31 [00:04<00:00,  6.50it/s, v_num=494, train_loss_step=0.0719, train_acc_step=0.874, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0739, train_acc_epoch=0.869]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 373:  97%|█████████▋| 30/31 [00:04<00:00,  7.39it/s, v_num=494, train_loss_step=0.0765, train_acc_step=0.859, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.110, val_acc_epoch=0.767, train_loss_epoch=0.0736, train_acc_epoch=0.869]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 374:  97%|█████████▋| 30/31 [00:03<00:00,  8.84it/s, v_num=494, train_loss_step=0.0732, train_acc_step=0.863, val_loss_step=0.112, val_acc_step=0.766, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0736, train_acc_epoch=0.869]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 375:  97%|█████████▋| 30/31 [00:03<00:00,  7.69it/s, v_num=494, train_loss_step=0.0738, train_acc_step=0.862, val_loss_step=0.112, val_acc_step=0.759, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.073, train_acc_epoch=0.870] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 376:  97%|█████████▋| 30/31 [00:03<00:00,  9.28it/s, v_num=494, train_loss_step=0.0763, train_acc_step=0.857, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0739, train_acc_epoch=0.867]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 377:  97%|█████████▋| 30/31 [00:03<00:00,  7.76it/s, v_num=494, train_loss_step=0.0734, train_acc_step=0.871, val_loss_step=0.112, val_acc_step=0.769, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0731, train_acc_epoch=0.869]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 378:  97%|█████████▋| 30/31 [00:03<00:00,  9.19it/s, v_num=494, train_loss_step=0.0734, train_acc_step=0.870, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0726, train_acc_epoch=0.871]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 379:  97%|█████████▋| 30/31 [00:04<00:00,  7.25it/s, v_num=494, train_loss_step=0.0734, train_acc_step=0.874, val_loss_step=0.111, val_acc_step=0.768, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0724, train_acc_epoch=0.870]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 380:  97%|█████████▋| 30/31 [00:03<00:00,  8.60it/s, v_num=494, train_loss_step=0.073, train_acc_step=0.868, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0727, train_acc_epoch=0.873] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 381:  97%|█████████▋| 30/31 [00:03<00:00,  9.75it/s, v_num=494, train_loss_step=0.0732, train_acc_step=0.865, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.072, train_acc_epoch=0.873] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 382:  97%|█████████▋| 30/31 [00:03<00:00,  9.08it/s, v_num=494, train_loss_step=0.0755, train_acc_step=0.853, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0725, train_acc_epoch=0.871]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 383:  97%|█████████▋| 30/31 [00:04<00:00,  7.32it/s, v_num=494, train_loss_step=0.0738, train_acc_step=0.861, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0721, train_acc_epoch=0.874]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 384:  97%|█████████▋| 30/31 [00:03<00:00,  8.98it/s, v_num=494, train_loss_step=0.0715, train_acc_step=0.867, val_loss_step=0.112, val_acc_step=0.761, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.072, train_acc_epoch=0.873] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 385:  97%|█████████▋| 30/31 [00:04<00:00,  6.68it/s, v_num=494, train_loss_step=0.0703, train_acc_step=0.873, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.770, train_loss_epoch=0.0713, train_acc_epoch=0.873]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 386:  97%|█████████▋| 30/31 [00:03<00:00,  8.73it/s, v_num=494, train_loss_step=0.0713, train_acc_step=0.872, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.109, val_acc_epoch=0.764, train_loss_epoch=0.0716, train_acc_epoch=0.873]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 387:  97%|█████████▋| 30/31 [00:03<00:00,  8.45it/s, v_num=494, train_loss_step=0.0728, train_acc_step=0.868, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0718, train_acc_epoch=0.872]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 388:  97%|█████████▋| 30/31 [00:04<00:00,  6.57it/s, v_num=494, train_loss_step=0.0745, train_acc_step=0.869, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0713, train_acc_epoch=0.873]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 389:  97%|█████████▋| 30/31 [00:03<00:00,  9.39it/s, v_num=494, train_loss_step=0.0745, train_acc_step=0.858, val_loss_step=0.112, val_acc_step=0.757, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0712, train_acc_epoch=0.874]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 390:  97%|█████████▋| 30/31 [00:03<00:00,  8.06it/s, v_num=494, train_loss_step=0.0716, train_acc_step=0.871, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0721, train_acc_epoch=0.870]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 391:  97%|█████████▋| 30/31 [00:03<00:00,  7.89it/s, v_num=494, train_loss_step=0.074, train_acc_step=0.866, val_loss_step=0.112, val_acc_step=0.763, val_loss_epoch=0.110, val_acc_epoch=0.766, train_loss_epoch=0.0712, train_acc_epoch=0.875] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 392:  97%|█████████▋| 30/31 [00:03<00:00,  9.16it/s, v_num=494, train_loss_step=0.0733, train_acc_step=0.868, val_loss_step=0.112, val_acc_step=0.765, val_loss_epoch=0.109, val_acc_epoch=0.767, train_loss_epoch=0.0716, train_acc_epoch=0.874]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 393:  97%|█████████▋| 30/31 [00:04<00:00,  7.18it/s, v_num=494, train_loss_step=0.0738, train_acc_step=0.867, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0713, train_acc_epoch=0.875]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 394:  97%|█████████▋| 30/31 [00:02<00:00, 10.52it/s, v_num=494, train_loss_step=0.075, train_acc_step=0.859, val_loss_step=0.112, val_acc_step=0.764, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0706, train_acc_epoch=0.877] Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 395:  97%|█████████▋| 30/31 [00:03<00:00,  7.97it/s, v_num=494, train_loss_step=0.0709, train_acc_step=0.869, val_loss_step=0.113, val_acc_step=0.761, val_loss_epoch=0.110, val_acc_epoch=0.770, train_loss_epoch=0.0707, train_acc_epoch=0.878]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 396:  97%|█████████▋| 30/31 [00:02<00:00, 10.34it/s, v_num=494, train_loss_step=0.0719, train_acc_step=0.864, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.766, train_loss_epoch=0.0705, train_acc_epoch=0.877]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 397:  97%|█████████▋| 30/31 [00:02<00:00, 11.72it/s, v_num=494, train_loss_step=0.0702, train_acc_step=0.868, val_loss_step=0.112, val_acc_step=0.760, val_loss_epoch=0.109, val_acc_epoch=0.765, train_loss_epoch=0.0708, train_acc_epoch=0.875]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 398:  97%|█████████▋| 30/31 [00:02<00:00, 10.63it/s, v_num=494, train_loss_step=0.0681, train_acc_step=0.883, val_loss_step=0.112, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0704, train_acc_epoch=0.877]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 399:  97%|█████████▋| 30/31 [00:02<00:00, 10.89it/s, v_num=494, train_loss_step=0.0669, train_acc_step=0.885, val_loss_step=0.112, val_acc_step=0.762, val_loss_epoch=0.109, val_acc_epoch=0.769, train_loss_epoch=0.0696, train_acc_epoch=0.877]Adjusting learning rate of group 0 to 8.6274e-05.\n",
      "Epoch 399: 100%|██████████| 31/31 [00:03<00:00,  9.97it/s, v_num=494, train_loss_step=0.0679, train_acc_step=0.889, val_loss_step=0.112, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0693, train_acc_epoch=0.879]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 31/31 [00:03<00:00,  8.14it/s, v_num=494, train_loss_step=0.0679, train_acc_step=0.889, val_loss_step=0.112, val_acc_step=0.767, val_loss_epoch=0.109, val_acc_epoch=0.768, train_loss_epoch=0.0693, train_acc_epoch=0.879]\n"
     ]
    }
   ],
   "source": [
    "# max_epochs = 1000\n",
    "# trainer.fit_loop.max_epochs = max_epochs\n",
    "trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(test_dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8065    0.7380    0.7707       271\n",
      "           1     0.8269    0.8417    0.8342       278\n",
      "           2     0.9127    0.8462    0.8782       247\n",
      "           3     0.8327    0.7770    0.8038       269\n",
      "           4     0.6900    0.6529    0.6709       242\n",
      "           5     0.6920    0.6458    0.6681       240\n",
      "           6     0.7545    0.7770    0.7656       269\n",
      "           7     0.8588    0.8295    0.8439       264\n",
      "           8     0.7148    0.7355    0.7250       276\n",
      "           9     0.6768    0.7882    0.7283       255\n",
      "          10     0.6697    0.7690    0.7159       290\n",
      "          11     0.8519    0.8070    0.8288       171\n",
      "\n",
      "    accuracy                         0.7676      3072\n",
      "   macro avg     0.7739    0.7673    0.7695      3072\n",
      "weighted avg     0.7716    0.7676    0.7684      3072\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[200,   3,   3,   0,   1,   3,  11,   3,  37,   2,   3,   5],\n",
      "        [  6, 234,   0,   0,   9,   9,   9,   3,   0,   3,   3,   2],\n",
      "        [  3,   2, 209,   3,   1,   3,   0,   3,   4,   8,   9,   2],\n",
      "        [  0,   0,   4, 209,   6,   1,   0,   8,   2,  12,  25,   2],\n",
      "        [  3,  11,   1,   8, 158,  13,   3,   1,   6,  16,  17,   5],\n",
      "        [  3,  13,   0,   2,  17, 155,  15,   3,   8,  11,  12,   1],\n",
      "        [  5,   6,   0,   2,   3,  20, 209,   3,   5,   8,   8,   0],\n",
      "        [  2,   3,   2,   7,   3,   1,   3, 219,   6,   3,  15,   0],\n",
      "        [ 21,   2,   1,   5,   3,   2,  11,   4, 203,  15,   7,   2],\n",
      "        [  0,   1,   2,   8,  12,   7,   4,   0,   8, 201,   9,   3],\n",
      "        [  3,   6,   3,   4,   7,  10,  10,   8,   3,  11, 223,   2],\n",
      "        [  2,   2,   4,   3,   9,   0,   2,   0,   2,   7,   2, 138]])\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "classfier_lightning_model = classfier_lightning_model.eval()\n",
    "calculate_metrics(classfier_lightning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
